{"id": "source:rss:7086792543", "title": "Introducing GPT-5.3-Codex-Spark", "summary": "Introducing GPT-5.3-Codex-Spark\u2014our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.", "url": "https://openai.com/index/introducing-gpt-5-3-codex-spark", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Introducing GPT-5.3-Codex-Spark\u2014our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users."]}
{"id": "source:rss:4925159998", "title": "Harness engineering: leveraging Codex in an agent-first world", "summary": "By Ryan Lopopolo, Member of the Technical Staff", "url": "https://openai.com/index/harness-engineering", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["By Ryan Lopopolo, Member of the Technical Staff"]}
{"id": "source:rss:6675598680", "title": "Testing ads in ChatGPT", "summary": "OpenAI begins testing ads in ChatGPT to support free access, with clear labeling, answer independence, strong privacy protections, and user control.", "url": "https://openai.com/index/testing-ads-in-chatgpt", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI begins testing ads in ChatGPT to support free access, with clear labeling, answer independence, strong privacy protections, and user control."]}
{"id": "source:rss:2471478226", "title": "Bringing ChatGPT to GenAI.mil", "summary": "OpenAI for Government announces the deployment of a custom ChatGPT on GenAI.mil, bringing secure, safety-forward AI to U.S. defense teams.", "url": "https://openai.com/index/bringing-chatgpt-to-genaimil", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI for Government announces the deployment of a custom ChatGPT on GenAI.mil, bringing secure, safety-forward AI to U.S. defense teams."]}
{"id": "source:rss:1194092314", "title": "Making AI work for everyone, everywhere: our approach to localization", "summary": "OpenAI shares its approach to AI localization, showing how globally shared frontier models can be adapted to local languages, laws, and cultures without compromising safety.", "url": "https://openai.com/index/our-approach-to-localization", "published_at": "Fri, 06 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI shares its approach to AI localization, showing how globally shared frontier models can be adapted to local languages, laws, and cultures without compromising safety."]}
{"id": "source:rss:9151009999", "title": "GPT-5 lowers the cost of cell-free protein synthesis", "summary": "An autonomous lab combining OpenAI\u2019s GPT-5 with Ginkgo Bioworks\u2019 cloud automation cut cell-free protein synthesis costs by 40% through closed-loop experimentation.", "url": "https://openai.com/index/gpt-5-lowers-protein-synthesis-cost", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["An autonomous lab combining OpenAI\u2019s GPT-5 with Ginkgo Bioworks\u2019 cloud automation cut cell-free protein synthesis costs by 40% through closed-loop experimentation."]}
{"id": "source:rss:1728989348", "title": "Introducing Trusted Access for Cyber", "summary": "OpenAI introduces Trusted Access for Cyber, a trust-based framework that expands access to frontier cyber capabilities while strengthening safeguards against misuse.", "url": "https://openai.com/index/trusted-access-for-cyber", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI introduces Trusted Access for Cyber, a trust-based framework that expands access to frontier cyber capabilities while strengthening safeguards against misuse."]}
{"id": "source:rss:7411648131", "title": "Introducing OpenAI Frontier", "summary": "OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents with shared context, onboarding, permissions, and governance.", "url": "https://openai.com/index/introducing-openai-frontier", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": ["ai_agents", "governance"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents with shared context, onboarding, permissions, and governance."]}
{"id": "source:rss:6765564858", "title": "Introducing GPT-5.3-Codex", "summary": "GPT-5.3-Codex is a Codex-native agent that pairs frontier coding performance with general reasoning to support long-horizon, real-world technical work.", "url": "https://openai.com/index/introducing-gpt-5-3-codex", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["GPT-5.3-Codex is a Codex-native agent that pairs frontier coding performance with general reasoning to support long-horizon, real-world technical work."]}
{"id": "source:rss:6029179820", "title": "Navigating health questions with ChatGPT", "summary": "A family shares how ChatGPT helped them prepare for critical cancer treatment decisions for their son alongside expert guidance from his doctors.", "url": "https://openai.com/index/navigating-health-questions", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["A family shares how ChatGPT helped them prepare for critical cancer treatment decisions for their son alongside expert guidance from his doctors."]}
{"id": "source:rss:5576876965", "title": "GPT-5.3-Codex System Card", "summary": "GPT\u20115.3-Codex is the most capable agentic coding model to date, combining the frontier coding performance of GPT\u20115.2-Codex with the reasoning and professional knowledge capabilities of GPT\u20115.2.", "url": "https://openai.com/index/gpt-5-3-codex-system-card", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["GPT\u20115.3-Codex is the most capable agentic coding model to date, combining the frontier coding performance of GPT\u20115.2-Codex with the reasoning and professional knowledge capabilities of GPT\u20115.2."]}
{"id": "source:rss:2945931042", "title": "Unlocking the Codex harness: how we built the App Server", "summary": "Learn how to embed the Codex agent using the Codex App Server, a bidirectional JSON-RPC API powering streaming progress, tool use, approvals, and diffs.", "url": "https://openai.com/index/unlocking-the-codex-harness", "published_at": "Wed, 04 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Learn how to embed the Codex agent using the Codex App Server, a bidirectional JSON-RPC API powering streaming progress, tool use, approvals, and diffs."]}
{"id": "source:rss:4560041066", "title": "VfL Wolfsburg turns ChatGPT into a club-wide capability", "summary": "By focusing on people, not pilots, the Bundesliga club is scaling efficiency, creativity, and knowledge\u2014without losing its football identity.", "url": "https://openai.com/index/vfl-wolfsburg", "published_at": "Wed, 04 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["By focusing on people, not pilots, the Bundesliga club is scaling efficiency, creativity, and knowledge\u2014without losing its football identity."]}
{"id": "source:rss:4166964181", "title": "The Sora feed philosophy", "summary": "Discover the Sora feed philosophy\u2014built to spark creativity, foster connections, and keep experiences safe with personalized recommendations, parental controls, and strong guardrails.", "url": "https://openai.com/index/sora-feed-philosophy", "published_at": "Tue, 03 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Discover the Sora feed philosophy\u2014built to spark creativity, foster connections, and keep experiences safe with personalized recommendations, parental controls, and strong guardrails."]}
{"id": "source:rss:7016756906", "title": "Snowflake and OpenAI partner to bring frontier intelligence to enterprise data", "summary": "OpenAI and Snowflake partner in a $200M agreement to bring frontier intelligence into enterprise data, enabling AI agents and insights directly in Snowflake.", "url": "https://openai.com/index/snowflake-partnership", "published_at": "Mon, 02 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI and Snowflake partner in a $200M agreement to bring frontier intelligence into enterprise data, enabling AI agents and insights directly in Snowflake."]}
{"id": "source:rss:2666319589", "title": "Introducing the Codex app", "summary": "Introducing the Codex app for macOS\u2014a command center for AI coding and software development with multiple agents, parallel workflows, and long-running tasks.", "url": "https://openai.com/index/introducing-the-codex-app", "published_at": "Mon, 02 Fe", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Introducing the Codex app for macOS\u2014a command center for AI coding and software development with multiple agents, parallel workflows, and long-running tasks."]}
{"id": "source:rss:5320522521", "title": "Inside OpenAI\u2019s in-house data agent", "summary": "How OpenAI built an in-house AI data agent that uses GPT-5, Codex, and memory to reason over massive datasets and deliver reliable insights in minutes.", "url": "https://openai.com/index/inside-our-in-house-data-agent", "published_at": "Thu, 29 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["How OpenAI built an in-house AI data agent that uses GPT-5, Codex, and memory to reason over massive datasets and deliver reliable insights in minutes."]}
{"id": "source:rss:3122223950", "title": "Taisei Corporation shapes the next generation of talent with ChatGPT", "summary": "Taisei Corporation uses ChatGPT Enterprise to support HR-led talent development and scale generative AI across its global construction business.", "url": "https://openai.com/index/taisei", "published_at": "Thu, 29 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Taisei Corporation uses ChatGPT Enterprise to support HR-led talent development and scale generative AI across its global construction business."]}
{"id": "source:rss:1973677089", "title": "Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ChatGPT", "summary": "On February 13, 2026, alongside the previously announced retirement\u2060 of GPT\u20115 (Instant, Thinking, and Pro), we will retire GPT\u20114o, GPT\u20114.1, GPT\u20114.1 mini, and OpenAI o4-mini from ChatGPT. In the API, there are no changes at this time.", "url": "https://openai.com/index/retiring-gpt-4o-and-older-models", "published_at": "Thu, 29 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["On February 13, 2026, alongside the previously announced retirement\u2060 of GPT\u20115 (Instant, Thinking, and Pro), we will retire GPT\u20114o, GPT\u20114.1, GPT\u20114.1 mini, and OpenAI o4-mini from ChatGPT. In the API, there are no changes at this time."]}
{"id": "source:rss:5840372916", "title": "The next chapter for AI in the EU", "summary": "OpenAI launches the EU Economic Blueprint 2.0 with new data, partnerships, and initiatives to accelerate AI adoption, skills, and growth across Europe.", "url": "https://openai.com/index/the-next-chapter-for-ai-in-the-eu", "published_at": "Wed, 28 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI launches the EU Economic Blueprint 2.0 with new data, partnerships, and initiatives to accelerate AI adoption, skills, and growth across Europe."]}
{"id": "source:rss:1975009180", "title": "EMEA Youth & Wellbeing Grant", "summary": "Apply for the EMEA Youth & Wellbeing Grant, a \u20ac500,000 program funding NGOs and researchers advancing youth safety and wellbeing in the age of AI.", "url": "https://openai.com/index/emea-youth-and-wellbeing-grant", "published_at": "Wed, 28 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Apply for the EMEA Youth & Wellbeing Grant, a \u20ac500,000 program funding NGOs and researchers advancing youth safety and wellbeing in the age of AI."]}
{"id": "source:rss:2452886760", "title": "Keeping your data safe when an AI agent clicks a link", "summary": "Learn how OpenAI protects user data when AI agents open links, preventing URL-based data exfiltration and prompt injection with built-in safeguards.", "url": "https://openai.com/index/ai-agent-link-safety", "published_at": "Wed, 28 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Learn how OpenAI protects user data when AI agents open links, preventing URL-based data exfiltration and prompt injection with built-in safeguards."]}
{"id": "source:rss:8895771033", "title": "PVH reimagines the future of fashion with OpenAI", "summary": "PVH Corp., parent company of Calvin Klein and Tommy Hilfiger, is adopting ChatGPT Enterprise to bring AI into fashion design, supply chain, and consumer engagement.", "url": "https://openai.com/index/pvh-future-of-fashion", "published_at": "Tue, 27 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["PVH Corp., parent company of Calvin Klein and Tommy Hilfiger, is adopting ChatGPT Enterprise to bring AI into fashion design, supply chain, and consumer engagement."]}
{"id": "source:rss:4715734585", "title": "Introducing Prism", "summary": "Prism is a free LaTeX-native workspace with GPT-5.2 built in, helping researchers write, collaborate, and reason in one place.", "url": "https://openai.com/index/introducing-prism", "published_at": "Tue, 27 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Prism is a free LaTeX-native workspace with GPT-5.2 built in, helping researchers write, collaborate, and reason in one place."]}
{"id": "source:rss:1339896906", "title": "Powering tax donations with AI powered personalized recommendations", "summary": "TRUSTBANK partnered with Recursive to build Choice AI using OpenAI models, delivering personalized, conversational recommendations that simplify Furusato Nozei gift discovery. A multi-agent system helps donors navigate thousands of options and find gifts that match their preferences.", "url": "https://openai.com/index/trustbank", "published_at": "Tue, 27 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["TRUSTBANK partnered with Recursive to build Choice AI using OpenAI models, delivering personalized, conversational recommendations that simplify Furusato Nozei gift discovery. A multi-agent system helps donors navigate thousands of options and find gifts that match their preferences."]}
{"id": "source:rss:4622501450", "title": "How Indeed uses AI to help evolve the job search", "summary": "Indeed\u2019s CRO Maggie Hulce shares how AI is transforming job search, recruiting, and talent acquisition for employers and job seekers.", "url": "https://openai.com/index/indeed-maggie-hulce", "published_at": "Mon, 26 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Indeed\u2019s CRO Maggie Hulce shares how AI is transforming job search, recruiting, and talent acquisition for employers and job seekers."]}
{"id": "source:rss:9223260491", "title": "Unrolling the Codex agent loop", "summary": "A technical deep dive into the Codex agent loop, explaining how Codex CLI orchestrates models, tools, prompts, and performance using the Responses API.", "url": "https://openai.com/index/unrolling-the-codex-agent-loop", "published_at": "Fri, 23 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["A technical deep dive into the Codex agent loop, explaining how Codex CLI orchestrates models, tools, prompts, and performance using the Responses API."]}
{"id": "source:rss:3759105108", "title": "Scaling PostgreSQL to power 800 million ChatGPT users", "summary": "An inside look at how OpenAI scaled PostgreSQL to millions of queries per second using replicas, caching, rate limiting, and workload isolation.", "url": "https://openai.com/index/scaling-postgresql", "published_at": "Thu, 22 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["An inside look at how OpenAI scaled PostgreSQL to millions of queries per second using replicas, caching, rate limiting, and workload isolation."]}
{"id": "source:rss:8052974897", "title": "Inside Praktika's conversational approach to language learning", "summary": "How Praktika uses GPT-4.1 and GPT-5.2 to build adaptive AI tutors that personalize lessons, track progress, and help learners achieve real-world language fluency", "url": "https://openai.com/index/praktika", "published_at": "Thu, 22 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["How Praktika uses GPT-4.1 and GPT-5.2 to build adaptive AI tutors that personalize lessons, track progress, and help learners achieve real-world language fluency"]}
{"id": "source:rss:4322617331", "title": "Inside GPT-5 for Work: How Businesses Use GPT-5", "summary": "A data-driven report on how workers across industries use ChatGPT\u2014covering adoption trends, top tasks, departmental patterns, and the future of AI at work.", "url": "https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work", "published_at": "Thu, 22 Ja", "source_type": "rss", "credibility_tier": "B", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["A data-driven report on how workers across industries use ChatGPT\u2014covering adoption trends, top tasks, departmental patterns, and the future of AI at work."]}
{"id": "source:rss:3264726571", "title": "A One-Line Command to Track Layoffs Costs Workers Jobs at Pinterest", "summary": "Pinterest engineer firings was a single line of code tracking office headcounts.", "url": "https://www.techbuzz.ai/articles/a-one-line-command-to-track-layoffs-costs-workers-jobs-at-pinterest", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Pinterest engineer firings was a single line of code tracking office headcounts."]}
{"id": "source:rss:5403743449", "title": "Waymo Launches Grassroots Campaign to Pressure DC Officials", "summary": "Google's self-driving unit mobilizes residents to lobby city leaders as robotaxi expansion stalls", "url": "https://www.techbuzz.ai/articles/waymo-launches-grassroots-campaign-to-pressure-dc-officials", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Google's self-driving unit mobilizes residents to lobby city leaders as robotaxi expansion stalls"]}
{"id": "source:rss:7876889953", "title": "Didero bags $30M Series A for AI procurement agents", "summary": "Manufacturing startup raises Series A from Chemistry and Headline to automate supply chain", "url": "https://www.techbuzz.ai/articles/didero-bags-30m-series-a-for-ai-procurement-agents", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Manufacturing startup raises Series A from Chemistry and Headline to automate supply chain"]}
{"id": "source:rss:5614360454", "title": "Iron Mike, Real Food, and the Great American Diet Reset", "summary": "Mike Tyson's $8M MAHA Super Bowl ad sends 100M to RealFood.gov", "url": "https://www.techbuzz.ai/articles/iron-mike-real-food-and-the-great-american-diet-reset", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Mike Tyson's $8M MAHA Super Bowl ad sends 100M to RealFood.gov"]}
{"id": "source:rss:4038263849", "title": "Anthropic Closes $30B Round at $380B Valuation", "summary": "AI startup secures second-largest private tech financing ever, trailing only OpenAI", "url": "https://www.techbuzz.ai/articles/anthropic-closes-30b-round-at-380b-valuation", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["AI startup secures second-largest private tech financing ever, trailing only OpenAI"]}
{"id": "source:rss:7776099232", "title": "OpenAI President's Trump Donations Spark Internal Revolt", "summary": "Greg Brockman defends millions in Trump donations as OpenAI employees revolt", "url": "https://www.techbuzz.ai/articles/openai-president-s-trump-donations-spark-internal-revolt", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Greg Brockman defends millions in Trump donations as OpenAI employees revolt"]}
{"id": "source:rss:5105398176", "title": "Spotify Devs Haven't Coded Since December\u2014AI Does It All", "summary": "Spotify's top engineers stopped writing code, relying on Claude Code and internal AI", "url": "https://www.techbuzz.ai/articles/spotify-devs-haven-t-coded-since-december-ai-does-it-all", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Spotify's top engineers stopped writing code, relying on Claude Code and internal AI"]}
{"id": "source:rss:3910547588", "title": "Spotify's Top Devs Haven't Coded Since December\u2014AI Does It All", "summary": "Spotify says its best engineers stopped manual coding, relying on Claude Code and Honk AI", "url": "https://www.techbuzz.ai/articles/spotify-s-top-devs-haven-t-coded-since-december-ai-does-it-all", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Spotify says its best engineers stopped manual coding, relying on Claude Code and Honk AI"]}
{"id": "source:rss:5790146491", "title": "DOJ Antitrust Chief Exits Weeks Before Live Nation Trial", "summary": "Gail Slater's sudden departure raises questions about DOJ's major monopoly cases", "url": "https://www.techbuzz.ai/articles/doj-antitrust-chief-exits-weeks-before-live-nation-trial", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Gail Slater's sudden departure raises questions about DOJ's major monopoly cases"]}
{"id": "source:rss:8851459008", "title": "Aurora's Self-Driving Trucks Just Beat Human Drivers", "summary": "Autonomous trucks complete 1,000 miles in 15 hours, surpassing legal human limits", "url": "https://www.techbuzz.ai/articles/aurora-s-self-driving-trucks-just-beat-human-drivers", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Autonomous trucks complete 1,000 miles in 15 hours, surpassing legal human limits"]}
{"id": "source:rss:5001347554", "title": "OpenAI Partners with Cerebras on New Codex-Spark Chip", "summary": "OpenAI launches Codex-Spark on dedicated Cerebras hardware in first milestone partnership", "url": "https://www.techbuzz.ai/articles/openai-partners-with-cerebras-on-new-codex-spark-chip", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI launches Codex-Spark on dedicated Cerebras hardware in first milestone partnership"]}
{"id": "source:rss:2736228019", "title": "YouTube Finally Launches Native App for Apple Vision Pro", "summary": "After two years, YouTube debuts official visionOS app with VR180 and 360 support", "url": "https://www.techbuzz.ai/articles/youtube-finally-launches-native-app-for-apple-vision-pro", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["After two years, YouTube debuts official visionOS app with VR180 and 360 support"]}
{"id": "source:rss:4709255847", "title": "AI Arbitrator Goes Live: One Case, Big Questions Ahead", "summary": "American Arbitration Association debuts AI judges for construction disputes\u2014just one case so far.", "url": "https://www.techbuzz.ai/articles/ai-arbitrator-goes-live-one-case-big-questions-ahead", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["American Arbitration Association debuts AI judges for construction disputes\u2014just one case so far."]}
{"id": "source:rss:3443601036", "title": "Google Unveils Gemini 3 Deep Think for Science & Engineering", "summary": "Google releases major upgrade to its specialized AI reasoning mode for research", "url": "https://www.techbuzz.ai/articles/google-unveils-gemini-3-deep-think-for-science-engineering", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Google releases major upgrade to its specialized AI reasoning mode for research"]}
{"id": "source:rss:7092580255", "title": "Apple Takes Full Control of 'Severance' in Streaming Power Play", "summary": "Apple acquires complete rights to hit series, signaling shift to full ownership model", "url": "https://www.techbuzz.ai/articles/apple-takes-full-control-of-severance-in-streaming-power-play", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Apple acquires complete rights to hit series, signaling shift to full ownership model"]}
{"id": "source:rss:5831299436", "title": "Waymo's Sixth-Gen Robotaxi Hits the Streets", "summary": "Alphabet's Waymo launches sixth-gen autonomous tech ready for scale production", "url": "https://www.techbuzz.ai/articles/waymo-s-sixth-gen-robotaxi-hits-the-streets", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Alphabet's Waymo launches sixth-gen autonomous tech ready for scale production"]}
{"id": "source:rss:5346113925", "title": "ByteDance Drops Seedance 2.0, a Multimodal AI Video Generator", "summary": "TikTok's parent launches AI model combining text, images, video, and audio prompts", "url": "https://www.techbuzz.ai/articles/bytedance-drops-seedance-2-0-a-multimodal-ai-video-generator", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["TikTok's parent launches AI model combining text, images, video, and audio prompts"]}
{"id": "source:rss:5373351722", "title": "Google Exposes AI Weaponization in Cyber Attack Wave", "summary": "Google's threat team reveals how hackers exploit AI tools in new security report", "url": "https://www.techbuzz.ai/articles/google-exposes-ai-weaponization-in-cyber-attack-wave", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Google's threat team reveals how hackers exploit AI tools in new security report"]}
{"id": "source:rss:1878557345", "title": "NVIDIA's DGX Spark Reaches South Pole Research Stations", "summary": "Desktop supercomputers bring petaflop AI power to universities worldwide", "url": "https://www.techbuzz.ai/articles/nvidia-s-dgx-spark-reaches-south-pole-research-stations", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Desktop supercomputers bring petaflop AI power to universities worldwide"]}
{"id": "source:rss:2512936366", "title": "FTC Questions Apple Over News Feed Bias Claims", "summary": "Federal regulator cites conservative group's report on Apple News curation practices", "url": "https://www.techbuzz.ai/articles/ftc-questions-apple-over-news-feed-bias-claims", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Federal regulator cites conservative group's report on Apple News curation practices"]}
{"id": "source:rss:4823146348", "title": "Amazon Turns Kindle Scribe Into AI Productivity Hub", "summary": "Send to Alexa Plus transforms handwritten notes into tasks and summaries", "url": "https://www.techbuzz.ai/articles/amazon-turns-kindle-scribe-into-ai-productivity-hub", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Send to Alexa Plus transforms handwritten notes into tasks and summaries"]}
{"id": "source:rss:4740253811", "title": "Ever Raises $31M Series A for AI-Powered EV Marketplace", "summary": "Eclipse leads funding round for San Francisco startup disrupting used EV sales", "url": "https://www.techbuzz.ai/articles/ever-raises-31m-series-a-for-ai-powered-ev-marketplace", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Eclipse leads funding round for San Francisco startup disrupting used EV sales"]}
{"id": "source:rss:4830544827", "title": "Weave's $8K laundry robot needs human help to fold clothes", "summary": "Bay Area startup launches Isaac 0, a stationary folding robot with teleoperators", "url": "https://www.techbuzz.ai/articles/weave-s-8k-laundry-robot-needs-human-help-to-fold-clothes", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Bay Area startup launches Isaac 0, a stationary folding robot with teleoperators"]}
{"id": "source:rss:4231821525", "title": "Anthropic Drops $20M on Pro-Regulation PAC for 2026 Elections", "summary": "AI startup backs Public First Action to counter industry's anti-regulation push", "url": "https://www.techbuzz.ai/articles/anthropic-drops-20m-on-pro-regulation-pac-for-2026-elections", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["AI startup backs Public First Action to counter industry's anti-regulation push"]}
{"id": "source:rss:2008964308", "title": "Samsung Brings AI to Budget Phones With Galaxy A07 5G Launch", "summary": "Galaxy A07 5G democratizes Google Gemini and Circle to Search in budget lineup", "url": "https://www.techbuzz.ai/articles/samsung-brings-ai-to-budget-phones-with-galaxy-a07-5g-launch", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Galaxy A07 5G democratizes Google Gemini and Circle to Search in budget lineup"]}
{"id": "source:rss:4801775949", "title": "HP ZBook Ultra G1a Packs AMD's Strix Halo Into Business Suit", "summary": "HP's enterprise workstation pairs AMD Ryzen AI Max chips with Thunderbolt 4 and OLED", "url": "https://www.techbuzz.ai/articles/hp-zbook-ultra-g1a-packs-amd-s-strix-halo-into-business-suit", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["HP's enterprise workstation pairs AMD Ryzen AI Max chips with Thunderbolt 4 and OLED"]}
{"id": "source:rss:8100828716", "title": "Russia Blocks WhatsApp, Cuts Off 100M Users in Messaging Crackdown", "summary": "Meta's WhatsApp confirms Russia blocked service affecting 100M users as Kremlin escalates censorship", "url": "https://www.techbuzz.ai/articles/russia-blocks-whatsapp-cuts-off-100m-users-in-messaging-crackdown", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Meta's WhatsApp confirms Russia blocked service affecting 100M users as Kremlin escalates censorship"]}
{"id": "source:rss:1319087875", "title": "Singapore Unveils AI Tax Breaks, Support in 2026 Budget Push", "summary": "Singapore rolls out tax incentives and support measures for companies using AI transformation", "url": "https://www.techbuzz.ai/articles/singapore-unveils-ai-tax-breaks-support-in-2026-budget-push", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Singapore rolls out tax incentives and support measures for companies using AI transformation"]}
{"id": "source:rss:6056440012", "title": "Alphabet Issues Century Bond to Fund AI Capex Blitz", "summary": "Google's parent taps debt markets with rare 100-year bond as AI spending war escalates", "url": "https://www.techbuzz.ai/articles/alphabet-issues-century-bond-to-fund-ai-capex-blitz", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Google's parent taps debt markets with rare 100-year bond as AI spending war escalates"]}
{"id": "source:rss:3641008828", "title": "Google Arts & Culture Drops 3 AI Heritage Tools for India", "summary": "Google launches AI experiences exploring Indian cultural heritage ahead of India AI Summit", "url": "https://www.techbuzz.ai/articles/google-arts-culture-drops-3-ai-heritage-tools-for-india", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Google launches AI experiences exploring Indian cultural heritage ahead of India AI Summit"]}
{"id": "source:rss:3329795715", "title": "CIA Makes New Push To Recruit Chinese Military Officers as Informants", "summary": "An anonymous reader shares a report: Just weeks after a dramatic purge of China's top general, the CIA is moving to capitalize on any resulting discord with a new public video targeting potential info", "url": "https://www.techbuzz.ai/press-release/Slashdot/Slashdot-https%3A%2F%2Fnews.slashdot.org%2Fstory%2F26%2F02%2F12%2F211223%2Fcia-makes-new-push-to-recruit-chinese-military-officers-as-informants%3Futm_source%3Drss1.0mainlinkanon%26utm_medium%3Dfeed", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["An anonymous reader shares a report: Just weeks after a dramatic purge of China's top general, the CIA is moving to capitalize on any resulting discord with a new public video targeting potential info"]}
{"id": "source:rss:5047622418", "title": "IBM Plans To Triple Entry-Level Hiring in the US", "summary": "IBM said it will triple entry-level hiring in the US in 2026, even as AI appears to be weighing on broader demand for early-career workers. From a report: While the company declined to disclose specif", "url": "https://www.techbuzz.ai/press-release/Slashdot/Slashdot-https%3A%2F%2Fslashdot.org%2Fstory%2F26%2F02%2F12%2F214250%2Fibm-plans-to-triple-entry-level-hiring-in-the-us%3Futm_source%3Drss1.0mainlinkanon%26utm_medium%3Dfeed", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["IBM said it will triple entry-level hiring in the US in 2026, even as AI appears to be weighing on broader demand for early-career workers. From a report: While the company declined to disclose specif"]}
{"id": "source:rss:8484275739", "title": "WP Engine Says Automattic Planned To Shake Down 10 Hosting Companies For WordPress Royalties", "summary": "WP Engine's third amended complaint against Automattic and WordPress co-founder Matt Mullenweg alleges that Mullenweg had plans to impose royalty fees on 10 hosting companies beyond WP Engine for thei", "url": "https://www.techbuzz.ai/press-release/Slashdot/Slashdot-https%3A%2F%2Fyro.slashdot.org%2Fstory%2F26%2F02%2F12%2F2055249%2Fwp-engine-says-automattic-planned-to-shake-down-10-hosting-companies-for-wordpress-royalties%3Futm_source%3Drss1.0mainlinkanon%26utm_medium%3Dfeed", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["WP Engine's third amended complaint against Automattic and WordPress co-founder Matt Mullenweg alleges that Mullenweg had plans to impose royalty fees on 10 hosting companies beyond WP Engine for thei"]}
{"id": "source:rss:2332267946", "title": "Anthropic Raises $30 Billion at $380 Billion Valuation, Eyes IPO This Year", "summary": "Anthropic has raised $30 billion in a Series G funding round that values the Claude maker at $380 billion as the company prepares for an initial public offering that could come as early as this year.", "url": "https://www.techbuzz.ai/press-release/Slashdot/Slashdot-https%3A%2F%2Fslashdot.org%2Fstory%2F26%2F02%2F12%2F1931255%2Fanthropic-raises-30-billion-at-380-billion-valuation-eyes-ipo-this-year%3Futm_source%3Drss1.0mainlinkanon%26utm_medium%3Dfeed", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Anthropic has raised $30 billion in a Series G funding round that values the Claude maker at $380 billion as the company prepares for an initial public offering that could come as early as this year."]}
{"id": "source:rss:8131178423", "title": "Palo Alto Chose Not To Tie China To Hacking Campaign For Fear of Retaliation From Beijing", "summary": "An anonymous reader shares a report: Palo Alto Networks opted not to tie China to a global cyberespionage campaign the firm exposed last week over concerns that the cybersecurity company or its client", "url": "https://www.techbuzz.ai/press-release/Slashdot/Slashdot-https%3A%2F%2Fit.slashdot.org%2Fstory%2F26%2F02%2F12%2F196217%2Fpalo-alto-chose-not-to-tie-china-to-hacking-campaign-for-fear-of-retaliation-from-beijing%3Futm_source%3Drss1.0mainlinkanon%26utm_medium%3Dfeed", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["An anonymous reader shares a report: Palo Alto Networks opted not to tie China to a global cyberespionage campaign the firm exposed last week over concerns that the cybersecurity company or its client"]}
{"id": "source:rss:7518511525", "title": "Sources: the Trump administration has shelved tech security measures against China, including data center equipment curbs, ahead of a Trump-Xi meeting in April (Alexandra Alper/Reuters)", "summary": "Alexandra Alper / Reuters: Sources: the Trump administration has shelved tech security measures against China, including data center equipment curbs, ahead of a Trump-Xi meeting in April\u00a0 \u2014\u00a0 The Trump", "url": "https://www.techbuzz.ai/press-release/Techmeme/Techmeme-http%3A%2F%2Fwww.techmeme.com%2F260212%2Fp64%23a260212p64", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Alexandra Alper / Reuters: Sources: the Trump administration has shelved tech security measures against China, including data center equipment curbs, ahead of a Trump-Xi meeting in April\u00a0 \u2014\u00a0 The Trump"]}
{"id": "source:rss:4610979685", "title": "Greenberg Traurig Announces Elevations of New Shareholders, Of Counsels, and Local Partners", "summary": "NEW YORK, Feb. 12, 2026 /PRNewswire/ -- Global law firm Greenberg Traurig, LLP today announced the elevation of 91 lawyers to shareholder, of counsel, and local partner. The 57 new shareholders span 2", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fgreenberg-traurig-announces-elevations-of-new-shareholders-of-counsels-and-local-partners-302687103.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["NEW YORK, Feb. 12, 2026 /PRNewswire/ -- Global law firm Greenberg Traurig, LLP today announced the elevation of 91 lawyers to shareholder, of counsel, and local partner. The 57 new shareholders span 2"]}
{"id": "source:rss:2111296739", "title": "Global Times: A French girl living in Beijing's hutongs", "summary": "BEIJING, Feb. 12, 2026 /PRNewswire/ -- This year marks the 105th anniversary of the founding of the Communist Party of China (CPC) and the opening year of the 15th Five-Year Plan (2026-30). A new year", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fglobal-times-a-french-girl-living-in-beijings-hutongs-302687126.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["BEIJING, Feb. 12, 2026 /PRNewswire/ -- This year marks the 105th anniversary of the founding of the Communist Party of China (CPC) and the opening year of the 15th Five-Year Plan (2026-30). A new year"]}
{"id": "source:rss:6464584858", "title": "Global Times: 'Sister Wu' sells vegetables by 'slow train'", "summary": "BEIJING, Feb. 12, 2026 /PRNewswire/ -- \"Sister Wu, can live chickens be taken on the train?\" At daybreak in the Miaoling Mountains, Southwest China's Guizhou Province, vegetable vendor Sister Wu began", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fglobal-times-sister-wu-sells-vegetables-by-slow-train-302687124.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["BEIJING, Feb. 12, 2026 /PRNewswire/ -- \"Sister Wu, can live chickens be taken on the train?\" At daybreak in the Miaoling Mountains, Southwest China's Guizhou Province, vegetable vendor Sister Wu began"]}
{"id": "source:rss:5766671334", "title": "Elder Clark G. Gilbert Is Called to the Quorum of the Twelve Apostles", "summary": "SALT LAKE CITY, Feb. 12, 2026 /PRNewswire/ -- Elder Clark G. Gilbert is the newest member of the Quorum of the Twelve Apostles of The Church of Jesus Christ of Latter-day Saints. He was called on Wedn", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Felder-clark-g-gilbert-is-called-to-the-quorum-of-the-twelve-apostles-302687121.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["SALT LAKE CITY, Feb. 12, 2026 /PRNewswire/ -- Elder Clark G. Gilbert is the newest member of the Quorum of the Twelve Apostles of The Church of Jesus Christ of Latter-day Saints. He was called on Wedn"]}
{"id": "source:rss:6145634708", "title": "Amazon's Ring cancels its partnership with Flock that would have let law enforcement agencies request footage from Ring doorbell users, following backlash (Jennifer Pattison Tuohy/The Verge)", "summary": "Jennifer Pattison Tuohy / The Verge: Amazon's Ring cancels its partnership with Flock that would have let law enforcement agencies request footage from Ring doorbell users, following backlash\u00a0 \u2014\u00a0 Afte", "url": "https://www.techbuzz.ai/press-release/Techmeme/Techmeme-http%3A%2F%2Fwww.techmeme.com%2F260212%2Fp63%23a260212p63", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Jennifer Pattison Tuohy / The Verge: Amazon's Ring cancels its partnership with Flock that would have let law enforcement agencies request footage from Ring doorbell users, following backlash\u00a0 \u2014\u00a0 Afte"]}
{"id": "source:rss:2880125835", "title": "The Poet Marketer: How Emily K. Bergquist\u2019s Literary Training Shapes Digital Strategy", "summary": "Today\u2019s digital environment is crowded. Audiences now often scroll past content that feels staged or overly polished. Fortunately, this glut of inauthenticity has left the door wide open for human and", "url": "https://www.techbuzz.ai/press-release/Grit Daily/Grit%20Daily-https%3A%2F%2Fgritdaily.com%2F%3Fp%3D174073", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Today\u2019s digital environment is crowded. Audiences now often scroll past content that feels staged or overly polished. Fortunately, this glut of inauthenticity has left the door wide open for human and"]}
{"id": "source:rss:3531520858", "title": "The only lithium button battery brand I recommend now - for serious safety reasons", "summary": "Button cell battery ingestion leads to thousands of injuries in the US each year. Here's the only brand I trust now.", "url": "https://www.techbuzz.ai/press-release/ZDNet/ZDNet-ecb05033-cf10-414b-af31-c14824a824be", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Button cell battery ingestion leads to thousands of injuries in the US each year. Here's the only brand I trust now."]}
{"id": "source:rss:6602007608", "title": "Samsung unveils enticing Galaxy S26 deal for $900 off ahead of February Unpacked", "summary": "Samsung's newest products will be unveiled on February 25, but you can already score a discount with this reservation offer.", "url": "https://www.techbuzz.ai/press-release/ZDNet/ZDNet-12e9e9cb-a6a5-4275-abf1-40cfc691995f", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Samsung's newest products will be unveiled on February 25, but you can already score a discount with this reservation offer."]}
{"id": "source:rss:3555974709", "title": "Kyndryl to Modernize Yamaguchi Financial Group's Core Banking System into a Multi\u2011Bank Platform", "summary": "TOKYO, Feb. 12, 2026 /PRNewswire/ -- Kyndryl (NYSE: KD), a leading provider of mission-critical enterprise technology services, today announced that it will support Yamaguchi Financial Group (Yamaguch", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fkyndryl-to-modernize-yamaguchi-financial-groups-core-banking-system-into-a-multibank-platform-302686764.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["TOKYO, Feb. 12, 2026 /PRNewswire/ -- Kyndryl (NYSE: KD), a leading provider of mission-critical enterprise technology services, today announced that it will support Yamaguchi Financial Group (Yamaguch"]}
{"id": "source:rss:4459070319", "title": "GreenPower Reports Revenue of $8.5 million and Net Income of $4.2 million for Third Quarter", "summary": "VANCOUVER, BC, Feb. 12, 2026 /PRNewswire/ -- GreenPower Motor Company Inc. (Nasdaq: GP) (\"GreenPower\" and the \"Company\"), a leading manufacturer and distributor of all-electric, purpose-built, zero-em", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fgreenpower-reports-revenue-of-8-5-million-and-net-income-of-4-2-million-for-third-quarter-302687117.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["VANCOUVER, BC, Feb. 12, 2026 /PRNewswire/ -- GreenPower Motor Company Inc. (Nasdaq: GP) (\"GreenPower\" and the \"Company\"), a leading manufacturer and distributor of all-electric, purpose-built, zero-em"]}
{"id": "source:rss:5775397835", "title": "Skip the Tips: A game to select \"No Tip\" but dark patterns try to stop you", "summary": "Comments", "url": "https://www.techbuzz.ai/press-release/Hacker News/Hacker%20News-https%3A%2F%2Fskipthe.tips%2F", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Comments"]}
{"id": "source:rss:8218317713", "title": "Zoomlion to Showcase Intelligent Construction Solutions and Flagship Equipment at CONEXPO-CON/AGG 2026", "summary": "LAS VEGAS, Feb. 12, 2026 /PRNewswire/ -- Zoomlion Heavy Industry Science & Technology Co., Ltd. (\"Zoomlion\" or \"the Company\"; 1157.HK) has announced its participation in CONEXPO-CON/AGG 2026, one of t", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fzoomlion-to-showcase-intelligent-construction-solutions-and-flagship-equipment-at-conexpo-conagg-2026-302687111.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["LAS VEGAS, Feb. 12, 2026 /PRNewswire/ -- Zoomlion Heavy Industry Science & Technology Co., Ltd. (\"Zoomlion\" or \"the Company\"; 1157.HK) has announced its participation in CONEXPO-CON/AGG 2026, one of t"]}
{"id": "source:rss:1164320420", "title": "Weyerhaeuser Company Declares Dividend on Common Shares", "summary": "SEATTLE, Feb. 12, 2026 /PRNewswire/ -- Weyerhaeuser Company (NYSE: WY) today announced that its board of directors declared a quarterly base cash dividend of $0.21 per share on the common stock of the", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fweyerhaeuser-company-declares-dividend-on-common-shares-302687106.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["SEATTLE, Feb. 12, 2026 /PRNewswire/ -- Weyerhaeuser Company (NYSE: WY) today announced that its board of directors declared a quarterly base cash dividend of $0.21 per share on the common stock of the"]}
{"id": "source:rss:8282918735", "title": "ORVANA ANNOUNCES RESULTS OF ANNUAL GENERAL SHAREHOLDERS' MEETING", "summary": "TSX:ORV TORONTO, Feb. 12, 2026 /PRNewswire/ - Orvana Minerals Corp. (TSX: ORV) (the \"Company\" or \"Orvana\") is pleased to report the results of its annual general shareholders' meeting (the \"Meeting\")", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Forvana-announces-results-of-annual-general-shareholders-meeting-302687063.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["TSX:ORV TORONTO, Feb. 12, 2026 /PRNewswire/ - Orvana Minerals Corp. (TSX: ORV) (the \"Company\" or \"Orvana\") is pleased to report the results of its annual general shareholders' meeting (the \"Meeting\")"]}
{"id": "source:rss:5874987216", "title": "Outten &amp; Golden Analyzes SEC Whistleblower Program Results for FY 2025: Whistleblowers Continue to Level the Playing Field for Investors and Promote Market Integrity", "summary": "NEW YORK, Feb. 12, 2026 /PRNewswire/ -- The Securities and Exchange Commission (SEC) today released its Annual Report to Congress on the Dodd-Frank Whistleblower Program for Fiscal Year 2025, which de", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Foutten--golden-analyzes-sec-whistleblower-program-results-for-fy-2025-whistleblowers-continue-to-level-the-playing-field-for-investors-and-promote-market-integrity-302687100.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["NEW YORK, Feb. 12, 2026 /PRNewswire/ -- The Securities and Exchange Commission (SEC) today released its Annual Report to Congress on the Dodd-Frank Whistleblower Program for Fiscal Year 2025, which de"]}
{"id": "source:rss:8197557821", "title": "POM Investors Have Opportunity to Lead PomDoctor Ltd. Securities Fraud Lawsuit", "summary": "NEW YORK, Feb. 12, 2026 /PRNewswire/ -- Why: Rosen Law Firm, a global investor rights law firm, announces a class action lawsuit on behalf of purchasers of securities of PomDoctor Ltd. (NASDAQ: POM) b", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fpom-investors-have-opportunity-to-lead-pomdoctor-ltd-securities-fraud-lawsuit-302687077.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["NEW YORK, Feb. 12, 2026 /PRNewswire/ -- Why: Rosen Law Firm, a global investor rights law firm, announces a class action lawsuit on behalf of purchasers of securities of PomDoctor Ltd. (NASDAQ: POM) b"]}
{"id": "source:rss:7233447770", "title": "CARsgen Signs Strategic Cooperation Agreements to Expand CAR-T Commercial Manufacturing Base in Jinshan, Shanghai", "summary": "SHANGHAI, Feb. 12, 2026 /PRNewswire/ -- CARsgen Therapeutics Holdings Limited (Stock Code: 2171.HK), a company focused on developing innovative CAR T-cell therapies, announces that through its indirec", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fcarsgen-signs-strategic-cooperation-agreements-to-expand-car-t-commercial-manufacturing-base-in-jinshan-shanghai-302686595.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["SHANGHAI, Feb. 12, 2026 /PRNewswire/ -- CARsgen Therapeutics Holdings Limited (Stock Code: 2171.HK), a company focused on developing innovative CAR T-cell therapies, announces that through its indirec"]}
{"id": "source:rss:6968310496", "title": "Cloudflare turns websites into faster food for AI agents", "summary": "Read the latest press release: Cloudflare turns websites into faster food for AI agents", "url": "https://www.techbuzz.ai/press-release/The Register/The%20Register-https%3A%2F%2Fgo.theregister.com%2Ffeed%2Fwww.theregister.com%2F2026%2F02%2F13%2Fcloudflare_markdown_for_ai_crawlers%2F", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Read the latest press release: Cloudflare turns websites into faster food for AI agents"]}
{"id": "source:rss:2848039003", "title": "AWS Adds support for nested virtualization", "summary": "Comments", "url": "https://www.techbuzz.ai/press-release/Hacker News/Hacker%20News-https%3A%2F%2Fgithub.com%2Faws%2Faws-sdk-go-v2%2Fcommit%2F3dca5e45d5ad05460b93410087833cbaa624754e", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Comments"]}
{"id": "source:rss:7783385977", "title": "AI to make call center agents 'superheroes,' not unemployed, says industry CEO", "summary": "Read the latest press release: AI to make call center agents 'superheroes,' not unemployed, says industry CEO", "url": "https://www.techbuzz.ai/press-release/The Register/The%20Register-https%3A%2F%2Fgo.theregister.com%2Ffeed%2Fwww.theregister.com%2F2026%2F02%2F13%2Fcall_center_ai_superheroes%2F", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Read the latest press release: AI to make call center agents 'superheroes,' not unemployed, says industry CEO"]}
{"id": "source:rss:1394863040", "title": "Apple's stock dropped 5% on Thursday, its worst day since April, following FTC scrutiny of Apple News and reports about delays with Siri (Jennifer Elias/CNBC)", "summary": "Jennifer Elias / CNBC: Apple's stock dropped 5% on Thursday, its worst day since April, following FTC scrutiny of Apple News and reports about delays with Siri\u00a0 \u2014\u00a0 Apple just wrapped up its worst day", "url": "https://www.techbuzz.ai/press-release/Techmeme/Techmeme-http%3A%2F%2Fwww.techmeme.com%2F260212%2Fp62%23a260212p62", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Jennifer Elias / CNBC: Apple's stock dropped 5% on Thursday, its worst day since April, following FTC scrutiny of Apple News and reports about delays with Siri\u00a0 \u2014\u00a0 Apple just wrapped up its worst day"]}
{"id": "source:rss:2852408766", "title": "PAN GLOBAL FILES NI 43-101 TECHNICAL REPORT FOR INITIAL MINERAL RESOURCE ESTIMATES AT THE ESCACENA PROJECT, SOUTHERN SPAIN", "summary": "TSXV: PGZ | OTCQB: PGZFF | FRA: 2EU VANCOUVER, BC, Feb. 13, 2026 /PRNewswire/ -- Pan Global Resources Inc. (\"Pan Global\" or the \"Company\") (TSXV: PGZ) (OTCQB: PGZFF) (FRA: 2EU) is pleased to announce", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fpan-global-files-ni-43-101-technical-report-for-initial-mineral-resource-estimates-at-the-escacena-project-southern-spain-302687093.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["TSXV: PGZ | OTCQB: PGZFF | FRA: 2EU VANCOUVER, BC, Feb. 13, 2026 /PRNewswire/ -- Pan Global Resources Inc. (\"Pan Global\" or the \"Company\") (TSXV: PGZ) (OTCQB: PGZFF) (FRA: 2EU) is pleased to announce"]}
{"id": "source:rss:1862028837", "title": "ArtCreativity Acquires Heritage Classic Wooly Willy\u00ae Brand from PlayMonster Group", "summary": "NEW HAMPTON, N.Y., Feb. 12, 2026 /PRNewswire/ -- ArtCreativity announced today the acquisition of the iconic Wooly Willy\u00ae brand from PlayMonster Group, bringing one of the toy industry's longest-stand", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fartcreativity-acquires-heritage-classic-wooly-willy-brand-from-playmonster-group-302687084.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["NEW HAMPTON, N.Y., Feb. 12, 2026 /PRNewswire/ -- ArtCreativity announced today the acquisition of the iconic Wooly Willy\u00ae brand from PlayMonster Group, bringing one of the toy industry's longest-stand"]}
{"id": "source:rss:5582521644", "title": "Innovent Dosed First Participant in Phase 3 Clinical Study of IBI354 (Novel HER2 ADC) for First Line Treatment of HER2-positive Breast Cancer", "summary": "SAN FRANCISCO and SUZHOU, China, Feb. 12, 2026 /PRNewswire/ -- Innovent Biologics, Inc. (\"Innovent\",HKEX: 01801), a world-class biopharmaceutical company that develops, manufactures and commercializes", "url": "https://www.techbuzz.ai/press-release/PRNewsWire/PRNewsWire-https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Finnovent-dosed-first-participant-in-phase-3-clinical-study-of-ibi354-novel-her2-adc-for-first-line-treatment-of-her2-positive-breast-cancer-302686402.html", "published_at": "Fri, 13 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["SAN FRANCISCO and SUZHOU, China, Feb. 12, 2026 /PRNewswire/ -- Innovent Biologics, Inc. (\"Innovent\",HKEX: 01801), a world-class biopharmaceutical company that develops, manufactures and commercializes"]}
{"id": "source:rss:2040007565", "title": "The Download: AI-enhanced cybercrime, and secure AI assistants", "summary": "This is today&#8217;s edition of\u00a0The Download,\u00a0our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. AI is already making online crimes easier. It could get much worse. Just as software engineers are using artificial intelligence to help write code and check for bugs, hackers are using these tools&#8230;", "url": "https://www.technologyreview.com/2026/02/12/1132819/the-download-ai-enhanced-cybercrime-and-secure-ai-assistants/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["This is today&#8217;s edition of\u00a0The Download,\u00a0our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. AI is already making online crimes easier. It could get much worse. Just as software engineers are using artificial intelligence to help write code an"]}
{"id": "source:rss:5014619162", "title": "AI is already making online crimes easier. It could get much worse.", "summary": "Anton Cherepanov is always on the lookout for something interesting. And in late August last year, he spotted just that. It was a file uploaded to VirusTotal, a site cybersecurity researchers like him use to analyze submissions for potential viruses and other types of malicious software, often known as malware. On the surface it seemed&#8230;", "url": "https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Anton Cherepanov is always on the lookout for something interesting. And in late August last year, he spotted just that. It was a file uploaded to VirusTotal, a site cybersecurity researchers like him use to analyze submissions for potential viruses and other types of malicious software, often known"]}
{"id": "source:rss:6693617644", "title": "Why EVs are gaining ground in Africa", "summary": "EVs are getting cheaper and more common all over the world. But the technology still faces major challenges in some markets, including many countries in Africa. Some regions across the continent still have limited grid and charging infrastructure, and those that do have widespread electricity access sometimes face reliability issues\u2014a problem for EV owners, who&#8230;", "url": "https://www.technologyreview.com/2026/02/12/1132790/evs-progress-africa/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["EVs are getting cheaper and more common all over the world. But the technology still faces major challenges in some markets, including many countries in Africa. Some regions across the continent still have limited grid and charging infrastructure, and those that do have widespread electricity access"]}
{"id": "source:rss:3556486917", "title": "What\u2019s next for Chinese open-source AI", "summary": "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them&#160;here. The past year has marked a turning point for Chinese AI. Since DeepSeek released its R1 reasoning model in January 2025, Chinese companies have repeatedly delivered AI&#8230;", "url": "https://www.technologyreview.com/2026/02/12/1132811/whats-next-for-chinese-open-source-ai/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them&#160;here. The past year has marked a turning point for Chinese AI. Since DeepSeek released its R1 reasoning model in January 2025, Chine"]}
{"id": "source:rss:7869336907", "title": "Is a secure AI assistant possible?", "summary": "AI agents are a risky business. Even when stuck inside the chatbox window, LLMs will make mistakes and behave badly. Once they have tools that they can use to interact with the outside world, such as web browsers and email addresses, the consequences of those mistakes become far more serious. That might explain why the&#8230;", "url": "https://www.technologyreview.com/2026/02/11/1132768/is-a-secure-ai-assistant-possible/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["AI agents are a risky business. Even when stuck inside the chatbox window, LLMs will make mistakes and behave badly. Once they have tools that they can use to interact with the outside world, such as web browsers and email addresses, the consequences of those mistakes become far more serious. That m"]}
{"id": "source:rss:6872269742", "title": "The Download: inside the QuitGPT movement, and EVs in Africa", "summary": "This is today&#8217;s edition of\u00a0The Download,\u00a0our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. A \u201cQuitGPT\u201d campaign is urging people to cancel their ChatGPT subscriptions In September, Alfred Stephen, a freelance software developer in Singapore, purchased a ChatGPT Plus subscription, which costs $20 a month and offers&#8230;", "url": "https://www.technologyreview.com/2026/02/11/1132724/the-download-inside-the-quitgpt-movement-and-evs-in-africa/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["This is today&#8217;s edition of\u00a0The Download,\u00a0our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. A \u201cQuitGPT\u201d campaign is urging people to cancel their ChatGPT subscriptions In September, Alfred Stephen, a freelance software developer in Singapore,"]}
{"id": "source:rss:7198567802", "title": "EVs could be cheaper to own than gas cars in Africa by 2040", "summary": "Electric vehicles could be economically competitive in Africa sooner than expected. Just 1% of new cars sold across the continent in 2025 were electric, but a new analysis finds that with solar off-grid charging, EVs could be cheaper to own than gas vehicles by 2040. There are major barriers to higher EV uptake in many&#8230;", "url": "https://www.technologyreview.com/2026/02/11/1132714/evs-africa-cost/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Electric vehicles could be economically competitive in Africa sooner than expected. Just 1% of new cars sold across the continent in 2025 were electric, but a new analysis finds that with solar off-grid charging, EVs could be cheaper to own than gas vehicles by 2040. There are major barriers to high"]}
{"id": "source:rss:4668292122", "title": "A \u201cQuitGPT\u201d campaign is urging people to cancel their ChatGPT subscriptions", "summary": "In September, Alfred Stephen, a freelance software developer in Singapore, purchased a ChatGPT Plus subscription, which costs $20 a month and offers more access to advanced models, to speed up his work. But he grew frustrated with the chatbot\u2019s coding abilities and its gushing, meandering replies. Then he came across a post on Reddit about&#8230;", "url": "https://www.technologyreview.com/2026/02/10/1132577/a-quitgpt-campaign-is-urging-people-to-cancel-chatgpt-subscriptions/", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["In September, Alfred Stephen, a freelance software developer in Singapore, purchased a ChatGPT Plus subscription, which costs $20 a month and offers more access to advanced models, to speed up his work. But he grew frustrated with the chatbot\u2019s coding abilities and its gushing, meandering replies. T"]}
{"id": "source:rss:8658098314", "title": "The Download: Making AI Work, and why the Moltbook hype is similar to Pok\u00e9mon", "summary": "This is today&#8217;s edition of\u00a0The Download,\u00a0our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. A first look at Making AI Work, MIT Technology Review\u2019s new AI newsletter Are you interested in learning more about the ways in which AI is actually being used? We\u2019ve launched a new&#8230;", "url": "https://www.technologyreview.com/2026/02/10/1132608/the-download-making-ai-work-and-why-the-moltbook-hype-is-similar-to-pokemon/", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["This is today&#8217;s edition of\u00a0The Download,\u00a0our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. A first look at Making AI Work, MIT Technology Review\u2019s new AI newsletter Are you interested in learning more about the ways in which AI is actually b"]}
{"id": "source:rss:8824476195", "title": "Why the Moltbook frenzy was like Pok\u00e9mon", "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show&#8230;", "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse in"]}
{"id": "source:rss:5014619162", "title": "AI is already making online crimes easier. It could get much worse.", "summary": "Anton Cherepanov is always on the lookout for something interesting. And in late August last year, he spotted just that. It was a file uploaded to VirusTotal, a site cybersecurity researchers like him use to analyze submissions for potential viruses and other types of malicious software, often known as malware. On the surface it seemed&#8230;", "url": "https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Anton Cherepanov is always on the lookout for something interesting. And in late August last year, he spotted just that. It was a file uploaded to VirusTotal, a site cybersecurity researchers like him use to analyze submissions for potential viruses and other types of malicious software, often known"]}
{"id": "source:rss:3556486917", "title": "What\u2019s next for Chinese open-source AI", "summary": "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them&#160;here. The past year has marked a turning point for Chinese AI. Since DeepSeek released its R1 reasoning model in January 2025, Chinese companies have repeatedly delivered AI&#8230;", "url": "https://www.technologyreview.com/2026/02/12/1132811/whats-next-for-chinese-open-source-ai/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them&#160;here. The past year has marked a turning point for Chinese AI. Since DeepSeek released its R1 reasoning model in January 2025, Chine"]}
{"id": "source:rss:7869336907", "title": "Is a secure AI assistant possible?", "summary": "AI agents are a risky business. Even when stuck inside the chatbox window, LLMs will make mistakes and behave badly. Once they have tools that they can use to interact with the outside world, such as web browsers and email addresses, the consequences of those mistakes become far more serious. That might explain why the&#8230;", "url": "https://www.technologyreview.com/2026/02/11/1132768/is-a-secure-ai-assistant-possible/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["AI agents are a risky business. Even when stuck inside the chatbox window, LLMs will make mistakes and behave badly. Once they have tools that they can use to interact with the outside world, such as web browsers and email addresses, the consequences of those mistakes become far more serious. That m"]}
{"id": "source:rss:4668292122", "title": "A \u201cQuitGPT\u201d campaign is urging people to cancel their ChatGPT subscriptions", "summary": "In September, Alfred Stephen, a freelance software developer in Singapore, purchased a ChatGPT Plus subscription, which costs $20 a month and offers more access to advanced models, to speed up his work. But he grew frustrated with the chatbot\u2019s coding abilities and its gushing, meandering replies. Then he came across a post on Reddit about&#8230;", "url": "https://www.technologyreview.com/2026/02/10/1132577/a-quitgpt-campaign-is-urging-people-to-cancel-chatgpt-subscriptions/", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["In September, Alfred Stephen, a freelance software developer in Singapore, purchased a ChatGPT Plus subscription, which costs $20 a month and offers more access to advanced models, to speed up his work. But he grew frustrated with the chatbot\u2019s coding abilities and its gushing, meandering replies. T"]}
{"id": "source:rss:8824476195", "title": "Why the Moltbook frenzy was like Pok\u00e9mon", "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show&#8230;", "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse in"]}
{"id": "source:rss:3433682648", "title": "Making AI Work, MIT Technology Review\u2019s new AI newsletter, is here", "summary": "For years, our newsroom has explored AI\u2019s limitations and potential dangers, as well as its growing energy needs. And our reporters have looked closely at how generative tools are being used for tasks such as coding and running scientific experiments.&#160; But how is AI actually being used in fields like health care, climate tech, education,&#8230;", "url": "https://www.technologyreview.com/2026/02/09/1132462/ai-newsletter-professional-applications/", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["For years, our newsroom has explored AI\u2019s limitations and potential dangers, as well as its growing energy needs. And our reporters have looked closely at how generative tools are being used for tasks such as coding and running scientific experiments.&#160; But how is AI actually being used in field"]}
{"id": "source:rss:8050852156", "title": "Moltbook was peak AI theater", "summary": "For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website\u2019s tagline puts it: \u201cWhere AI agents share, discuss, and upvote. Humans welcome to observe.\u201d We observed! Launched on January 28 by Matt Schlicht,&#8230;", "url": "https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/", "published_at": "Fri, 06 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website\u2019s tagline puts it: \u201cWhere AI agents share, discuss, and upvote. Humans welcome to observe.\u201d We observed! Launched on Januar"]}
{"id": "source:rss:4975504048", "title": "This is the most misunderstood graph in AI", "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what\u2019s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn\u2019t exhale until METR, an AI&#8230;", "url": "https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what\u2019s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It "]}
{"id": "source:rss:6238898206", "title": "From guardrails to governance: A CEO\u2019s guide for securing agentic systems", "summary": "The previous article in this series, \u201cRules fail at the prompt, succeed at the boundary,\u201d focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of: What do we do about agent risk? Across&#8230;", "url": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/", "published_at": "Wed, 04 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["governance"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The previous article in this series, \u201cRules fail at the prompt, succeed at the boundary,\u201d focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of: What"]}
{"id": "source:rss:2098807501", "title": "What we\u2019ve been getting wrong about AI\u2019s truth crisis", "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. What would it take to convince you that the era of truth decay we were long warned about\u2014where AI content dupes us, shapes our beliefs even when we catch the lie, and&#8230;", "url": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/", "published_at": "Mon, 02 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. What would it take to convince you that the era of truth decay we were long warned about\u2014where AI content dupes us, shapes our beliefs even when we catch the"]}
{"id": "source:rss:6637584481", "title": "Nvidia\u2019s new technique cuts LLM reasoning costs by 8x without losing accuracy", "summary": "<p>Researchers at Nvidia have developed a technique that can reduce the memory costs of large language model reasoning by up to eight times. Their technique, called <a href=\"https://arxiv.org/abs/2506.05345\"><u>dynamic memory sparsification</u></a> (DMS), compresses the key value (KV) cache, the temporary memory LLMs generate and store as they process prompts and reason through problems and documents.</p><p>While researchers have proposed various methods to compress this cache before, most struggle to do so without degrading the model&#x27;s intelligence. Nvidia&#x27;s approach manages to discard much of the cache while maintaining (and in some cases improving) the model&#x27;s reasoning capabilities.</p><p>Experiments show that DMS enables LLMs to &quot;think&quot; longer and explore more solutions without the usual penalty in speed or memory costs.</p><h2>The bottleneck of reasoning</h2><p>LLMs improve their performance on complex tasks by generating &quot;<a href=\"https://venturebeat.com/ai/dont-believe-reasoning-models-chains-of-thought-says-anthropic\"><u>chain-of-thought</u></a>&quot; tokens, essentially writing out their reasoning steps before arriving at a final answer. Inference-time scaling techniques leverage this by giving the model a larger budget to generate these thinking tokens or to explore multiple potential reasoning paths in parallel.</p><p>However, this improved reasoning comes with a significant computational cost. As the model generates more tokens, it builds up a <a href=\"https://venturebeat.com/ai/mixture-of-recursions-delivers-2x-faster-inference-heres-how-to-implement-it\"><u>KV cache</u></a>. </p><p>For real-world applications, the KV cache is a major bottleneck. As the reasoning chain grows, the cache grows linearly, consuming vast amounts of memory on GPUs. This forces the hardware to spend more time reading data from memory than actually computing, which slows down generation and increases latency. It also caps the number of users a system can serve simultaneously, as running out of VRAM causes the system to crash or slow to a crawl.</p><p>Nvidia researchers frame this not just as a technical hurdle, but as a fundamental economic one for the enterprise.</p><p>&quot;The question isn&#x27;t just about hardware quantity; it&#x27;s about whether your infrastructure is processing 100 reasoning threads or 800 threads for the same cost,&quot; Piotr Nawrot, Senior Deep Learning Engineer at Nvidia, told VentureBeat.</p><p>Previous attempts to solve this focused on heuristics-based approaches. These methods use rigid rules, such as a &quot;sliding window&quot; that only caches the most recent tokens and deletes the rest. While this reduces memory usage, it often forces the model to discard critical information required for solving the problem, degrading the accuracy of the output.</p><p>&quot;Standard eviction methods attempt to select old and unused tokens for eviction using heuristics,&quot; the researchers said. &quot;They simplify the problem, hoping that if they approximate the model&#x27;s internal mechanics, the answer will remain correct.&quot;</p><p>Other solutions use paging to offload the unused parts of the KV cache to slower memory, but the constant swapping of data introduces latency overhead that makes real-time applications sluggish.</p><h2>Dynamic memory sparsification</h2><p>DMS takes a different approach by &quot;retrofitting&quot; existing LLMs to intelligently manage their own memory. Rather than applying a fixed rule for what to delete, DMS trains the model to identify which tokens are essential for future reasoning and which are disposable.</p><p>&quot;It doesn&#x27;t just guess importance; it learns a policy that explicitly preserves the model&#x27;s final output distribution,&quot; Nawrot said.</p><p>The process transforms a standard, pre-trained LLM such as Llama 3 or Qwen 3 into a self-compressing model. Crucially, this does not require training the model from scratch, which would be prohibitively expensive. Instead, DMS repurposes existing neurons within the model\u2019s attention layers to output a &quot;keep&quot; or &quot;evict&quot; signal for each token.</p><p>For teams worried about the complexity of retrofitting, the researchers noted that the process is designed to be lightweight. &quot;To improve the efficiency of this process, the model&#x27;s weights can be frozen, which makes the process similar to Low-Rank Adaptation (LoRA),&quot; Nawrot said. This means a standard enterprise model like Qwen3-8B &quot;can be retrofitted with DMS within hours on a single DGX H100.&quot;</p><p>One of the important parts of DMS is a mechanism called &quot;delayed eviction.&quot; In standard sparsification, if a token is deemed unimportant, it is deleted immediately. This is risky because the model might need a split second to integrate that token&#x27;s context into its current state.</p><p>DMS mitigates this by flagging a token for eviction but keeping it accessible for a short window of time (e.g., a few hundred steps). This delay allows the model to &quot;extract&quot; any remaining necessary information from the token and merge it into the current context before the token is wiped from the KV cache.</p><p>\u201cThe \u2018delayed eviction\u2019 mechanism is crucial because not all tokens are simply \u2018important\u2019 (keep forever) or \u2018useless\u2019 (delete immediately). Many fall in between \u2014 they carry some information, but not enough to justify occupying an entire slot in memory,\u201d Nawrot said. \u201cThis is where the redundancy lies. By keeping these tokens in a local window for a short time before eviction, we allow the model to attend to them and redistribute their information into future tokens.\u201d</p><p>The researchers found that this retrofitting process is highly efficient. They could equip a pre-trained LLM with DMS in just 1,000 training steps, a tiny fraction of the compute required for the original training. The resulting models use standard kernels and can drop directly into existing high-performance inference stacks without custom hardware or complex software rewriting.</p><h2>DMS in action</h2><p>To validate the technique, the researchers applied DMS to several reasoning models, including the Qwen-R1 series (distilled from DeepSeek R1) and Llama 3.2, and tested them on difficult benchmarks like AIME 24 (math), GPQA Diamond (science), and LiveCodeBench (coding).</p><p>The results show that DMS effectively moves the Pareto frontier, the optimal trade-off between cost and performance. On the AIME 24 math benchmark, a Qwen-R1 32B model equipped with DMS achieved a score 12.0 points higher than a standard model when constrained to the same memory bandwidth budget. By compressing the cache, the model could afford to &quot;think&quot; much deeper and wider than the standard model could for the same memory and compute budget.</p><p>Perhaps most surprisingly, DMS defied the common wisdom that compression hurts long-context understanding. In &quot;needle-in-a-haystack&quot; tests, which measure a model&#x27;s ability to find a specific piece of information buried in a large document, DMS variants actually outperformed the standard models. By actively managing its memory rather than passively accumulating noise, the model maintained a cleaner, more useful context.</p><p>For enterprise infrastructure, the efficiency gains translate directly to throughput and hardware savings. Because the memory cache is significantly smaller, the GPU spends less time fetching data, reducing the wait time for users. In tests with the Qwen3-8B model, DMS matched the accuracy of the vanilla model while delivering up to 5x higher throughput. This means a single server can handle five times as many customer queries per second without a drop in quality.</p><h2>The future of memory</h2><p>Nvidia has released DMS as part of its <a href=\"https://github.com/NVIDIA/kvpress\"><u>KVPress library</u></a>. Regarding how enterprises can get started with DMS, Nawrot emphasized that the barrier to entry is low. &quot;The &#x27;minimum viable infrastructure&#x27; is standard Hugging Face pipelines \u2014 no custom CUDA kernels are required,&quot; Nawrot said, noting that the code is fully compatible with standard FlashAttention.\u00a0</p><p>Looking ahead, the team views DMS as part of a larger shift where memory management becomes a distinct, intelligent layer of the AI stack. Nawrot also confirmed that DMS is &quot;fully compatible&quot; with newer architectures like the <a href=\"https://bdtechtalks.com/2025/04/07/deepseek-innovations/\"><u>Multi-Head Latent Attention</u></a> (MLA) used in DeepSeek\u2019s models, suggesting that combining these approaches could yield even greater efficiency gains.</p><p>As enterprises move from simple chatbots to complex agentic systems that require extended reasoning, the cost of inference is becoming a primary concern. Techniques like DMS provide a path to scale these capabilities sustainably.</p><p>&quot;We\u2019ve barely scratched the surface of what is possible,&quot; Nawrot said, &quot;and we expect inference-time scaling to further evolve.&quot; </p>", "url": "https://venturebeat.com/orchestration/nvidias-new-technique-cuts-llm-reasoning-costs-by-8x-without-losing-accuracy", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Researchers at Nvidia have developed a technique that can reduce the memory costs of large language model reasoning by up to eight times. Their technique, called <a href=\"https://arxiv.org/abs/2506.05345\"><u>dynamic memory sparsification</u></a> (DMS), compresses the key value (KV) cache, the tem"]}
{"id": "source:rss:6491291968", "title": "MiniMax's new open M2.5 and M2.5 Lightning near state-of-the-art while costing 1/20th of Claude Opus 4.6", "summary": "<p>Chinese AI startup <a href=\"https://www.minimax.io/news/minimax-m25\">MiniMax</a>, headquartered in Shanghai, has sent shockwaves through the AI industry today with the release of its new<a href=\"https://www.minimax.io/news/minimax-m25\"> M2.5 language model</a> in two variants, which promise to make high-end artificial intelligence so cheap you might stop worrying about the bill entirely. </p><p>It&#x27;s also said to be &quot;<a href=\"https://x.com/MiniMax_AI/status/2021980761210134808\">open source</a>,&quot; though the weights (settings) and code haven&#x27;t been posted yet, nor has the exact license type or terms. But that&#x27;s almost beside the point given how cheap MiniMax is serving it through its API and those of partners.</p><p>For the last few years, using the world\u2019s most powerful AI was like hiring an expensive consultant\u2014it was brilliant, but you watched the clock (and the token count) constantly. M2.5 changes that math, <b>dropping the cost of the frontier by as much as 95%.</b></p><div></div><p>By delivering performance that rivals the top-tier models from Google and Anthropic at a fraction of the cost,  particularly in agentic tool use for enterprise tasks, including <b>creating Microsoft Word, Excel and PowerPoint files</b>, MiniMax is betting that the future isn&#x27;t just about how smart a model is, but how often you can afford to use it.</p><p>Indeed, to this end, MiniMax says it worked &quot;with senior professionals in fields such as finance, law, and social sciences&quot; to ensure the model could perform real work up to their specifications and standards.</p><p>This release matters because it signals a shift from AI as a &quot;chatbot&quot; to AI as a &quot;worker&quot;. When intelligence becomes &quot;too cheap to meter,&quot; developers stop building simple Q&amp;A tools and start building &quot;agents&quot;\u2014software that can spend hours autonomously coding, researching, and organizing complex projects without breaking the bank.</p><p>In fact, MiniMax has already deployed this model into its own operations. Currently, <b>30% of all tasks at MiniMax HQ are completed by M2.5</b>, and a staggering <b>80% of their newly committed code is generated by M2.5!</b></p><p>As the MiniMax team writes in their release blog post, &quot;we believe that M2.5 provides virtually limitless possibilities for the development and operation of agents in the economy.&quot;</p><h2><b>Technology: sparse power and the CISPO breakthrough</b></h2><p>The secret to M2.5\u2019s efficiency lies in its Mixture of Experts (MoE) architecture. Rather than running all of its 230 billion parameters for every single word it generates, the model only &quot;activates&quot; 10 billion. This allows it to maintain the reasoning depth of a massive model while moving with the agility of a much smaller one.</p><p>To train this complex system, MiniMax developed a proprietary Reinforcement Learning (RL) framework called Forge. MiniMax engineer <a href=\"https://x.com/olive_jy_song\">Olive Song</a> stated on the <a href=\"https://www.youtube.com/live/uw2ZJhbv4ig?si=mCfiRpbZCs2eka9u&amp;t=3112\">ThursdAI podcast on YouTube</a> that this technique was instrumental to scaling the performance even while using the relatively small number of parameters, and that the model was trained over a period of two months.</p><div></div><p>Forge is designed to help the model learn from &quot;real-world environments&quot; \u2014 essentially letting the AI practice coding and using tools in thousands of simulated workspaces. </p><p>&quot;What we realized is that there&#x27;s a lot of potential with a small model like this if we train reinforcement learning on it with a large amount of environments and agents,&quot; Song said. &quot;But it&#x27;s not a very easy thing to do,&quot; adding that was what they spent &quot;a lot of time&quot; on.</p><p>To keep the model stable during this intense training, they used a mathematical approach called CISPO (Clipping Importance Sampling Policy Optimization) and shared the formula on their blog.</p><p>This formula ensures the model doesn&#x27;t over-correct during training, allowing it to develop what MiniMax calls an &quot;Architect Mindset&quot;. Instead of jumping straight into writing code, M2.5 has learned to proactively plan the structure, features, and interface of a project first.</p><h2><b>State-of-the-art (and near) benchmarks</b></h2><p>The results of this architecture are reflected in the latest industry leaderboards. M2.5 hasn&#x27;t just improved; it has vaulted into the top tier of coding models, approaching Anthropic&#x27;s latest model, <a href=\"https://venturebeat.com/technology/anthropics-claude-opus-4-6-brings-1m-token-context-and-agent-teams-to-take\">Claude Opus 4.6, released just a week ago</a>, and showing that Chinese companies are now just days away from catching up to far better resourced (in terms of GPUs) U.S. labs.</p><p>Here are some of the new MiniMax M2.5 benchmark highlights:</p><ul><li><p><b>SWE-Bench Verified: </b>80.2% \u2014 Matches Claude Opus 4.6 speeds</p></li><li><p><b>BrowseComp:</b> 76.3% \u2014 Industry-leading search &amp; tool use.</p></li><li><p><b>Multi-SWE-Bench:</b> 51.3% \u2014 SOTA in multi-language coding</p></li><li><p><b>BFCL (Tool Calling):</b> 76.8% \u2014 High-precision agentic workflows.</p></li></ul><p>On the ThursdAI podcast, host Alex Volkov pointed out that MiniMax M2.5 operates extremely quickly and therefore uses less tokens to complete tasks, on the order $0.15 per task compared to $3.00 for Claude Opus 4.6.</p><h2><b>Breaking the cost barrier</b></h2><p>MiniMax is offering two versions of the model through its API, both focused on high-volume production use:</p><ul><li><p><b>M2.5-Lightning: </b>Optimized for speed, delivering 100 tokens per second. It costs $0.30 per 1M input tokens and $2.40 per 1M output tokens.</p></li><li><p><b>Standard M2.5: </b>Optimized for cost, running at 50 tokens per second. It costs half as much as the Lightning version ($0.15 per 1M input tokens / $1.20 per 1M output tokens).</p></li></ul><p>In plain language: MiniMax claims you can run four &quot;agents&quot; (AI workers) continuously for an entire year for roughly $10,000. </p><p>For enterprise users, this pricing is roughly 1/10th to 1/20th the cost of competing proprietary models like GPT-5 or Claude 4.6 Opus.</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>Input</b></p></td><td><p><b>Output</b></p></td><td><p><b>Total Cost</b></p></td><td><p><b>Source</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/help/en/model-studio/developer-reference/model-pricing\">Alibaba Cloud</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Grok 4.1 Fast (reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/pricing\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast (non-reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/pricing\">xAI</a></p></td></tr><tr><td><p><b>MiniMax M2.5</b></p></td><td><p><b>$0.15</b></p></td><td><p><b>$1.20</b></p></td><td><p><b>$1.35</b></p></td><td><p><a href=\"https://www.minimax.io/news/minimax-m25\">MiniMax</a></p></td></tr><tr><td><p><b>MiniMax M2.5-Lightning</b></p></td><td><p><b>$0.30</b></p></td><td><p><b>$2.40</b></p></td><td><p><b>$2.70</b></p></td><td><p><a href=\"https://www.minimax.io/news/minimax-m25\">MiniMax</a></p></td></tr><tr><td><p>Gemini 3 Flash Preview</p></td><td><p>$0.50</p></td><td><p>$3.00</p></td><td><p>$3.50</p></td><td><p><a href=\"https://ai.google.dev/pricing\">Google</a></p></td></tr><tr><td><p>Kimi-k2.5</p></td><td><p>$0.60</p></td><td><p>$3.00</p></td><td><p>$3.60</p></td><td><p><a href=\"https://platform.moonshot.cn/docs/pricing\">Moonshot</a></p></td></tr><tr><td><p>GLM-5</p></td><td><p>$1.00</p></td><td><p>$3.20</p></td><td><p>$4.20</p></td><td><p><a href=\"https://docs.z.ai/guides/overview/pricing\">Z.ai</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/rlitqm7pi\">Baidu</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://www.anthropic.com/pricing\">Anthropic</a></p></td></tr><tr><td><p>Qwen3-Max (2026-01-23)</p></td><td><p>$1.20</p></td><td><p>$6.00</p></td><td><p>$7.20</p></td><td><p><a href=\"https://www.alibabacloud.com/help/en/model-studio/developer-reference/model-pricing\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (\u2264200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/pricing\">Google</a></p></td></tr><tr><td><p>GPT-5.2</p></td><td><p>$1.75</p></td><td><p>$14.00</p></td><td><p>$15.75</p></td><td><p><a href=\"https://openai.com/api/pricing/\">OpenAI</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://www.anthropic.com/pricing\">Anthropic</a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/pricing\">Google</a></p></td></tr><tr><td><p>Claude Opus 4.6</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://www.anthropic.com/pricing\">Anthropic</a></p></td></tr><tr><td><p>GPT-5.2 Pro</p></td><td><p>$21.00</p></td><td><p>$168.00</p></td><td><p>$189.00</p></td><td><p><a href=\"https://openai.com/api/pricing/\">OpenAI</a></p></td></tr></tbody></table><h2><b>Strategic implications for enterprises and leaders</b></h2><p>For technical leaders, M2.5 represents more than just a cheaper API. It changes the operational playbook for enterprises right now.</p><p>The pressure to &quot;optimize&quot; prompts to save money is gone. You can now deploy high-context, high-reasoning models for routine tasks that were previously cost-prohibitive.</p><p>The 37% speed improvement in end-to-end task completion means the &quot;agentic&quot; pipelines valued by AI orchestrators \u2014 where models talk to other models \u2014 finally move fast enough for real-time user applications.</p><p>In addition, M2.5\u2019s high scores in financial modeling (74.4% on MEWC) suggest it can handle the &quot;tacit knowledge&quot; of specialized industries like law and finance with minimal oversight.</p><p>Because M2.5 is positioned as an open-source model, organizations can potentially run intensive, automated code audits at a scale that was previously impossible without massive human intervention, all while maintaining better control over data privacy, but until the licensing terms and weights are posted, this remains just a moniker. </p><p>MiniMax M2.5 is a signal that the frontier of AI is no longer just about who can build the biggest brain, but who can make that brain the most useful\u2014and affordable\u2014worker in the room.</p>", "url": "https://venturebeat.com/technology/minimaxs-new-open-m2-5-and-m2-5-lightning-near-state-of-the-art-while", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Chinese AI startup <a href=\"https://www.minimax.io/news/minimax-m25\">MiniMax</a>, headquartered in Shanghai, has sent shockwaves through the AI industry today with the release of its new<a href=\"https://www.minimax.io/news/minimax-m25\"> M2.5 language model</a> in two variants, which promise to ma"]}
{"id": "source:rss:3516142964", "title": "OpenAI deploys Cerebras chips for 'near-instant' code generation in first major move beyond Nvidia", "summary": "<p><a href=\"https://openai.com/\">OpenAI</a> on Thursday launched <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">GPT-5.3-Codex-Spark</a>, a stripped-down coding model engineered for near-instantaneous response times, marking the company&#x27;s first significant inference partnership outside its traditional Nvidia-dominated infrastructure. The model runs on hardware from <a href=\"https://www.cerebras.ai/\">Cerebras Systems</a>, a Sunnyvale-based chipmaker whose wafer-scale processors specialize in low-latency AI workloads.</p><p>The partnership arrives at a pivotal moment for OpenAI. The company finds itself navigating a <a href=\"https://www.cnbc.com/2026/02/03/nvidia-openai-stalled-on-their-mega-deal-ai-giants-need-each-other.html\">frayed relationship</a> with longtime chip supplier Nvidia, <a href=\"https://www.nytimes.com/2026/02/11/opinion/openai-ads-chatgpt.html\">mounting criticism</a> over its decision to introduce advertisements into ChatGPT, a newly announced <a href=\"https://www.semafor.com/article/02/11/2026/how-openai-got-comfortable-with-the-pentagon-using-chatgpt-for-war\">Pentagon contract</a>, and internal organizational upheaval that has seen a <a href=\"https://techcrunch.com/2026/02/11/openai-disbands-mission-alignment-team-which-focused-on-safe-and-trustworthy-ai-development/\">safety-focused team disbanded</a> and at least one researcher <a href=\"https://www.nytimes.com/2026/02/11/opinion/openai-ads-chatgpt.html\">resign in protest</a>.</p><p>&quot;GPUs remain foundational across our training and inference pipelines and deliver the most cost effective tokens for broad usage,&quot; an OpenAI spokesperson told VentureBeat. &quot;Cerebras complements that foundation by excelling at workflows that demand extremely low latency, tightening the end-to-end loop so use cases such as real-time coding in Codex feel more responsive as you iterate.&quot;</p><p>The careful framing \u2014 emphasizing that GPUs &quot;remain foundational&quot; while positioning Cerebras as a &quot;complement&quot; \u2014 underscores the delicate balance OpenAI must strike as it diversifies its chip suppliers without alienating <a href=\"https://www.nvidia.com/en-us/\">Nvidia</a>, the dominant force in AI accelerators.</p><h2><b>Speed gains come with capability tradeoffs that OpenAI says developers will accept</b></h2><p><a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">Codex-Spark</a> represents OpenAI&#x27;s first model purpose-built for real-time coding collaboration. The company claims the model delivers <!-- -->more than 1000 tokens per second when served on ultra-low latency hardware, though it declined to provide specific latency metrics such as time-to-first-token figures.</p><p>&quot;We aren&#x27;t able to share specific latency numbers, however Codex-Spark is optimized to feel near-instant \u2014 delivering more than 1000 tokens per second while remaining highly capable for real-world coding tasks,&quot; the OpenAI spokesperson said.</p><p>The speed gains come with acknowledged capability tradeoffs. On <a href=\"https://www.swebench.com/\">SWE-Bench Pro</a> and <a href=\"https://www.tbench.ai/\">Terminal-Bench 2.0</a> \u2014 two industry benchmarks that evaluate AI systems&#x27; ability to perform complex software engineering tasks autonomously \u2014 Codex-Spark underperforms the full <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">GPT-5.3-Codex model</a>. OpenAI positions this as an acceptable exchange: developers get responses fast enough to maintain creative flow, even if the underlying model cannot tackle the most sophisticated multi-step programming challenges.</p><p>The model launches with a 128,000-token context window and supports text only \u2014 no image or multimodal inputs. OpenAI has made it available as a research preview to <a href=\"https://openai.com/index/introducing-chatgpt-pro/\">ChatGPT Pro</a> subscribers through the Codex app, command-line interface, and Visual Studio Code extension. A small group of enterprise partners will receive API access to evaluate integration possibilities.</p><p>&quot;We are making <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">Codex-Spark</a> available in the API for a small set of design partners to understand how developers want to integrate Codex-Spark into their products,&quot; the spokesperson explained. &quot;We&#x27;ll expand access over the coming weeks as we continue tuning our integration under real workloads.&quot;</p><h2><b>Cerebras hardware eliminates bottlenecks that plague traditional GPU clusters</b></h2><p>The technical architecture behind <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">Codex-Spark</a> tells a story about inference economics that increasingly matters as AI companies scale consumer-facing products. Cerebras&#x27;s <a href=\"https://www.cerebras.ai/chip\">Wafer Scale Engine 3</a> \u2014 a single chip roughly the size of a dinner plate containing 4 trillion transistors \u2014 eliminates much of the communication overhead that occurs when AI workloads spread across clusters of smaller processors.</p><p>For training massive models, that distributed approach remains necessary and Nvidia&#x27;s GPUs excel at it. But for inference \u2014 the process of generating responses to user queries \u2014 Cerebras argues its architecture can deliver results with dramatically lower latency. Sean Lie, Cerebras&#x27;s CTO and co-founder, framed the partnership as an opportunity to reshape how developers interact with AI systems.</p><p>&quot;What excites us most about GPT-5.3-Codex-Spark is partnering with OpenAI and the developer community to discover what fast inference makes possible \u2014 new interaction patterns, new use cases, and a fundamentally different model experience,&quot; Lie said in a statement. &quot;This preview is just the beginning.&quot;</p><p>OpenAI&#x27;s infrastructure team did not limit its optimization work to the Cerebras hardware. The company announced latency improvements across its entire inference stack that benefit all Codex models regardless of underlying hardware, including persistent <a href=\"https://developers.openai.com/api/docs/guides/realtime-websocket\">WebSocket connections </a>and optimizations within the <a href=\"https://developers.openai.com/api/reference/resources/responses\">Responses API</a>. The results: 80 percent reduction in overhead per client-server round trip, 30 percent reduction in per-token overhead, and 50 percent reduction in time-to-first-token.</p><h2><b>A $100 billion Nvidia megadeal has quietly fallen apart behind the scenes</b></h2><p>The Cerebras partnership takes on additional significance given the increasingly complicated relationship between <a href=\"https://openai.com/\">OpenAI</a> and <a href=\"https://www.nvidia.com/en-us/\">Nvidia</a>. Last fall, when OpenAI announced its <a href=\"https://openai.com/index/announcing-the-stargate-project/\">Stargate</a> infrastructure initiative, Nvidia publicly committed to <a href=\"https://nvidianews.nvidia.com/news/openai-and-nvidia-announce-strategic-partnership-to-deploy-10gw-of-nvidia-systems\">investing $100 billion</a> to support OpenAI as it built out AI infrastructure. The announcement appeared to cement a strategic alliance between the world&#x27;s most valuable AI company and its dominant chip supplier.</p><p>Five months later, that megadeal has effectively stalled, according to <a href=\"https://www.cnbc.com/2026/02/03/nvidia-openai-stalled-on-their-mega-deal-ai-giants-need-each-other.html\">multiple</a> <a href=\"https://www.wsj.com/tech/ai/the-100-billion-megadeal-between-openai-and-nvidia-is-on-ice-aa3025e3?gaa_at=eafs&amp;gaa_n=AWEtsqfe0QGgHdMiR8gUBgaz9wQinHCS7kyhwZCSd6eNxrXKtH4voU_uFZxw3SV-DgI%3D&amp;gaa_ts=698e0667&amp;gaa_sig=Yec2ZvfMXkAm7N0vdWnevbBH9qMD4RsgyuuPbvqPzAVZP-0cPkqZS2Gyr3OJ5T7eR0_ZvwzRJ38Hnqa5a_lz-g%3D%3D\">reports</a>. Nvidia CEO Jensen Huang has publicly denied tensions, telling reporters in late January that there is &quot;<a href=\"https://www.cnbc.com/2026/02/03/nvidias-jensen-huang-denies-openai-deal-rumors-theres-no-drama.html\">no drama</a>&quot; and that Nvidia remains committed to participating in OpenAI&#x27;s current funding round. But the relationship has cooled considerably, with friction stemming from multiple sources.</p><p>OpenAI has aggressively pursued partnerships with alternative chip suppliers, including the <a href=\"https://www.cerebras.ai/\">Cerebras</a> deal and separate agreements with <a href=\"https://openai.com/index/openai-amd-strategic-partnership/\">AMD</a> and <a href=\"https://openai.com/index/openai-and-broadcom-announce-strategic-collaboration/\">Broadcom</a>. From Nvidia&#x27;s perspective, OpenAI may be using its influence to commoditize the very hardware that made its AI breakthroughs possible. From OpenAI&#x27;s perspective, reducing dependence on a single supplier represents prudent business strategy.</p><p>&quot;We will continue working with the ecosystem on evaluating the most price-performant chips across all use cases on an ongoing basis,&quot; OpenAI&#x27;s spokesperson told VentureBeat. &quot;GPUs remain our priority for cost-sensitive and throughput-first use cases across research and inference.&quot; The statement reads as a careful effort to avoid antagonizing Nvidia while preserving flexibility \u2014 and reflects a broader reality that training frontier AI models still requires exactly the kind of massive parallel processing that Nvidia GPUs provide.</p><h2><b>Disbanded safety teams and researcher departures raise questions about OpenAI&#x27;s priorities</b></h2><p>The <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">Codex-Spark</a> launch comes as OpenAI navigates a series of internal challenges that have intensified scrutiny of the company&#x27;s direction and values. Earlier this week, reports emerged that OpenAI <a href=\"https://www.platformer.news/openai-mission-alignment-team-joshua-achiam/\">disbanded its mission alignment team</a>, a group established in September 2024 to promote the company&#x27;s stated goal of ensuring artificial general intelligence benefits humanity. The team&#x27;s seven members have been reassigned to other roles, with leader Joshua Achiam given a new title as OpenAI&#x27;s &quot;chief futurist.&quot;</p><p>OpenAI previously <a href=\"https://www.cnbc.com/2024/05/17/openai-superalignment-sutskever-leike.html\">disbanded another safety-focused group</a>, the superalignment team, in 2024. That team had concentrated on long-term existential risks from AI. The pattern of dissolving safety-oriented teams has drawn criticism from researchers who argue that OpenAI&#x27;s commercial pressures are overwhelming its original non-profit mission.</p><p>The company also faces fallout from its decision to introduce advertisements into ChatGPT. Researcher <a href=\"https://www.nytimes.com/2026/02/11/opinion/openai-ads-chatgpt.html\">Zo\u00eb Hitzig resigned this week</a> over what she described as the &quot;slippery slope&quot; of ad-supported AI, warning in a New York Times essay that ChatGPT&#x27;s archive of intimate user conversations creates unprecedented opportunities for manipulation. Anthropic seized on the controversy with a <a href=\"https://www.theverge.com/ai-artificial-intelligence/873686/anthropic-claude-ai-ad-free-super-bowl-advert-chatgpt\">Super Bowl advertising campaign</a> featuring the tagline: &quot;Ads are coming to AI. But not to Claude.&quot;</p><p>Separately, the company <a href=\"https://www.semafor.com/article/02/11/2026/how-openai-got-comfortable-with-the-pentagon-using-chatgpt-for-war\">agreed to provide ChatGPT to the Pentagon</a> through <a href=\"http://genai.mil\">Genai.mil</a>, a new Department of Defense program that requires OpenAI to permit &quot;all lawful uses&quot; without company-imposed restrictions \u2014 terms that Anthropic reportedly rejected. And reports emerged that Ryan Beiermeister, OpenAI&#x27;s vice president of product policy who had expressed concerns about a planned explicit content feature, was terminated in January following a discrimination allegation she denies.</p><h2><b>OpenAI envisions AI coding assistants that juggle quick edits and complex autonomous tasks</b></h2><p>Despite the surrounding turbulence, OpenAI&#x27;s technical roadmap for Codex suggests ambitious plans. The company envisions a coding assistant that seamlessly blends rapid-fire interactive editing with longer-running autonomous tasks \u2014 an AI that handles quick fixes while simultaneously orchestrating multiple agents working on more complex problems in the background.</p><p>&quot;Over time, the modes will blend \u2014 Codex can keep you in a tight interactive loop while delegating longer-running work to sub-agents in the background, or fanning out tasks to many models in parallel when you want breadth and speed, so you don&#x27;t have to choose a single mode up front,&quot; the OpenAI spokesperson told VentureBeat.</p><p>This vision would require not just faster inference but sophisticated task decomposition and coordination across models of varying sizes and capabilities. <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">Codex-Spark</a> establishes the low-latency foundation for the interactive portion of that experience; future releases will need to deliver the autonomous reasoning and multi-agent coordination that would make the full vision possible.</p><p>For now, <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">Codex-Spark</a> operates under separate rate limits from other OpenAI models, reflecting constrained Cerebras infrastructure capacity during the research preview. &quot;Because it runs on specialized low-latency hardware, usage is governed by a separate rate limit that may adjust based on demand during the research preview,&quot; the spokesperson noted. The limits are designed to be &quot;generous,&quot; with OpenAI monitoring usage patterns as it determines how to scale.</p><h2><b>The real test is whether faster responses translate into better software</b></h2><p>The <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">Codex-Spark announcement</a> arrives amid <a href=\"https://venturebeat.com/technology/anthropics-claude-cowork-finally-lands-on-windows-and-it-wants-to-automate\">intense competition</a> for AI-powered developer tools. Anthropic&#x27;s Claude Cowork product triggered a <a href=\"https://fortune.com/2026/02/06/anthropic-claude-opus-4-6-stock-selloff-new-upgrade/\">selloff in traditional software stocks</a> last week as investors considered whether AI assistants might displace conventional enterprise applications. <a href=\"https://www.microsoft.com/en-us\">Microsoft</a>, <a href=\"https://www.google.com/\">Google</a>, and <a href=\"https://www.amazon.com/\">Amazon</a> continue investing heavily in AI coding capabilities integrated with their respective cloud platforms.</p><p>OpenAI&#x27;s <a href=\"https://venturebeat.com/article-pv/openai-launches-a-codex-desktop-app-for-macos-to-run-multiple-ai-coding\">Codex app</a> has demonstrated rapid adoption since launching ten days ago, with more than one million downloads and weekly active users growing 60 percent week-over-week. More than 325,000 developers now actively use Codex across free and paid tiers. But the fundamental question facing OpenAI \u2014 and the broader AI industry \u2014 is whether speed improvements like those promised by <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">Codex-Spark</a> translate into meaningful productivity gains or merely create more pleasant experiences without changing outcomes.</p><p>Early evidence from AI coding tools suggests that faster responses encourage more iterative experimentation. Whether that experimentation produces better software remains contested among researchers and practitioners alike. What seems clear is that OpenAI views inference latency as a competitive frontier worth substantial investment, even as that investment takes it beyond its traditional Nvidia partnership into untested territory with alternative chip suppliers.</p><p>The Cerebras deal is a calculated bet that specialized hardware can unlock use cases that general-purpose GPUs cannot cost-effectively serve. For a company simultaneously battling competitors, managing strained supplier relationships, and weathering internal dissent over its commercial direction, it is also a reminder that in the AI race, standing still is not an option. OpenAI built its reputation by moving fast and breaking conventions. Now it must prove it can move even faster \u2014 without breaking itself.</p>", "url": "https://venturebeat.com/technology/openai-deploys-cerebras-chips-for-15x-faster-code-generation-in-first-major", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p><a href=\"https://openai.com/\">OpenAI</a> on Thursday launched <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">GPT-5.3-Codex-Spark</a>, a stripped-down coding model engineered for near-instantaneous response times, marking the company&#x27;s first significant inference partners"]}
{"id": "source:rss:4625101917", "title": "Google Chrome ships WebMCP in early preview, turning every website into a structured tool for AI agents", "summary": "<p>When an AI agent visits a website, it\u2019s essentially a tourist who doesn\u2019t speak the local language. Whether built on LangChain, Claude Code, or the increasingly popular OpenClaw framework, the agent is reduced to guessing which buttons to press: scraping raw HTML, firing off screenshots to multimodal models, and burning through thousands of tokens just to figure out where a search bar is.</p><p>That era may be ending. Earlier this week, the Google Chrome team launched <a href=\"https://developer.chrome.com/blog/webmcp-epp\"><u>WebMCP</u></a> \u2014 Web Model Context Protocol \u2014 as an early preview in Chrome 146 Canary. WebMCP, which was developed jointly by engineers at Google and Microsoft and incubated through the W3C&#x27;s <a href=\"https://github.com/webmachinelearning/webmcp\"><u>Web Machine Learning community group</u></a>, is a proposed web standard that lets any website expose structured, callable tools directly to AI agents through a new browser API: navigator.modelContext.</p><p>The implications for enterprise IT are significant. Instead of building and maintaining separate back-end MCP servers in Python or Node.js to connect their web applications to AI platforms, development teams can now wrap their existing client-side JavaScript logic into agent-readable tools \u2014 without re-architecting a single page.</p><h2>AI agents are expensive, fragile tourists on the web</h2><p>The cost and reliability issues with current approaches to web-agent (browser agents)\u00a0 interaction are well understood by anyone who has deployed them at scale. The two dominant methods \u2014 visual screen-scraping and DOM parsing \u2014 both suffer from fundamental inefficiencies that directly affect enterprise budgets.</p><p> </p><p>With screenshot-based approaches, agents pass images into multimodal models (like Claude and Gemini) and hope the model can identify not only what is on the screen, but where buttons, form fields, and interactive elements are located. Each image consumes thousands of tokens and can have a long latency. With DOM-based approaches, agents ingest raw HTML and JavaScript \u2014 a foreign language full of various tags, CSS rules, and structural markup that is irrelevant to the task at hand but still consumes context window space and inference cost.</p><p>In both cases, the agent is translating between what the website was designed for (human eyes) and what the model needs (structured data about available actions). A single product search that a human completes in seconds can require dozens of sequential agent interactions \u2014 clicking filters, scrolling pages, parsing results \u2014 each one an inference call that adds latency and cost.</p><h2>How WebMCP works: Two APIs, one standard</h2><p>WebMCP proposes two complementary APIs that serve as a bridge between websites and AI agents.</p><p>The <b>Declarative API</b> handles standard actions that can be defined directly in existing HTML forms. For organizations with well-structured forms already in production, this pathway requires minimal additional work; by adding tool names and descriptions to existing form markup, developers can make those forms callable by agents. If your HTML forms are already clean and well-structured, you are probably already 80% of the way there.</p><p>The <b>Imperative API</b> handles more complex, dynamic interactions that require JavaScript execution. This is where developers define richer tool schemas \u2014 conceptually similar to the tool definitions sent to the OpenAI or Anthropic API endpoints, but running entirely client-side in the browser. Through the registerTool(), a website can expose functions like searchProducts(query, filters) or orderPrints(copies, page_size) with full parameter schemas and natural language descriptions.</p><p>The key insight is that a single tool call through WebMCP can replace what might have been dozens of browser-use interactions. An e-commerce site that registers a searchProducts tool lets the agent make one structured function call and receive structured JSON results, rather than having the agent click through filter dropdowns, scroll through paginated results, and screenshot each page.</p><h2>The enterprise case: Cost, reliability, and the end of fragile scraping</h2><p>For IT decision makers evaluating agentic AI deployments, WebMCP addresses three persistent pain points simultaneously.</p><p><b>Cost reduction</b> is the most immediately quantifiable benefit. By replacing sequences of screenshot captures, multimodal inference calls, and iterative DOM parsing with single structured tool calls, organizations can expect significant reductions in token consumption.\u00a0</p><p><b>Reliability</b> improves because agents are no longer guessing about page structure. When a website explicitly publishes a tool contract \u2014 &quot;here are the functions I support, here are their parameters, here is what they return&quot; \u2014 the agent operates with certainty rather than inference. Failed interactions due to UI changes, dynamic content loading, or ambiguous element identification are largely eliminated for any interaction covered by a registered tool.</p><p><b>Development velocity</b> accelerates because web teams can leverage their existing front-end JavaScript rather than standing up separate backend infrastructure. The specification emphasizes that any task a user can accomplish through a page&#x27;s UI can be made into a tool by reusing much of the page&#x27;s existing JavaScript code. Teams do not need to learn new server frameworks or maintain separate API surfaces for agent consumers.</p><h2>Human-in-the-loop by design, not an afterthought</h2><p>A critical architectural decision separates WebMCP from the fully autonomous agent paradigm that has dominated recent headlines. The standard is explicitly designed around cooperative, human-in-the-loop workflows \u2014 not unsupervised automation.</p><p>According to Khushal Sagar, a staff software engineer for Chrome, the WebMCP specification identifies three pillars that underpin this philosophy.\u00a0</p><ol><li><p><b>Context</b>: All the data agents need to understand what the user is doing, including content that is often not currently visible on screen.\u00a0</p></li><li><p><b>Capabilities</b>: Actions the agent can take on the user&#x27;s behalf, from answering questions to filling out forms.\u00a0</p></li><li><p><b>Coordination</b>: Controlling the handoff between user and agent when the agent encounters situations it cannot resolve autonomously.</p></li></ol><p>The specification&#x27;s authors at Google and Microsoft illustrate this with a shopping scenario: a user named Maya asks her AI assistant to help find an eco-friendly dress for a wedding. The agent suggests vendors, opens a browser to a dress site, and discovers the page exposes WebMCP tools like getDresses() and showDresses().\u00a0 When Maya&#x27;s criteria go beyond the site&#x27;s basic filters, the agent calls those tools to fetch product data, uses its own reasoning to filter for &quot;cocktail-attire appropriate,&quot; and then calls showDresses()to update the page with only the relevant results. It&#x27;s a fluid loop of human taste and agent capability, exactly the kind of collaborative browsing that WebMCP is designed to enable.</p><p>This is not a headless browsing standard. The <a href=\"https://github.com/webmachinelearning/webmcp\"><u>specification explicitly states</u></a> that headless and fully autonomous scenarios are non-goals. For those use cases, the authors point to existing protocols like Google&#x27;s Agent-to-Agent (A2A) protocol. WebMCP is about the browser \u2014 where the user is present, watching, and collaborating.</p><h2>Not a replacement for MCP, but a complement</h2><p>WebMCP is not a replacement for Anthropic&#x27;s Model Context Protocol, despite sharing a conceptual lineage and a portion of its name. It does not follow the JSON-RPC specification that MCP uses for client-server communication. Where MCP operates as a back-end protocol connecting AI platforms to service providers through hosted servers, WebMCP operates entirely client-side within the browser.</p><p>The relationship is complementary. A travel company might maintain a back-end MCP server for direct API integrations with AI platforms like ChatGPT or Claude, while simultaneously implementing WebMCP tools on its consumer-facing website so that browser-based agents can interact with its booking flow in the context of a user&#x27;s active session. The two standards serve different interaction patterns without conflict.</p><p>The distinction matters for enterprise architects. Back-end MCP integrations are appropriate for service-to-service automation where no browser UI is needed. WebMCP is appropriate when the user is present and the interaction benefits from shared visual context \u2014 which describes the majority of consumer-facing web interactions that enterprises care about.</p><h2>What comes next: From flag to standard</h2><p>WebMCP is currently available in Chrome 146 Canary behind the &quot;WebMCP for testing&quot; flag at chrome://flags. Developers can join the <a href=\"https://developer.chrome.com/docs/ai/join-epp\"><u>Chrome Early Preview Program</u></a> for access to documentation and demos. Other browsers have not yet announced implementation timelines, though Microsoft&#x27;s active co-authorship of the specification suggests Edge support is likely.</p><p>Industry observers expect formal browser announcements by mid-to-late 2026, with Google Cloud Next and Google I/O as probable venues for broader rollout announcements. The specification is transitioning from community incubation within the W3C to a formal draft \u2014 a process that historically takes months but signals serious institutional commitment.</p><p>The comparison that Sagar has drawn is instructive: WebMCP aims to become the USB-C of AI agent interactions with the web. A single, standardized interface that any agent can plug into, replacing the current tangle of bespoke scraping strategies and fragile automation scripts.</p><p>Whether that vision is realized depends on adoption \u2014 by both browser vendors and web developers. But with Google and Microsoft jointly shipping code, the W3C providing institutional scaffolding, and Chrome 146 already running the implementation behind a flag, WebMCP has cleared the most difficult hurdle any web standard faces: getting from proposal to working software.</p>", "url": "https://venturebeat.com/infrastructure/google-chrome-ships-webmcp-in-early-preview-turning-every-website-into-a", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>When an AI agent visits a website, it\u2019s essentially a tourist who doesn\u2019t speak the local language. Whether built on LangChain, Claude Code, or the increasingly popular OpenClaw framework, the agent is reduced to guessing which buttons to press: scraping raw HTML, firing off screenshots to multim"]}
{"id": "source:rss:8883812740", "title": "AI inference costs dropped up to 10x on Nvidia's Blackwell \u2014 but hardware is only half the equation", "summary": "<p>Lowering the cost of inference is typically a combination of hardware and software. A new analysis released Thursday by Nvidia details how four leading inference providers are reporting 4x to 10x reductions in cost per token.</p><p>The dramatic cost reductions were achieved using Nvidia&#x27;s Blackwell platform with open-source models. Production deployment data from Baseten, DeepInfra, Fireworks AI and Together AI shows significant cost improvements across healthcare, gaming, agentic chat, and customer service as enterprises scale AI from pilot projects to millions of users.</p><p>The 4x to 10x cost reductions reported by inference providers required combining Blackwell hardware with two other elements: optimized software stacks and switching from proprietary to open-source models that now match frontier-level intelligence. Hardware improvements alone delivered 2x gains in some deployments, according to the analysis. Reaching larger cost reductions required adopting low-precision formats like NVFP4 and moving away from closed source APIs that charge premium rates.</p><p>The economics prove counterintuitive. Reducing inference costs requires investing in higher-performance infrastructure because throughput improvements translate directly into lower per-token costs.</p><p>&quot;Performance is what drives down the cost of inference,&quot; Dion Harris, senior director of HPC and AI hyperscaler solutions at Nvidia, told VentureBeat in an exclusive interview. &quot;What we&#x27;re seeing in inference is that throughput literally translates into real dollar value and driving down the cost.&quot;</p><h2>Production deployments show 4x to 10x cost reductions</h2><p>Nvidia detailed four customer deployments in a blog post showing how the combination of Blackwell infrastructure, optimized software stacks and open-source models delivers cost reductions across different industry workloads. The case studies span high-volume applications where inference economics directly determines business viability.</p><p>Sully.ai cut healthcare AI inference costs by 90% (a 10x reduction) while improving response times 65% by switching from proprietary models to open-source models running on Baseten&#x27;s Blackwell-powered platform, according to Nvidia. The company returned over 30 million minutes to physicians by automating medical coding and note-taking tasks that previously required manual data entry.</p><p>Nvidia also reported that Latitude reduced gaming inference costs 4x for its AI Dungeon platform by running large mixture-of-experts (MoE) models on DeepInfra&#x27;s Blackwell deployment. Cost per million tokens dropped from 20 cents on Nvidia&#x27;s previous Hopper platform to 10 cents on Blackwell, then to 5 cents after adopting Blackwell&#x27;s native NVFP4 low-precision format. Hardware alone delivered 2x improvement, but reaching 4x required the precision format change.</p><p>Sentient Foundation achieved 25% to 50% better cost efficiency for its agentic chat platform using Fireworks AI&#x27;s Blackwell-optimized inference stack, according to Nvidia. The platform orchestrates complex multi-agent workflows and processed 5.6 million queries in a single week during its viral launch while maintaining low latency.</p><p>Nvidia said Decagon saw 6x cost reduction per query for AI-powered voice customer support by running its multimodel stack on Together AI&#x27;s Blackwell infrastructure. Response times stayed under 400 milliseconds, even when processing thousands of tokens per query, critical for voice interactions where delays cause users to hang up or lose trust.</p><h2>Technical factors driving 4x versus 10x improvements</h2><p>The range from 4x to 10x cost reductions across deployments reflects different combinations of technical optimizations rather than just hardware differences. Three factors emerge as primary drivers: precision format adoption, model architecture choices, and software stack integration.</p><p><b>Precision formats show the clearest impact</b>. Latitude&#x27;s case demonstrates this directly. Moving from Hopper to Blackwell delivered 2x cost reduction through hardware improvements. Adopting NVFP4, Blackwell&#x27;s native low-precision format, doubled that improvement to 4x total. NVFP4 reduces the number of bits required to represent model weights and activations, allowing more computation per GPU cycle while maintaining accuracy. The format works particularly well for MoE models where only a subset of the model activates for each inference request.</p><p><b>Model architecture matters.</b> MoE models, which activate different specialized sub-models based on input, benefit from Blackwell&#x27;s NVLink fabric that enables rapid communication between experts. &quot;Having those experts communicate across that NVLink fabric allows you to reason very quickly,&quot; Harris said. Dense models that activate all parameters for every inference don&#x27;t leverage this architecture as effectively.</p><p><b>Software stack integration creates additional performance deltas</b>. Harris said that Nvidia&#x27;s co-design approach \u2014 where Blackwell hardware, NVL72 scale-up architecture, and software like Dynamo and TensorRT-LLM are optimized together \u2014 also makes a difference. Baseten&#x27;s deployment for Sully.ai used this integrated stack, combining NVFP4, TensorRT-LLM and Dynamo to achieve the 10x cost reduction. Providers running alternative frameworks like vLLM may see lower gains.</p><p><b>Workload characteristics matter</b>. Reasoning models show particular advantages on Blackwell because they generate significantly more tokens to reach better answers. The platform&#x27;s ability to process these extended token sequences efficiently through disaggregated serving, where context prefill and token generation are handled separately, makes reasoning workloads cost-effective.</p><p>Teams evaluating potential cost reductions should examine their workload profiles against these factors. High token generation workloads using mixture-of-experts models with the integrated Blackwell software stack will approach the 10x range. Lower token volumes using dense models on alternative frameworks will land closer to 4x. </p><h2>What teams should test before migrating</h2><p>While these case studies focus on Nvidia Blackwell deployments, enterprises have multiple paths to reducing inference costs. AMD&#x27;s MI300 series, Google TPUs, and specialized inference accelerators from Groq and Cerebras offer alternative architectures. Cloud providers also continue optimizing their inference services. The question isn&#x27;t whether Blackwell is the only option but whether the specific combination of hardware, software and models fits particular workload requirements.</p><p>Enterprises considering Blackwell-based inference should start by calculating whether their workloads justify infrastructure changes.\u00a0</p><p>&quot;Enterprises need to work back from their workloads and use case and cost constraints,&quot; Shruti Koparkar, AI product marketing at Nvidia, told VentureBeat.</p><p>The deployments achieving 6x to 10x improvements all involved high-volume, latency-sensitive applications processing millions of requests monthly. Teams running lower volumes or applications with latency budgets exceeding one second should explore software optimization or model switching before considering infrastructure upgrades.</p><p><b>Testing matters more than provider specifications</b>. Koparkar emphasizes that providers publish throughput and latency metrics, but these represent ideal conditions.\u00a0</p><p>&quot;If it&#x27;s a highly latency-sensitive workload, they might want to test a couple of providers and see who meets the minimum they need while keeping the cost down,&quot; she said. Teams should run actual production workloads across multiple Blackwell providers to measure real performance under their specific usage patterns and traffic spikes rather than relying on published benchmarks.</p><p><b>The staged approach Latitude used provides a model for evaluation</b>. The company first moved to Blackwell hardware and measured 2x improvement, then adopted NVFP4 format to reach 4x total reduction. Teams currently on Hopper or other infrastructure can test whether precision format changes and software optimization on existing hardware capture meaningful savings before committing to full infrastructure migrations. Running open source models on current infrastructure might deliver half the potential cost reduction without new hardware investments.</p><p><b>Provider selection requires understanding software stack differences</b>. While multiple providers offer Blackwell infrastructure, their software implementations vary. Some run Nvidia&#x27;s integrated stack using Dynamo and TensorRT-LLM, while others use frameworks like vLLM. Harris acknowledges performance deltas exist between these configurations. Teams should evaluate what each provider actually runs and how it matches their workload requirements rather than assuming all Blackwell deployments perform identically.</p><p><b>The economic equation extends beyond cost per token</b>. Specialized inference providers like Baseten, DeepInfra, Fireworks and Together offer optimized deployments but require managing additional vendor relationships. Managed services from AWS, Azure or Google Cloud may have higher per-token costs but lower operational complexity. Teams should calculate total cost including operational overhead, not just inference pricing, to determine which approach delivers better economics for their specific situation.</p>", "url": "https://venturebeat.com/infrastructure/ai-inference-costs-dropped-up-to-10x-on-nvidias-blackwell-but-hardware-is", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Lowering the cost of inference is typically a combination of hardware and software. A new analysis released Thursday by Nvidia details how four leading inference providers are reporting 4x to 10x reductions in cost per token.</p><p>The dramatic cost reductions were achieved using Nvidia&#x27;s Bl"]}
{"id": "source:rss:1086082291", "title": "z.ai's open source GLM-5 achieves record low hallucination rate and leverages new RL 'slime' technique", "summary": "<p>Chinese AI startup Zhupai aka z.ai is back this week with an eye-popping new frontier large language model: <a href=\"https://x.com/Zai_org/status/2021638634739527773\">GLM-5</a>.</p><p>The latest in z.ai&#x27;s ongoing and continually impressive GLM series, it retains an open source MIT License \u2014 perfect for enterprise deployment \u2013 and, in one of several notable achievements, achieves a record-low hallucination rate on the independent <a href=\"https://x.com/ArtificialAnlys/status/2021678229418066004\">Artificial Analysis Intelligence Index v4.0</a>. </p><p>With a score of -1 on the AA-Omniscience Index\u2014representing a massive 35-point improvement over its predecessor\u2014GLM-5 now leads the entire AI industry, including U.S. competitors like Google, OpenAI and Anthropic, in knowledge reliability by knowing when to abstain rather than fabricate information.</p><p>Beyond its reasoning prowess, GLM-5 is built for high-utility knowledge work. It features native &quot;Agent Mode&quot; capabilities that allow it to turn raw prompts or source materials directly into professional office documents, including ready-to-use <code>.docx</code>, <code>.pdf</code>, and <code>.xlsx</code> files. </p><p>Whether generating detailed financial reports, high school sponsorship proposals, or complex spreadsheets, GLM-5 delivers results in real-world formats that integrate directly into enterprise workflows.</p><p>It is also disruptively priced at roughly $0.80 per million input tokens and $2.56 per million output tokens, approximately 6x cheaper than proprietary competitors like Claude Opus 4.6, making state-of-the-art agentic engineering more cost-effective than ever before. Here&#x27;s what else enterprise decision makers should know about the model and its training. </p><h2><b>Technology: scaling for agentic efficiency</b></h2><p>At the heart of GLM-5 is a massive leap in raw parameters. The model scales from the 355B parameters of GLM-4.5 to a staggering 744B parameters, with 40B active per token in its Mixture-of-Experts (MoE) architecture. This growth is supported by an increase in pre-training data to 28.5T tokens.</p><p>To address training inefficiencies at this magnitude, Zai developed &quot;<a href=\"https://github.com/THUDM/slime\">slime</a>,&quot; a novel asynchronous reinforcement learning (RL) infrastructure. </p><p>Traditional RL often suffers from &quot;long-tail&quot; bottlenecks; Slime breaks this lockstep by allowing trajectories to be generated independently, enabling the fine-grained iterations necessary for complex agentic behavior. </p><p>By integrating system-level optimizations like Active Partial Rollouts (APRIL), slime addresses the generation bottlenecks that typically consume over 90% of RL training time, significantly accelerating the iteration cycle for complex agentic tasks.</p><p>The framework\u2019s design is centered on a tripartite modular system: a high-performance training module powered by Megatron-LM, a rollout module utilizing SGLang and custom routers for high-throughput data generation, and a centralized Data Buffer that manages prompt initialization and rollout storage. </p><p>By enabling adaptive verifiable environments and multi-turn compilation feedback loops, slime provides the robust, high-throughput foundation required to transition AI from simple chat interactions toward rigorous, long-horizon systems engineering.</p><p>To keep deployment manageable, GLM-5 integrates DeepSeek Sparse Attention (DSA), preserving a 200K context capacity while drastically reducing costs.</p><h2><b>End-to-end knowledge work</b></h2><p>Zai is framing GLM-5 as an &quot;office&quot; tool for the AGI era. While previous models focused on snippets, GLM-5 is built to deliver ready-to-use documents. </p><p>It can autonomously transform prompts into formatted .docx, .pdf, and .xlsx files\u2014ranging from financial reports to sponsorship proposals. </p><p>In practice, this means the model can decompose high-level goals into actionable subtasks and perform &quot;Agentic Engineering,&quot; where humans define quality gates while the AI handles execution.</p><h2><b>High performance </b></h2><p>GLM-5\u2019s benchmarks make it the new most powerful open source model in the world, according to <a href=\"https://x.com/ArtificialAnlys/status/2021678229418066004\">Artificial Analysis</a>, surpassing Chinese rival <a href=\"https://venturebeat.com/orchestration/moonshot-ai-debuts-kimi-k2-5-most-powerful-open-source-llm-beating-opus-4-5\">Moonshot&#x27;s new Kimi K2.5</a> released just two weeks ago, showing that Chinese AI companies are nearly caught up with far better resourced proprietary Western rivals. </p><p>According to z.ai&#x27;s own materials shared today, GLM-5 ranks near state-of-the-art on several key benchmarks:</p><p><b>SWE-bench Verified: </b>GLM-5 achieved a score of 77.8, outperforming Gemini 3 Pro (76.2) and approaching Claude Opus 4.6 (80.9).</p><p><b>Vending Bench 2:</b> In a simulation of running a business, GLM-5 ranked #1 among open-source models with a final balance of $4,432.12.</p><p>Beyond performance, GLM-5 is aggressively undercutting the market. Live on OpenRouter as of February 11, 2026, it is priced at approximately $0.80\u2013$1.00 per million input tokens and $2.56\u2013$3.20 per million output tokens. It falls in the mid-range compared to other leading LLMs, but based on its top-tier bechmarking performance, it&#x27;s what one might call a &quot;steal.&quot;</p><table><tbody><tr><td><p>Model</p></td><td><p>Input (per 1M tokens)</p></td><td><p>Output (per 1M tokens)</p></td><td><p>Total Cost (1M in + 1M out) </p></td><td><p>Source</p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p><b>$0.25</b></p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast (reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast (non-reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Gemini 3 Flash Preview</p></td><td><p>$0.50</p></td><td><p>$3.00</p></td><td><p><b>$3.50</b></p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Kimi-k2.5</p></td><td><p>$0.60</p></td><td><p>$3.00</p></td><td><p><b>$3.60</b></p></td><td><p><a href=\"https://platform.moonshot.ai/docs/pricing/chat#billing-logic\">Moonshot</a></p></td></tr><tr><td><p><b>GLM-5</b></p></td><td><p><b>$1.00</b></p></td><td><p><b>$3.20</b></p></td><td><p><b>$4.20</b></p></td><td><p><a href=\"https://docs.z.ai/guides/overview/pricing\"><b>Z.ai</b></a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p><b>$4.25</b></p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p><b>$6.00</b></p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen3-Max (2026-01-23)</p></td><td><p>$1.20</p></td><td><p>$6.00</p></td><td><p><b>$7.20</b></p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (\u2264200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p><b>$14.00</b></p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>GPT-5.2</p></td><td><p>$1.75</p></td><td><p>$14.00</p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\">OpenAI</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p><b>$18.00</b></p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p><b>$22.00</b></p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Opus 4.6</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p><b>$30.00</b></p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>GPT-5.2 Pro</p></td><td><p>$21.00</p></td><td><p>$168.00</p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\">OpenAI</a></p></td></tr></tbody></table><p>This is roughly 6x cheaper on input and nearly 10x cheaper on output than Claude Opus 4.6 ($5/$25). This release confirms rumors that Zhipu AI was behind &quot;Pony Alpha,&quot; a stealth model that previously crushed coding benchmarks on OpenRouter.</p><p>However, despite the high benchmarks and low cost, not all early users are enthusiastic about the model, noting its high performance doesn&#x27;t tell the whole story. </p><p>Lukas Petersson, co-founder of the safety-focused autonomous AI protocol startup Andon Labs, <a href=\"https://x.com/lukaspet/status/2021634344738328871\">remarked on X</a>: <i>&quot;After hours of reading GLM-5 traces: an incredibly effective model, but far less situationally aware. Achieves goals via aggressive tactics but doesn&#x27;t reason about its situation or leverage experience. This is scary. This is how you get a paperclip maximizer.&quot;</i></p><p>The &quot;paperclip maximizer&quot; refers to a hypothetical situation <a href=\"https://nickbostrom.com/ethics/ai\">described by Oxford philosopher Nick Bostrom back in 2003</a>, in which an AI or other autonomous creation accidentally leads to an apocalyptic scenario or human extinction by following a seemingly benign instruction \u2014 like maximizing the number of paperclips produced \u2014 to an extreme degree, redirecting all resources necessary for human (or other life) or otherwise making life impossible through its commitment to fulfilling the seemingly benign objective. </p><h2><b>Should your enterprise adopt GLM-5?</b></h2><p>Enterprises seeking to escape vendor lock-in will find GLM-5\u2019s MIT License and open-weights availability a significant strategic advantage. Unlike closed-source competitors that keep intelligence behind proprietary walls, GLM-5 allows organizations to host their own frontier-level intelligence.</p><p>Adoption is not without friction. The sheer scale of GLM-5\u2014744B parameters\u2014requires a massive hardware floor that may be out of reach for smaller firms without significant cloud or on-premise GPU clusters. </p><p>Security leaders must weigh the geopolitical implications of a flagship model from a China-based lab, especially in regulated industries where data residency and provenance are strictly audited.</p><p>Furthermore, the shift toward more autonomous AI agents introduces new governance risks. As models move from &quot;chat&quot; to &quot;work,&quot; they begin to operate across apps and files autonomously. Without the robust agent-specific permissions and human-in-the-loop quality gates established by enterprise data leaders, the risk of autonomous error increases exponentially.</p><p>Ultimately, GLM-5 is a &quot;buy&quot; for organizations that have outgrown simple copilots and are ready to build a truly autonomous office.</p><p>It is for engineers who need to refactor a legacy backend or requires a &quot;self-healing&quot; pipeline that doesn&#x27;t sleep.</p><p>While Western labs continue to optimize for &quot;Thinking&quot; and reasoning depth, Zai is optimizing for execution and scale. </p><p>Enterprises that adopt GLM-5 today are not just buying a cheaper model; they are betting on a future where the most valuable AI is the one that can finish the project without being asked twice.</p>", "url": "https://venturebeat.com/technology/z-ais-open-source-glm-5-achieves-record-low-hallucination-rate-and-leverages", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents", "governance"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Chinese AI startup Zhupai aka z.ai is back this week with an eye-popping new frontier large language model: <a href=\"https://x.com/Zai_org/status/2021638634739527773\">GLM-5</a>.</p><p>The latest in z.ai&#x27;s ongoing and continually impressive GLM series, it retains an open source MIT License \u2014 "]}
{"id": "source:rss:6168579542", "title": "Anthropic\u2019s Claude Cowork finally lands on Windows \u2014 and it wants to automate your workday", "summary": "<p><a href=\"https://www.anthropic.com/\">Anthropic</a> released its <a href=\"https://www.anthropic.com/webinars/future-of-ai-at-work-introducing-cowork\">Claude Cowork</a> AI agent software for <a href=\"https://www.microsoft.com/en-us/windows?r=1\">Windows</a> on Monday, bringing the file management and task automation tool to <a href=\"https://www.computerworld.com/article/1682500/windows-by-the-numbers-windows-10-rolls-on-past-70.html\">roughly 70 percent</a> of the desktop computing market and intensifying a remarkable corporate realignment that has seen Microsoft embrace a direct competitor to its longtime AI partner, OpenAI.</p><p>The Windows launch arrives with what Anthropic calls &quot;full feature parity&quot; with the macOS version: file access, multi-step task execution, plugins, and <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">Model Context Protocol</a> (MCP) connectors for integrating external services. Users can now also set global and folder-specific instructions that Claude follows in every session, a feature developers on Reddit described as &quot;a game-changer&quot; for maintaining context across projects.</p><p>&quot;Cowork is now available on Windows,&quot; Anthropic announced on X. &quot;We&#x27;re bringing full feature parity with MacOS: file access, multi-step task execution, plugins, and MCP connectors.&quot;</p><p>The release closes a critical platform gap that had limited <a href=\"https://venturebeat.com/orchestration/openai-launches-a-codex-desktop-app-for-macos-to-run-multiple-ai-coding\">Cowork to Apple&#x27;s operating system</a> since its January 12 debut. The Windows expansion underscores a broader transformation already underway in enterprise AI, with Microsoft simultaneously selling its own <a href=\"https://github.com/features/copilot\">GitHub Copilot</a> to customers while encouraging thousands of its own employees to adopt Anthropic&#x27;s competing tools internally.</p><div></div><h2><b>Inside Microsoft&#x27;s surprising pivot toward its biggest AI rival</b></h2><p>The relationship between <a href=\"https://www.microsoft.com/en-us\">Microsoft</a> and <a href=\"https://www.anthropic.com/\">Anthropic</a> has accelerated with striking speed. In November, the two companies announced a <a href=\"https://www.anthropic.com/news/claude-in-microsoft-foundry\">strategic partnership</a> allowing Microsoft Foundry customers access to Claude Sonnet 4.5, Claude Opus 4.1, and Claude Haiku 4.5. As part of that arrangement, Anthropic committed to purchasing $30 billion of Azure compute capacity.</p><p>But the partnership has expanded well beyond cloud hosting. According to a January 22 report in <a href=\"https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad\">The Verge</a>, Microsoft has begun encouraging thousands of employees from some of its most prolific teams to adopt <a href=\"https://claude.com/product/claude-code\">Claude Code</a> \u2014 and now, by extension, <a href=\"https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no\">Cowork</a> \u2014 even if they have no coding experience.</p><p>Microsoft&#x27;s CoreAI team, the new AI engineering group led by former Meta engineering chief Jay Parikh, has tested Claude Code in recent months, The Verge reported. The company has also approved Claude Code across all code and repositories for its Business and Industry Copilot teams.</p><p>&quot;Software engineers at Microsoft are now expected to use both Claude Code and GitHub Copilot and give feedback comparing the two,&quot; <a href=\"https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad\">The Verge reported</a>.</p><p>The company&#x27;s spending on Anthropic approaches $500 million annually, according to <a href=\"https://www.theinformation.com/articles/microsofts-spending-anthropic-ai-pace-hit-500-million\">The Information</a>. Microsoft has even begun counting Anthropic AI model sales toward Azure sales quotas \u2014 an unusual incentive structure that the company typically reserves for homegrown products or models from OpenAI.</p><h2><b>A $13 billion partnership faces new questions as Microsoft hedges its bets</b></h2><p>Microsoft&#x27;s embrace of Anthropic raises uncomfortable questions about its <a href=\"https://www.cnbc.com/2024/08/10/rise-of-openai-microsofts-13-billion-artificial-intelligence-bet.html\">$13 billion investment in OpenAI</a>, which has long served as the exclusive provider of frontier AI models for Microsoft&#x27;s products. The two companies signed their <a href=\"https://news.microsoft.com/source/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/\">landmark partnership</a> in 2019, with Microsoft providing Azure computing infrastructure in exchange for preferential access to OpenAI&#x27;s technology.</p><p>That relationship now appears to be evolving into something more nuanced. Microsoft has started favoring Anthropic&#x27;s Claude models inside Microsoft 365 apps and Copilot recently, deploying them in specific applications or features where Anthropic&#x27;s models have proven more capable than OpenAI&#x27;s counterparts.</p><p>On February 5, Microsoft announced that Claude Opus 4.6 \u2014 Anthropic&#x27;s most advanced model \u2014 would become <a href=\"https://azure.microsoft.com/en-us/blog/claude-opus-4-6-anthropics-powerful-model-for-coding-agents-and-enterprise-workflows-is-now-available-in-microsoft-foundry-on-azure/\">available in Microsoft Foundry</a>, the company&#x27;s enterprise AI platform. The Azure blog post framed the integration as bringing &quot;even more capability to agents that increasingly learn from and act on business systems.&quot;</p><p>&quot;At Microsoft we believe that intelligence and trust are the core requirements of agentic AI at scale,&quot; the announcement stated. &quot;Built on Azure, Microsoft Foundry brings these capabilities together on a secure, scalable cloud foundation for enterprise AI.&quot;</p><p>The timing and tone suggest Microsoft views Anthropic not merely as a hedging strategy but as a genuine technical leader in certain domains. <a href=\"https://venturebeat.com/article-pv/anthropics-claude-opus-4-6-brings-1m-token-context-and-agent-teams-to-take\">Claude Opus 4.6</a> offers a one-million-token context window and 128,000-token maximum output \u2014 specifications that position it for complex, long-running enterprise tasks that require processing vast amounts of information.</p><h2><b>Why a $285 billion stock selloff has the software industry questioning its future</b></h2><p>The deepening Microsoft-Anthropic alliance takes on added significance when viewed against a backdrop of genuine alarm rippling through the software industry. Within days of the <a href=\"https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no\">macOS launch in January</a>, investors began repricing SaaS companies whose products overlap with Cowork&#x27;s capabilities \u2014 project management tools, writing assistants, data analysis platforms, and workflow automation software all saw sharp declines.</p><p>Bloomberg reported that Cowork <a href=\"https://sg.finance.yahoo.com/news/anthropic-ai-tool-sparks-selloff-143304538.html\">triggered a $285 billion software stocks selloff</a>. The carnage reflected growing investor conviction that AI agents capable of automating knowledge work could render entire categories of enterprise software obsolete.</p><p>The fear is not abstract. Cowork operates as a desktop agent powered by <a href=\"https://www.anthropic.com/news/claude-opus-4-6\">Claude Opus 4.6</a> that can read local files, execute multi-step tasks, and interact with external services through plugins \u2014 all running directly on a user&#x27;s machine. Unlike chatbot interfaces that respond to individual prompts, Cowork plans and executes complete workflows across files, applications, and connected services.</p><p>Anthropic has leaned into this positioning. On January 30, the company&#x27;s Anthropic Labs division released <a href=\"https://techcrunch.com/2026/01/30/anthropic-brings-agentic-plugins-to-cowork/\">11 open-source agentic plugins</a> spanning sales, legal, finance, marketing, data analysis, and software development. These plugins connect Cowork to external tools, enabling the agent to pull data from CRMs, draft legal documents, analyze spreadsheets, or manage project boards without users switching applications.</p><h2><b>The hidden risks of giving an AI agent access to your files</b></h2><p>Such convenience comes with tradeoffs, and Anthropic has been transparent about the risks inherent in agent software that can read, write, and delete files. The company&#x27;s support documentation warns users to &quot;be cautious about granting access to sensitive information like financial documents, credentials, or personal records&quot; and suggests saving backups and creating dedicated folders with nonsensitive information.</p><p>Cowork remains susceptible to <a href=\"https://www.anthropic.com/research/prompt-injection-defenses\">prompt injection attacks</a> \u2014 hidden instructions embedded in documents or websites that can hijack AI agents and redirect their actions. The browser automation feature includes an explicit disclaimer warning that hidden code in websites may &quot;steal your data, inject malware into your systems, or take over your system.&quot;</p><p>&quot;We use a virtual machine under the hood,&quot; Boris Cherny, Anthropic&#x27;s head of Claude Code, told <a href=\"https://www.wired.com/story/claude-code-success-anthropic-business-model/\">Wired</a>. &quot;This means you have to say which folders Claude has access to. And if you don&#x27;t give it access to a folder, Claude literally cannot see that folder.&quot;</p><p>The <a href=\"https://support.claude.com/en/articles/13345190-getting-started-with-cowork\">Windows version</a> includes additional safety constraints. According to user reports on Reddit, Cowork on Windows restricts file access to the user&#x27;s personal folder, preventing the agent from accessing common development directories like C:\\git. While some users expressed frustration at this limitation, others noted it as a prudent safeguard for less technical users.</p><p>&quot;To be fair, seeing how many people nuked themselves with Claude Code, it is much safer to limit people to reduce the collateral damage,&quot; <a href=\"https://www.reddit.com/r/ClaudeAI/comments/1r1gwj8/cowork_is_now_available_on_windows/\">wrote one Reddit user</a>.</p><h2><b>Major corporations are already betting on Claude&#x27;s enterprise potential</b></h2><p>Despite the security caveats, early enterprise adoption suggests meaningful interest. <a href=\"https://azure.microsoft.com/en-us/blog/claude-opus-4-6-anthropics-powerful-model-for-coding-agents-and-enterprise-workflows-is-now-available-in-microsoft-foundry-on-azure/\">Customer testimonials</a> published alongside the Claude Opus 4.6 announcement on the Microsoft Azure blog included statements from Adobe, Dentons, and other major organizations already integrating Anthropic&#x27;s technology into their workflows.</p><p>&quot;At Adobe, we&#x27;re continuously evaluating new AI capabilities that can help us deliver more powerful, responsible, and intuitive experiences for our customers,&quot; said Michael Marth, VP Engineering for Experience Manager and LLM Optimizer. &quot;Foundry gives us a flexible, enterprise-ready environment to explore frontier models while maintaining the trust, governance, and scale that are critical for Adobe.&quot;</p><p>Matej Jambrich, CTO of Dentons Europe, described deploying Claude for legal work: &quot;Better model reasoning reduces rework and improves consistency, so our lawyers can focus on higher value judgment.&quot;</p><p>On Reddit, an Anthropic representative wrote that the Windows release addresses &quot;<a href=\"https://www.reddit.com/r/ClaudeAI/comments/1r1gwj8/cowork_is_now_available_on_windows/\">the most consistent request</a>&quot; since Cowork&#x27;s macOS debut \u2014 a demand that came &quot;especially from enterprise teams.&quot; The detail underscores the tool&#x27;s perceived value in corporate environments where Windows dominates the desktop landscape.</p><h2><b>At $20 a month, Cowork positions itself as a premium productivity play</b></h2><p>Access to these capabilities comes at a price. Cowork for Windows is available in research preview at <a href=\"http://claude.com/cowork\">claude.com/cowork</a> for all paid <a href=\"https://support.claude.com/en/articles/11049762-choosing-a-claude-plan\">Claude subscription tiers</a>, including Pro ($20/month), Max ($100/month), Team, and Enterprise. Free-tier users cannot access the feature.</p><p>This pricing structure positions Cowork as a premium productivity tool rather than a mass-market offering \u2014 at least for now. Anthropic has not announced plans for broader availability, and the &quot;research preview&quot; designation suggests the company continues to gather user feedback before committing to a general release.</p><p>The <a href=\"https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no\">January macOS launch</a> was similarly restricted to $100/month Max subscribers before expanding to other paid tiers, suggesting Anthropic may follow a gradual rollout strategy as it refines the product. For enterprise customers evaluating the tool, the pricing represents a fraction of what many pay for traditional software licenses\u2014a calculus that could accelerate adoption if Cowork delivers on its automation promises.</p><h2><b>The battle for the future of work has a new front line</b></h2><p>For Microsoft, the deepening Anthropic partnership reflects a pragmatic recognition that AI leadership may require embracing multiple frontier providers rather than relying exclusively on a single partner.</p><p>The company&#x27;s willingness to deploy Claude tools internally while selling GitHub Copilot externally suggests confidence that the enterprise market can accommodate competing approaches \u2014 or perhaps an acknowledgment that betting everything on OpenAI carries its own risks.</p><p>For the broader software industry, Cowork&#x27;s expansion to Windows extends the competitive threat to an even larger installed base. Companies whose value propositions rest on task automation, file management, or workflow orchestration now face a well-funded competitor capable of replicating their core functionality through natural language commands.</p><p>The $285 billion in market capitalization that evaporated after Cowork&#x27;s January launch may prove to be just an opening salvo. With Windows support now live, Anthropic has removed the last major platform barrier between its AI agent and the enterprise customers most likely to adopt it.</p><p>The software industry spent decades building tools to help knowledge workers manage files, automate tasks, and organize information. Now it faces a future where a single application, powered by an AI that learns and improves with every interaction, threatens to do all of that and more. The question is no longer whether AI agents will reshape enterprise software, but how much of the old world will survive the transformation.</p>", "url": "https://venturebeat.com/technology/anthropics-claude-cowork-finally-lands-on-windows-and-it-wants-to-automate", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents", "governance"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p><a href=\"https://www.anthropic.com/\">Anthropic</a> released its <a href=\"https://www.anthropic.com/webinars/future-of-ai-at-work-introducing-cowork\">Claude Cowork</a> AI agent software for <a href=\"https://www.microsoft.com/en-us/windows?r=1\">Windows</a> on Monday, bringing the file management an"]}
{"id": "source:rss:7784306149", "title": "Railway secures $100 million to challenge AWS with AI-native cloud infrastructure", "summary": "<p><a href=\"https://railway.com/\">Railway</a>, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.</p><p><a href=\"https://tq.vc/\">TQ Ventures</a> led the round, with participation from <a href=\"https://fpvventures.com/\">FPV Ventures</a>, <a href=\"https://www.redpoint.com/\">Redpoint</a>, and <a href=\"https://www.unusual.vc/\">Unusual Ventures</a>. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like <a href=\"https://aws.amazon.com/\">Amazon Web Services</a> and <a href=\"https://cloud.google.com/\">Google Cloud</a>.</p><p>&quot;As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?&quot; said Jake Cooper, Railway&#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. &quot;The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&#x27;t keep up.&quot;</p><p>The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a <a href=\"https://techcrunch.com/2022/05/31/railway-snags-20m-to-streamline-the-process-of-deploying-apps-and-services/\">$20 million Series A</a> from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network \u2014 metrics that rival far larger and better-funded competitors.</p><h2><b>Why three-minute deploy times have become unacceptable in the age of AI coding assistants</b></h2><p>Railway&#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using <a href=\"https://station.railway.com/feedback/terraform-provider-954567d7\">Terraform</a>, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like <a href=\"https://claude.ai/login\">Claude</a>, <a href=\"https://chatgpt.com/\">ChatGPT</a>, and <a href=\"https://cursor.com/\">Cursor</a> can generate working code in seconds.</p><p>&quot;When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,&quot; Cooper told VentureBeat. &quot;What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.&quot;</p><p>The company claims its platform delivers deployments in under one second \u2014 fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.</p><p>These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.</p><p>&quot;The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,&quot; Lobaton said. &quot;If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.&quot;</p><h2><b>Inside the controversial decision to abandon Google Cloud and build data centers from scratch</b></h2><p>What distinguishes <a href=\"https://railway.com/\">Railway</a> from competitors like <a href=\"https://render.com/\">Render</a> and <a href=\"http://fly.io\">Fly.io</a> is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: &quot;People who are really serious about software should make their own hardware.&quot;</p><p>&quot;We wanted to design hardware in a way where we could build a differentiated experience,&quot; Cooper said. &quot;Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &#x27;agentic speed&#x27; while staying 100 percent the smoothest ride in town.&quot;</p><p>The approach paid dividends during recent <a href=\"https://restofworld.org/2026/cloud-outages-2025-global-business-impact/\">widespread outages</a> that affected major cloud providers \u2014 Railway remained online throughout.</p><p>This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines \u2014 a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.</p><p>&quot;The conventional wisdom is that the big guys have economies of scale to offer better pricing,&quot; Cooper noted. &quot;But when they&#x27;re charging for VMs that usually sit idle in the cloud, and we&#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.&quot;</p><h2><b>How 30 employees built a platform generating tens of millions in annual revenue</b></h2><p><a href=\"https://railway.com/\">Railway</a> has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue \u2014 a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.</p><p>Cooper emphasized that the fundraise was strategic rather than necessary. &quot;We&#x27;re default alive; there&#x27;s no reason for us to raise money,&quot; he said. &quot;We raised because we see a massive opportunity to accelerate, not because we needed to survive.&quot;</p><p>The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&#x27;s two million users discovered the platform through word of mouth \u2014 developers telling other developers about a tool that actually works.</p><p>&quot;We basically did the standard engineering thing: if you build it, they will come,&quot; Cooper recalled. &quot;And to some degree, they came.&quot;</p><h2><b>From side projects to Fortune 500 deployments: Railway&#x27;s unlikely corporate expansion</b></h2><p>Despite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.</p><p>Notable customers include <a href=\"https://www.biltrewards.com/\">Bilt</a>, the loyalty program company; Intuit&#x27;s <a href=\"https://www.goco.io/\">GoCo</a> subsidiary; TripAdvisor&#x27;s <a href=\"https://www.cruisecritic.com/\">Cruise Critic</a>; and <a href=\"https://www.mgmresorts.com/en.html\">MGM Resorts</a>. <a href=\"https://www.ycombinator.com/companies/kernel\">Kernel</a>, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.</p><p>&quot;At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,&quot; said Rafael Garcia, Kernel&#x27;s chief technology officer. &quot;Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.&quot;</p><p>For enterprise customers, <a href=\"https://railway.com/\">Railway</a> offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&#x27;s existing cloud environment through a &quot;bring your own cloud&quot; configuration.</p><p>Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).</p><h2><b>The startup&#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivals</b></h2><p>Railway enters a crowded market that includes not only the hyperscale cloud providers\u2014Amazon Web Services, Microsoft Azure, and Google Cloud Platform\u2014but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.</p><p>Cooper argues that Railway&#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.</p><p>&quot;The hyperscalers have two competing systems, and they haven&#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,&quot; he observed. &quot;They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&#x27;t really need to?&quot;</p><p>Against startup competitors, Railway differentiates by covering the full infrastructure stack. &quot;We&#x27;re not just containers; we&#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,&quot; Cooper said. &quot;And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.&quot;</p><p>The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.</p><h2><b>Why investors are betting that AI will create a thousand times more software than exists today</b></h2><p>Railway&#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, <a href=\"https://cursor.com/agents\">Cursor</a>, and <a href=\"https://claude.ai/login\">Claude</a> become standard fixtures in developer workflows, the volume of code being written \u2014 and the infrastructure needed to run it \u2014 is expanding dramatically.</p><p>&quot;The amount of software that&#x27;s going to come online over the next five years is unfathomable compared to what existed before \u2014 we&#x27;re talking a thousand times more software,&quot; Cooper predicted. &quot;All of that has to run somewhere.&quot;</p><p>The company has already integrated directly with AI systems, building what Cooper calls &quot;loops where Claude can hook in, call deployments, and analyze infrastructure automatically.&quot; Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.</p><p>&quot;The notion of a developer is melting before our eyes,&quot; Cooper said. &quot;You don&#x27;t have to be an engineer to engineer things anymore \u2014 you just need critical thinking and the ability to analyze things in a systems capacity.&quot;</p><h2><b>What Railway plans to do with $100 million and zero marketing experience</b></h2><p><a href=\"https://railway.com/\">Railway</a> plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&#x27;s five-year history.</p><p>&quot;One of my mentors said you raise money when you can change the trajectory of the business,&quot; Cooper explained. &quot;We&#x27;ve built all the required substrate to scale indefinitely; what&#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.&quot;</p><p>The company&#x27;s investor roster reads like a who&#x27;s who of developer infrastructure. Angel investors include <a href=\"https://tom.preston-werner.com/\">Tom Preston-Werner,</a> co-founder of GitHub; <a href=\"https://rauchg.com/about\">Guillermo Rauch</a>, chief executive of Vercel; <a href=\"https://www.cockroachlabs.com/author/spencer-kimball/\">Spencer Kimball</a>, chief executive of Cockroach Labs; <a href=\"https://www.datadoghq.com/about/leadership/\">Olivier Pomel</a>, chief executive of Datadog; and <a href=\"https://sequoiacap.com/founder/jori-lallo/\">Jori Lallo</a>, co-founder of Linear.</p><p>The timing of Railway&#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities \u2014 they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.</p><p>Whether <a href=\"https://railway.com/\">Railway</a> can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at <a href=\"https://www.wolframalpha.com/\">Wolfram Alpha</a>, <a href=\"https://www.bloomberg.com/\">Bloomberg</a>, and <a href=\"https://www.uber.com/\">Uber</a> before founding Railway in 2020, seems unfazed by the scale of his ambition.</p><p>&quot;In five years, Railway [will be] the place where software gets created and evolved, period,&quot; he said. &quot;Deploy instantly, scale infinitely, with zero friction. That&#x27;s the prize worth playing for, and there&#x27;s no bigger one on offer.&quot;</p><p>For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates \u2014 no marketing, no sales team, no venture hype\u2014the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.</p>", "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud", "published_at": "Thu, 22 Ja", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p><a href=\"https://railway.com/\">Railway</a>, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applic"]}
{"id": "source:rss:8790360241", "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.", "summary": "<p>The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.</p><p><a href=\"https://claude.com/product/claude-code\">Claude Code</a>, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its <a href=\"https://claude.com/pricing\">pricing</a> \u2014 ranging from $20 to $200 per month depending on usage \u2014 has sparked a growing rebellion among the very programmers it aims to serve.</p><p>Now, a free alternative is gaining traction. <a href=\"https://block.github.io/goose/\">Goose</a>, an open-source AI agent developed by <a href=\"https://block.xyz/\">Block</a> (the financial technology company formerly known as Square), offers nearly identical functionality to <a href=\"https://claude.com/product/claude-code\">Claude Code</a> but runs entirely on a user&#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.</p><p>&quot;Your data stays with you, period,&quot; said Parth Sareen, a software engineer who demonstrated the tool during a <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">recent livestream</a>. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline \u2014 even on an airplane.</p><p>The project has exploded in popularity. Goose now boasts more than <a href=\"https://github.com/block/goose\">26,100 stars on GitHub</a>, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, <a href=\"https://block.github.io/goose/docs/getting-started/installation\">1.20.1</a>, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.</p><p>For developers frustrated by Claude Code&#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.</p><div></div><h2><b>Anthropic&#x27;s new rate limits spark a developer revolt</b></h2><p>To understand why <a href=\"https://block.github.io/goose/\">Goose</a> matters, you need to understand the <a href=\"https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/\">Claude Code pricing controversy</a>.</p><p>Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The <a href=\"https://www.anthropic.com/news/claude-pro\">Pro plan</a>, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours \u2014 a constraint that serious developers exhaust within minutes of intensive work.</p><p>The <a href=\"https://support.claude.com/en/articles/11049741-what-is-the-max-plan\">Max plans</a>, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&#x27;s most powerful model, <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>. But even these premium tiers come with restrictions that have inflamed the developer community.</p><p>In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.</p><p>The problem? Those &quot;hours&quot; are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.</p><p>&quot;It&#x27;s confusing and vague,&quot; one developer wrote in a <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">widely shared analysis</a>. &quot;When they say &#x27;24-40 hours of Opus 4,&#x27; that doesn&#x27;t really tell you anything useful about what you&#x27;re actually getting.&quot;</p><p>The <a href=\"https://www.reddit.com/r/Anthropic/comments/1mbo4uw/claude_code_max_new_weekly_rate_limits/\">backlash on Reddit</a> and <a href=\"https://venturebeat.com/ai/anthropic-throttles-claude-rate-limits-devs-call-foul\">developer forums</a> has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions &quot;a joke&quot; and &quot;unusable for real work.&quot;</p><p>Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code &quot;<a href=\"https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/\">continuously in the background, 24/7</a>.&quot; But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users \u2014 a distinction that matters enormously.</p><h2><b>How Block built a free AI coding agent that works offline</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> takes a radically different approach to the same problem.</p><p>Built by <a href=\"https://block.xyz/\">Block</a>, the payments company led by Jack Dorsey, Goose is what engineers call an &quot;<a href=\"https://github.com/block/goose\">on-machine AI agent</a>.&quot; Unlike Claude Code, which sends your queries to Anthropic&#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.</p><p>The project&#x27;s documentation describes it as going &quot;<a href=\"https://github.com/block/goose\">beyond code suggestions</a>&quot; to &quot;install, execute, edit, and test with any LLM.&quot; That last phrase \u2014 &quot;any LLM&quot; \u2014 is the key differentiator. Goose is model-agnostic by design.</p><p>You can connect Goose to Anthropic&#x27;s <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude models</a> if you have <a href=\"https://claude.com/platform/api\">API access</a>. You can use OpenAI&#x27;s <a href=\"https://platform.openai.com/docs/models/gpt-5\">GPT-5</a> or Google&#x27;s <a href=\"https://ai.google.dev/gemini-api/docs\">Gemini</a>. You can route it through services like <a href=\"https://groq.com/\">Groq</a> or <a href=\"https://openrouter.ai/\">OpenRouter</a>. Or \u2014 and this is where things get interesting \u2014 you can run it entirely locally using tools like <a href=\"https://ollama.com/\">Ollama</a>, which let you download and execute open-source models on your own hardware.</p><p>The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.</p><p>&quot;I use Ollama all the time on planes \u2014 it&#x27;s a lot of fun!&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen noted</a> during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.</p><h2><b>What Goose can do that traditional code assistants can&#x27;t</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs \u2014 all without constant human oversight.</p><p>The architecture relies on what the AI industry calls &quot;<a href=\"https://www.ibm.com/think/topics/tool-calling\">tool calling</a>&quot; or &quot;<a href=\"https://platform.openai.com/docs/guides/function-calling?api-mode=chat\">function calling</a>&quot; \u2014 the ability for a language model to request specific actions from external systems. When you ask <a href=\"https://block.github.io/goose/\">Goose</a> to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&#x27;t just generate text describing what should happen. It actually executes those operations.</p><p>This capability depends heavily on the underlying language model. <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude 4 models</a> from Anthropic currently perform best at tool calling, according to the <a href=\"https://gorilla.cs.berkeley.edu/leaderboard.html\">Berkeley Function-Calling Leaderboard</a>, which ranks models on their ability to translate natural language requests into executable code and system commands.</p><p>But newer open-source models are catching up quickly. Goose&#x27;s documentation highlights several options with strong tool-calling support: Meta&#x27;s <a href=\"https://www.llama.com/\">Llama series</a>, Alibaba&#x27;s <a href=\"https://qwen.ai/home\">Qwen models</a>, Google&#x27;s <a href=\"https://deepmind.google/models/gemma/\">Gemma variants</a>, and DeepSeek&#x27;s <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\">reasoning-focused architectures</a>.</p><p>The tool also integrates with the <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">Model Context Protocol</a>, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs \u2014 extending its capabilities far beyond what the base language model provides.</p><h2><b>Setting Up Goose with a Local Model</b></h2><p>For developers interested in a completely free, privacy-preserving setup, the process involves three main components: <a href=\"https://block.github.io/goose/\">Goose</a> itself, <a href=\"https://ollama.com/\">Ollama</a> (a tool for running open-source models locally), and a compatible language model.</p><p><b>Step 1: Install Ollama</b></p><p><a href=\"https://ollama.com/\">Ollama</a> is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.</p><p>Download and install Ollama from <a href=\"http://ollama.com\">ollama.com</a>. Once installed, you can pull models with a single command. For coding tasks, <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a> offers strong tool-calling support:</p><p>ollama run qwen2.5</p><p>The model downloads automatically and begins running on your machine.</p><p><b>Step 2: Install Goose</b></p><p><a href=\"https://block.github.io/goose/\">Goose</a> is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.</p><p>Installation instructions vary by operating system but generally involve downloading from Goose&#x27;s <a href=\"https://github.com/block/goose\">GitHub releases page</a> or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.</p><p><b>Step 3: Configure the Connection</b></p><p>In Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&#x27;s default port) and click Submit.</p><p>For the command-line version, run goose configure, select &quot;Configure Providers,&quot; choose Ollama, and enter the model name when prompted.</p><p>That&#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.</p><h2><b>The RAM, processing power, and trade-offs you should know about</b></h2><p>The obvious question: what kind of computer do you need?</p><p>Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory \u2014 specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.</p><p>Block&#x27;s <a href=\"https://block.github.io/goose/docs/category/guides\">documentation</a> suggests that 32 gigabytes of RAM provides &quot;a solid baseline for larger models and outputs.&quot; For Mac users, this means the computer&#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.</p><p>But you don&#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a>, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.</p><p>&quot;You don&#x27;t need to run the largest models to get excellent results,&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen emphasized</a>. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.</p><p>For context, Apple&#x27;s entry-level <a href=\"https://www.apple.com/macbook-air/\">MacBook Air</a> with 8 gigabytes of RAM would struggle with most capable coding models. But a <a href=\"https://www.apple.com/macbook-pro/\">MacBook Pro</a> with 32 gigabytes \u2014 increasingly common among professional developers \u2014 handles them comfortably.</p><h2><b>Why keeping your code off the cloud matters more than ever</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> with a local LLM is not a perfect substitute for <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. The comparison involves real trade-offs that developers should understand.</p><p><b>Model Quality</b>: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>, Anthropic&#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists \u2014 particularly for the most challenging tasks.</p><p>One developer who switched to the $200 Claude Code plan <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">described the difference bluntly</a>: &quot;When I say &#x27;make this look modern,&#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.&quot;</p><p><b>Context Window</b>: <a href=\"https://www.anthropic.com/news/claude-sonnet-4-5\">Claude Sonnet 4.5</a>, accessible through the API, offers a massive one-million-token context window \u2014 enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.</p><p><b>Speed</b>: Cloud-based services like <a href=\"https://claude.com/product/claude-code\">Claude Code</a> run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&#x27;re making rapid changes and waiting for AI feedback.</p><p><b>Tooling Maturity</b>: <a href=\"https://claude.com/product/claude-code\">Claude Code</a> benefits from Anthropic&#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. <a href=\"https://block.github.io/goose/\">Goose</a>, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.</p><h2><b>How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market</b></h2><p>Goose enters a crowded market of AI coding tools, but occupies a distinctive position.</p><p><a href=\"https://cursor.com/\">Cursor</a>, a popular AI-enhanced code editor, charges $20 per month for its <a href=\"https://cursor.com/pricing\">Pro tier</a> and $200 for <a href=\"https://cursor.com/pricing\">Ultra</a>\u2014pricing that mirrors <a href=\"https://claude.com/pricing\">Claude Code&#x27;s Max plans</a>. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&#x27;s hourly resets.</p><p><a href=\"https://cline.bot/\">Cline</a>, <a href=\"https://roocode.com/\">Roo Code</a>, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.</p><p>Amazon&#x27;s <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\">CodeWhisperer</a>, <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.</p><p>Goose&#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&#x27;s competing on freedom \u2014 both financial and architectural.</p><h2><b>The $200-a-month era for AI coding tools may be ending</b></h2><p>The AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&#x27;s <a href=\"https://www.kimi.com/en\">Kimi K2</a> and z.ai&#x27;s <a href=\"https://z.ai/blog/glm-4.5\">GLM 4.5</a> now benchmark near <a href=\"https://www.anthropic.com/news/claude-4\">Claude Sonnet 4 levels</a> \u2014 and they&#x27;re freely available.</p><p>If this trajectory continues, the quality advantage that justifies Claude Code&#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.</p><p>For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in <a href=\"https://block.github.io/goose/\">Goose</a>.</p><p>The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.</p><p>Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.</p><p>But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.</p><hr /><p><i>Goose is available for download at </i><a href=\"http://github.com/block/goose\"><i>github.com/block/goose</i></a><i>. Ollama is available at </i><a href=\"http://ollama.com\"><i>ollama.com</i></a><i>. Both projects are free and open source.</i></p>", "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free", "published_at": "Mon, 19 Ja", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.</p><p><a href=\"https://claude.com/product/claude-code\">Claude Code</a>, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software dev"]}
{"id": "source:rss:6249538022", "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews", "summary": "<p>Alfred Wahlforss was running out of options. His startup, <a href=\"https://listenlabs.ai/\">Listen Labs</a>, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s <a href=\"https://news.bloomberglaw.com/employee-benefits/zuckerbergs-100-million-ai-job-offers-pay-off-parmy-olson\">$100 million offers</a> seemed impossible. So he spent $5,000 \u2014 a fifth of his marketing budget \u2014 on a <a href=\"https://billboardinsider.com/ai-startup/\">billboard in San Francisco</a> displaying what looked like gibberish: five strings of random numbers.</p><p>The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.</p><p>That unconventional approach has now attracted $69 million in Series B funding, led by <a href=\"https://www.ribbitcap.com/\">Ribbit Capital</a> with participation from <a href=\"https://www.evantic.ai/\">Evantic</a> and existing investors <a href=\"https://sequoiacap.com/\">Sequoia Capital</a>, <a href=\"https://www.conviction.com/\">Conviction</a>, and <a href=\"https://pear.vc/\">Pear VC</a>. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.</p><div></div><p>&quot;When you obsess over customers, everything else follows,&quot; Wahlforss said in an interview with VentureBeat. &quot;Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.&quot;</p><h2><b>Why traditional market research is broken, and what Listen Labs is building to fix it</b></h2><p>Listen&#x27;s <a href=\"https://listenlabs.ai/role/agencies\">AI researcher</a> finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys \u2014 which provide statistical precision but miss nuance\u2014and qualitative interviews, which deliver depth but cannot scale.</p><p>Wahlforss explained the limitation of existing approaches: &quot;Essentially surveys give you false precision because people end up answering the same question... You can&#x27;t get the outliers. People are actually not honest on surveys.&quot; The alternative, one-on-one human interviews, &quot;gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they&#x27;re talking about. And the problem is you can&#x27;t scale that.&quot;</p><p>The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.</p><p>What distinguishes Listen&#x27;s approach is its use of open-ended video conversations rather than multiple-choice forms. &quot;In a survey, you can kind of guess what you should answer, and you have four options,&quot; Wahlforss said. &quot;Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.&quot;</p><h2><b>The dirty secret of the $140 billion market research industry: rampant fraud</b></h2><p><a href=\"https://listenlabs.ai/\">Listen</a> finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called &quot;one of the most shocking things that we&#x27;ve learned when we entered this industry&quot;\u2014rampant fraud.</p><p>&quot;Essentially, there&#x27;s a financial transaction involved, which means there will be bad players,&quot; he explained. &quot;We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.&quot;</p><p>The company built what it calls a &quot;quality guard&quot; that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: &quot;People talk three times more. They&#x27;re much more honest when they talk about sensitive topics like politics and mental health.&quot;</p><p><a href=\"https://listenlabs.ai/case-studies/emeritus\">Emeritus</a>, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. &quot;We did not have to replace any responses because of fraud or gibberish information,&quot; said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.</p><h2><b>How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products</b></h2><p>The speed advantage has proven central to Listen&#x27;s pitch. Traditional customer research at <a href=\"https://listenlabs.ai/case-studies/microsoft\">Microsoft</a> could take four to six weeks to generate insights. &quot;By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,&quot; said Romani Patel, Senior Research Manager at Microsoft.</p><p>With Listen, Microsoft can now get insights in days, and in many cases, within hours.</p><p>The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. &quot;We wanted users to share how Copilot is empowering them to bring their best self forward,&quot; Patel said, &quot;and we were able to collect those user video stories within a day.&quot; Traditionally, that kind of work would have taken six to eight weeks.</p><p><a href=\"https://listenlabs.ai/case-studies/simple-modern\">Simple Modern</a>, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. &quot;We went from &#x27;Should we even have this product?&#x27; to &#x27;How should we launch it?&#x27;&quot; said Chris Hoyle, the company&#x27;s Chief Marketing Officer.</p><p><a href=\"https://listenlabs.ai/case-studies/chubbies\">Chubbies</a>, the shorts brand, achieved a 24x increase in youth research participation\u2014growing from 5 to 120 participants \u2014 by using Listen to overcome the scheduling challenges of traditional focus groups with children. &quot;There&#x27;s school, sports, dinner, and homework,&quot; explained Lauren Neville, Director of Insights and Innovation. &quot;I had to find a way to hear from them that fit into their schedules.&quot;</p><p>The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI &quot;through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.&quot; The redesigned product became &quot;a blockbuster hit.&quot;</p><h2><b>The Jevons paradox explains why cheaper research creates more demand, not less</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly <a href=\"https://a16z.com/ai-market-research/\">$140 billion annually</a>, populated by legacy players \u2014 some with more than a billion dollars in revenue \u2014 that he believes are vulnerable to disruption.</p><p>&quot;There are very much existing budget lines that we are replacing,&quot; Wahlforss said. &quot;Why we&#x27;re replacing them is that one, they&#x27;re super costly. Two, they&#x27;re kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.&quot;</p><p>But the more intriguing dynamic may be that AI-powered research doesn&#x27;t just replace existing spending \u2014 it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.</p><p>&quot;What I&#x27;ve noticed is that as something gets cheaper, you don&#x27;t need less of it. You want more of it,&quot; Wahlforss explained. &quot;There&#x27;s infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren&#x27;t researchers before can now do that as part of their job.&quot;</p><h2><b>Inside the elite engineering team that built Listen Labs before they had a working toilet</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. &quot;We built this consumer app that got 20,000 downloads in one day,&quot; Wahlforss recalled. &quot;We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.&quot;</p><p>The founding team brings an unusual pedigree. Wahlforss&#x27;s co-founder &quot;was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.&quot; The company claims that 30% of its engineering team are medalists from the <a href=\"https://ioinformatics.org/\">International Olympiad in Informatics</a> \u2014 the same competition that produced the founders of <a href=\"https://cognition.ai/\">Cognition</a>, the AI coding startup.</p><p>The <a href=\"https://www.cbsnews.com/sanfrancisco/news/san-francisco-billboard-challenge-puts-ai-engineers-to-the-test/\">Berghain billboard stunt</a> generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.</p><p>&quot;We had to do these things because some of our, like early employees, joined the company before we had a working toilet,&quot; he said. &quot;But now we fixed that situation.&quot;</p><p>The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations \u2014 a bet that in the AI era, technical fluency matters everywhere.</p><h2><b>Synthetic customers and automated decisions: what Listen Labs is building next</b></h2><p>Wahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building &quot;the ability to simulate your customers, so you can take all of those interviews we&#x27;ve done, and then extrapolate based on that and create synthetic users or simulated user voices.&quot;</p><p>Beyond simulation, Listen aims to enable automated action based on research findings. &quot;Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?&quot;</p><p>Wahlforss acknowledged the ethical implications. &quot;Obviously, as you said, there&#x27;s kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.&quot;</p><p>The company already handles sensitive data with care. &quot;We don&#x27;t train on any of the data,&quot; Wahlforss said. &quot;We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.&quot;</p><h2><b>How AI could reshape the future of product development</b></h2><p>Perhaps the most provocative implication of Listen&#x27;s model is how it could reshape product development itself. Wahlforss described a customer \u2014 an Australian startup \u2014 that has adopted what amounts to a continuous feedback loop.</p><p>&quot;They&#x27;re based in Australia, so they&#x27;re coding during the day, and then in their night, they&#x27;re releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.&quot;</p><p>The vision extends Y Combinator&#x27;s famous dictum \u2014 &quot;<a href=\"https://www.ycombinator.com/library/4D-yc-s-essential-startup-advice\">write code, talk to users</a>&quot; \u2014 into an automated cycle. &quot;Write code is now getting automated. And I think like talk to users will be as well, and you&#x27;ll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.&quot;</p><p>Whether that vision materializes depends on factors beyond Listen&#x27;s control \u2014 the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A <a href=\"https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf\">2024 MIT study</a> found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.</p><p>&quot;I&#x27;m constantly have to emphasize like, let&#x27;s make sure the quality is there and the details are right,&quot; he said.</p><p>But the company&#x27;s growth suggests appetite for the experiment. Microsoft&#x27;s Patel said Listen has &quot;removed the drudgery of research and brought the fun and joy back into my work.&quot; Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.</p><p>&quot;It&#x27;s a total game changer,&quot; said Ali Romero, Sling Money&#x27;s marketing manager.</p><p>Wahlforss has a different phrase for what he&#x27;s building. When asked about the tension between speed and rigor \u2014 the long-held belief that moving fast means cutting corners \u2014 he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.</p><p>One of them: &quot;Slow is fake.&quot;</p><p>It&#x27;s an aggressive claim for an industry built on methodological caution. But <a href=\"https://listenlabs.ai/\">Listen Labs</a> is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.</p>", "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai", "published_at": "Fri, 16 Ja", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Alfred Wahlforss was running out of options. His startup, <a href=\"https://listenlabs.ai/\">Listen Labs</a>, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s <a href=\"https://news.bloomberglaw.com/employee-benefits/zuckerbergs-100-million-ai-job-offers-pay-off-parmy-"]}
{"id": "source:rss:4009453173", "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI", "summary": "<p><a href=\"https://www.salesforce.com/\">Salesforce</a> on Tuesday launched an entirely rebuilt version of <a href=\"https://slack.com/help/articles/202026038-An-introduction-to-Slackbot\">Slackbot</a>, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.</p><p>The new Slackbot, now generally available to <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging &quot;agentic AI&quot; movement \u2014 where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.</p><p>&quot;Slackbot isn&#x27;t just another copilot or AI assistant,&quot; said <a href=\"https://www.salesforce.com/company/parker-harris-bio/\">Parker Harris</a>, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. &quot;It&#x27;s the front door to the agentic enterprise, powered by Salesforce.&quot;</p><h2><b>From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up</b></h2><p>Harris was blunt about what distinguishes the new Slackbot from its predecessor: &quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&quot;</p><p>The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks \u2014 reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.</p><p>&quot;It&#x27;s two different things,&quot; Harris explained. &quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new \u2014 it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&quot;</p><p>Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &quot;People know what Slackbot is, and so we wanted to carry that forward,&quot; Harris said.</p><h2><b>Why Anthropic&#x27;s Claude powers the new Slackbot \u2014 and which AI models could come next</b></h2><p>The new Slackbot runs on <a href=\"https://claude.ai/\">Claude</a>, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under <a href=\"https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/\">FedRAMP Moderate certification</a> to serve U.S. federal government customers, and Harris said Anthropic was &quot;the only provider that could give us a compliant LLM&quot; when Slack began building the new system.</p><p>But that exclusivity won&#x27;t last. &quot;We are, this year, going to support additional providers,&quot; Harris said. &quot;We have a great relationship with Google. Gemini is incredible \u2014 performance is great, cost is great. So we&#x27;re going to use Gemini for some things.&quot; He added that OpenAI remains a possibility as well.</p><p>Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: &quot;You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.&quot;</p><p>On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &quot;Models don&#x27;t have any sort of security,&quot; he explained. &quot;If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know \u2014 if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.&quot;</p><h2><b>Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking results</b></h2><p>Salesforce has been <a href=\"https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade\">testing the new Slackbot internally for months</a>, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: &quot;It&#x27;s the fastest adopted product in Salesforce history.&quot;</p><p>Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% \u2014 the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.</p><p>The adoption happened largely organically. &quot;I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;&quot; Gavin said. &quot;People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.&quot;</p><p>Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &quot;Everybody is there to help each other learn and communicate hacks,&quot; she said.</p><h2><b>How Slackbot transforms scattered enterprise data into executive-ready insights</b></h2><p>During a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.</p><p>&quot;This is where Slackbot really earns its keep for me,&quot; Bauer explained. &quot;What it&#x27;s doing is not just simply reading the image \u2014 it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.&quot;</p><p>Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &quot;a really great justification and plan to move forward.&quot; Finally, it can synthesize all that information into a Canvas \u2014 Slack&#x27;s collaborative document format \u2014 and find calendar availability among stakeholders to schedule a review meeting.</p><p>&quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&quot; Bauer said. &quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&quot;</p><p>Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot \u2014 we&#x27;re eventually going to be adding in additional third-party tool calls.&quot;</p><h2><b>MrBeast&#x27;s company became a Slackbot guinea pig\u2014and employees say they&#x27;re saving 90 minutes a day</b></h2><p>Among Salesforce&#x27;s pilot customers is <a href=\"https://www.thecashmerefund.com/portfolio-company/beast-industries\">Beast Industries</a>, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.</p><p>&quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&quot; Madrigal said. &quot;The plumbing is there. Slack as an implementation, Enterprise Tools \u2014 being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&quot;</p><p>Madrigal said his security team signed off &quot;rather quickly&quot; \u2014 unusual for enterprise AI deployments \u2014 because Slackbot accesses only the information each individual user already has permission to view. &quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of\u2014that made my security team sign off rather quickly.&quot;</p><p>One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &quot;at bare minimum, 90 minutes a day.&quot; Another employee, Spencer, a creative supervisor, described it as &quot;an assistant who&#x27;s paying attention when I&#x27;m not.&quot;</p><p>Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &quot;an absolute &#x27;chaos tamer&#x27; for our team,&quot; estimating it saves her about 30 minutes daily &quot;just by eliminating context switching.&quot;</p><h2><b>Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance</b></h2><p>The launch puts Salesforce in direct competition with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a>, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.</p><p>&quot;The thing that makes it most powerful for our customers and users is the proximity \u2014 it&#x27;s just right there in your Slack,&quot; Seaman said. &quot;There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.&quot;</p><p>The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. &quot;Most AI tools sound the same no matter who is using them,&quot; the company&#x27;s announcement stated. &quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&quot;</p><p>Harris put it more directly: &quot;If you&#x27;ve ever had that magic experience with AI \u2014 I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective \u2014 Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&quot;</p><p>Amy Bauer emphasized the frictionless nature of the experience. &quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&quot; she said. &quot;So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.&quot;</p><h2><b>Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the others</b></h2><p>Salesforce positions Slackbot as what Harris calls a &quot;super agent&quot; \u2014 a central hub that can eventually coordinate with other AI agents across an organization.</p><p>&quot;Every corporation is going to have an employee super agent,&quot; Harris said. &quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.&quot;</p><p>The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.</p><p>&quot;Most of the net-new apps that are being deployed to Slack are agents,&quot; Seaman noted during the press conference. &quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&quot;</p><p>Harris described a future where Slackbot becomes an <a href=\"https://modelcontextprotocol.io/docs/learn/client-concepts\">MCP (Model Context Protocol) client</a>, able to leverage tools from across the software ecosystem \u2014 similar to how the developer tool Cursor works. &quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&quot; he said.</p><p>But Harris also cautioned against over-promising on multi-agent coordination. &quot;I still think we&#x27;re in the single agent world,&quot; he said. &quot;FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.&quot;</p><h2><b>Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customers</b></h2><p>Slackbot is included at no additional cost for customers on <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> plans. &quot;There&#x27;s no additional fees customers have to do,&quot; Gavin confirmed. &quot;If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.&quot;</p><p>However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.</p><p>Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&quot; Fraser said in a <a href=\"https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html\">recent CIO report</a>.</p><p>Salesforce has framed the pricing change as standard industry practice.</p><h2><b>What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmap</b></h2><p>The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.</p><p>Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &quot;coming a few weeks after,&quot; according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s &quot;something that we are looking at in the future.&quot;</p><p>When asked about integration with competing CRM systems like <a href=\"https://www.hubspot.com/\">HubSpot</a> and <a href=\"https://www.microsoft.com/en-us/dynamics-365\">Microsoft Dynamics</a>, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.</p><h2><b>Salesforce is betting the future of work looks like a chat window\u2014and it&#x27;s not alone</b></h2><p>The Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational \u2014 that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.</p><p>Harris described Slack&#x27;s product philosophy using principles like &quot;don&#x27;t make me think&quot; and &quot;be a great host.&quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.</p><p>&quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&quot; Harris said. &quot;And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack \u2014 the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.&quot;</p><p>Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &quot;We&#x27;re kind of saturating what we can do with purely conversational UIs,&quot; he said. &quot;I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&quot;</p><p>Microsoft, Google, and a growing roster of AI startups are placing similar bets \u2014 that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.</p><p>For Salesforce, the stakes extend beyond a single product launch. After a <a href=\"https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399\">bruising year</a> on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite \u2014 that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.</p><p>Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &quot;I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&quot;</p><p>That&#x27;s precisely what Salesforce is counting on.</p>", "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and", "published_at": "Tue, 13 Ja", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p><a href=\"https://www.salesforce.com/\">Salesforce</a> on Tuesday launched an entirely rebuilt version of <a href=\"https://slack.com/help/articles/202026038-An-introduction-to-Slackbot\">Slackbot</a>, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what e"]}
{"id": "source:rss:1492684199", "title": "Anthropic launches Cowork, a Claude Desktop agent that works in your files \u2014 no coding required", "summary": "<p><a href=\"https://www.anthropic.com/\">Anthropic</a> released <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> on Monday, a new AI agent capability that extends the power of its wildly successful <a href=\"https://claude.com/product/claude-code\">Claude Code</a> tool to non-technical users \u2014 and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.</p><p>The launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with <a href=\"https://openai.com/\">OpenAI</a> and <a href=\"https://gemini.google.com/app\">Google</a> in conversational AI, but with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a> in the burgeoning market for AI-powered productivity tools.</p><p>&quot;Cowork lets you complete non-technical tasks much like how developers use Claude Code,&quot; the <a href=\"https://x.com/claudeai/status/2010805682434666759?s=20\">company announced</a> via its official Claude account on X. The feature arrives as a research preview available exclusively to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> \u2014 Anthropic&#x27;s power-user tier priced between $100 and $200 per month \u2014 through the macOS desktop application.</p><p>For the past year, the industry narrative has focused on large language models that can write poetry or debug code. With <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding.</p><div></div><h2><b>How developers using a coding tool for vacation research inspired Anthropic&#x27;s latest product</b></h2><p>The genesis of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> lies in Anthropic&#x27;s recent success with the developer community. In late 2024, the company released <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">Claude Code</a>, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.</p><p>According to <a href=\"https://x.com/bcherny/status/2010809450844831752\">Boris Cherny</a>, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks.</p><div></div><p>&quot;Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven,&quot; Cherny wrote on X. &quot;These use cases are diverse and surprising \u2014 the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model.&quot;</p><p>Recognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, <a href=\"https://claude.com/blog/cowork-research-preview\">Anthropic explained</a> that developers &quot;quickly began using it for almost everything else,&quot; which &quot;prompted us to build Cowork: a simpler way for anyone \u2014 not just developers \u2014 to work with Claude in the very same way.&quot;</p><h2><b>Inside the folder-based architecture that lets Claude read, edit, and create files on your computer</b></h2><p>Unlike a standard chat interface where a user pastes text for analysis, <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.</p><p>Anthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.</p><p>&quot;In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder,&quot; <a href=\"https://x.com/claudeai/status/2010805685530038351\">the company explained</a> on X. &quot;Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes.&quot;</p><div></div><p>The architecture relies on what is known as an &quot;agentic loop.&quot; When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously \u2014 a workflow Anthropic describes as feeling &quot;much less like a back-and-forth and much more like leaving messages for a coworker.&quot;</p><p>The system is built on Anthropic&#x27;s <a href=\"https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk\">Claude Agent SDK</a>, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork &quot;can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.&quot;</p><h2><b>The recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork</b></h2><p>Perhaps the most remarkable detail surrounding Cowork&#x27;s launch is the speed at which the tool was reportedly built \u2014 highlighting a recursive feedback loop where AI tools are being used to build better AI tools.</p><p>During a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that <a href=\"https://x.com/blakeir/status/2010837251505205656\">t</a>he team <a href=\"https://x.com/blakeir/status/2010837251505205656\">built Cowork in approximately a week and a half</a>.</p><p>Alex Volkov, who covers AI developments, expressed surprise at the timeline: &quot;Holy shit Anthropic built &#x27;Cowork&#x27; in the last... week and a half?!&quot;</p><div></div><p>This prompted immediate speculation about how much of Cowork was itself built by Claude Code. <a href=\"https://x.com/_simonsmith\">Simon Smith</a>, EVP of Generative AI at Klick Health, put it bluntly on X: &quot;Claude Code wrote all of Claude Cowork. Can we all agree that we&#x27;re in at least somewhat of a recursive improvement loop here?&quot;</p><p>The implication is profound: Anthropic&#x27;s AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion \u2014 a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.</p><h2><b>Connectors, browser automation, and skills extend Cowork&#x27;s reach beyond the local file system</b></h2><p>Cowork doesn&#x27;t operate in isolation. The feature integrates with Anthropic&#x27;s existing ecosystem of connectors \u2014 tools that link <a href=\"https://claude.ai/login?returnTo=%2Fnew%3F\">Claude</a> to external information sources and services such as <a href=\"https://asana.com/\">Asana</a>, <a href=\"https://www.notion.com/\">Notion</a>, <a href=\"https://www.paypal.com/us/home\">PayPal</a>, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.</p><p>Additionally, Cowork can pair with <a href=\"https://code.claude.com/docs/en/chrome\">Claude in Chrome</a>, Anthropic&#x27;s browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet \u2014 all while operating from the desktop application.</p><p>&quot;Cowork includes a number of novel UX and safety features that we think make the product really special,&quot; <a href=\"https://x.com/bcherny/status/2010809450844831752\">Cherny explained</a>, highlighting &quot;a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it&#x27;s unsure.&quot;</p><p><a href=\"https://www.anthropic.com/\">Anthropic</a> has also introduced an initial set of &quot;skills&quot; specifically designed for Cowork that enhance Claude&#x27;s ability to create documents, presentations, and other files. These build on the <a href=\"https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills\">Skills for Claude</a> framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.</p><h2><b>Why Anthropic is warning users that its own AI agent could delete their files</b></h2><p>The transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.</p><p>In a notable display of transparency, Anthropic devoted considerable space in its announcement to <a href=\"https://claude.com/blog/cowork-research-preview\">warning users about Cowork&#x27;s potential dangers</a> \u2014 an unusual approach for a product launch.</p><p>The company explicitly acknowledges that Claude &quot;can take potentially destructive actions (such as deleting local files) if it&#x27;s instructed to.&quot; Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide &quot;very clear guidance&quot; about sensitive operations.</p><p>More concerning is the risk of prompt injection attacks \u2014 a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.</p><p>&quot;We&#x27;ve built sophisticated defenses against prompt injections,&quot; Anthropic wrote, &quot;but agent safety \u2014 that is, the task of securing Claude&#x27;s real-world actions \u2014 is still an active area of development in the industry.&quot;</p><p>The company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. &quot;These risks aren&#x27;t new with Cowork, but it might be the first time you&#x27;re using a more advanced tool that moves beyond a simple conversation,&quot; the announcement notes.</p><h2><b>Anthropic&#x27;s desktop agent strategy sets up a direct challenge to Microsoft Copilot</b></h2><p>The launch of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> places Anthropic in direct competition with <a href=\"https://www.microsoft.com/en-us/\">Microsoft</a>, which has spent years attempting to integrate its <a href=\"https://copilot.microsoft.com/\">Copilot AI</a> into the fabric of the Windows operating system with mixed adoption results.</p><p>However, Anthropic&#x27;s approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.</p><p>What distinguishes Anthropic&#x27;s approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first \u2014 <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> \u2014 and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.</p><p>Claude Code has generated significant enthusiasm among developers since its initial launch as <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">a command-line tool in late 2024</a>. The company expanded access with a <a href=\"https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/\">web interface</a> in October 2025, followed by a <a href=\"https://venturebeat.com/ai/anthropics-claude-code-can-now-read-your-slack-messages-and-write-code-for\">Slack integration</a> in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.</p><h2><b>Who can access Cowork now, and what&#x27;s coming next for Windows and other platforms</b></h2><p>For now, Cowork remains exclusive to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> using the macOS desktop application. Users on other subscription tiers \u2014 Free, Pro, Team, or Enterprise \u2014 can join a waitlist for future access.</p><p>Anthropic has signaled clear intentions to expand the feature&#x27;s reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.</p><p>Cherny set expectations appropriately, describing the product as &quot;early and raw, similar to what Claude Code felt like when it first launched.&quot;</p><p>To access <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Max subscribers can download or update the Claude macOS app and click on &quot;Cowork&quot; in the sidebar.</p><h2><b>The real question facing enterprise AI adoption</b></h2><p>For technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting \u2014 no longer is model intelligence the limiting factor, but rather workflow integration and user trust.</p><p>Anthropic&#x27;s goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.</p><p>But the speed of Cowork&#x27;s development \u2014 a major feature built in ten days, possibly by the company&#x27;s own AI \u2014 previews a future where the capabilities of these systems compound faster than organizations can evaluate them. </p><p>The chatbot has learned to use a file manager. What it learns to use next is anyone&#x27;s guess.</p>", "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no", "published_at": "Mon, 12 Ja", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p><a href=\"https://www.anthropic.com/\">Anthropic</a> released <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> on Monday, a new AI agent capability that extends the power of its wildly successful <a href=\"https://claude.com/product/claude-code\">Claude Code</a> tool to non-techni"]}
{"id": "source:rss:3087177843", "title": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment", "summary": "<p><a href=\"https://nousresearch.com/\">Nous Research</a>, the open-source artificial intelligence startup backed by crypto venture firm <a href=\"https://www.paradigm.xyz/\">Paradigm</a>, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems \u2014 trained in just four days using 48 of Nvidia&#x27;s latest <a href=\"https://www.nvidia.com/en-us/data-center/dgx-b200/\">B200 graphics processors</a>.</p><p>The model, called <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: <a href=\"https://claude.com/product/claude-code\">Claude Code</a>, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&#x27;s Day, with developers posting <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">breathless</a> <a href=\"https://x.com/hayesdev_/status/2008043379805048948\">testimonials</a> <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">about its capabilities</a>. The simultaneous developments underscore how quickly AI-assisted software development is evolving \u2014 and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.</p><p><span>type: <!-- -->embedded-entry-inline<!-- --> id: <!-- -->74cSyrq6OUrp9SEQ5zOUSl</span></p><p><a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">NousCoder-14B</a> achieves a 67.87 percent accuracy rate on <a href=\"https://livecodebench.github.io/\">LiveCodeBench v6</a>, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&#x27;s <a href=\"https://huggingface.co/Qwen/Qwen3-14B\">Qwen3-14B</a>, according to Nous Research&#x27;s technical report published alongside the release.</p><p>&quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&quot; <a href=\"https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/\">wrote Jaana Dogan</a>, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing \u2014 a system Claude Code approximated from a three-paragraph prompt.</p><p>The juxtaposition is instructive: while Anthropic&#x27;s <a href=\"https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are\">Claude Code has captured imaginations</a> with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap \u2014 and that transparency in how these models are built matters as much as raw capability.</p><hr /><h2><b>How Nous Research built an AI coding model that anyone can replicate</b></h2><p>What distinguishes the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> release from many competitor announcements is its radical openness. Nous Research published not just the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">model weights</a> but the <a href=\"https://github.com/NousResearch/atropos/pull/296\">complete reinforcement learning environment</a>, benchmark suite, and training harness \u2014 built on the company&#x27;s <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos framework </a>\u2014 enabling any researcher with sufficient compute to <a href=\"https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o\">reproduce or extend the work</a>.</p><p>&quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&quot; <a href=\"https://x.com/o_mega___/status/2008907268700475450?s=20\">noted one observer on X</a>, summarizing the significance for the academic and open-source communities.</p><p>The model was trained by <a href=\"https://x.com/JoeLi5050\">Joe Li</a>, a researcher in residence at Nous Research and a former competitive programmer himself. Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report </a>reveals an unexpectedly personal dimension: he compared the model&#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.</p><p>Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&#x27;s improvemen t\u2014 from approximately the 1600-1750 rating range to 2100-2200 \u2014 mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.</p><p>&quot;Watching that final training run unfold was quite a surreal experience,&quot; Li wrote in the technical report.</p><p>But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.</p><hr /><h2><b>Inside the reinforcement learning system that trains on 24,000 competitive programming problems</b></h2><p><a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>&#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.</p><p>The approach relies on what researchers call &quot;verifiable rewards&quot; \u2014 a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.</p><p>Nous Research used <a href=\"https://modal.com/\">Modal</a>, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints \u2014 15 seconds and 4 gigabytes, respectively.</p><p>The training employed a technique called <a href=\"https://dapo-sia.github.io/\">DAPO (Dynamic Sampling Policy Optimization)</a>, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &quot;dynamic sampling&quot; \u2014 discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.</p><p>The researchers also adopted &quot;iterative context extension,&quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.</p><p>Perhaps most significantly, the training pipeline overlaps inference and verification \u2014 as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.</p><hr /><h2><b>The looming data shortage that could slow AI coding model progress</b></h2><p>Buried in Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report</a> is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&quot;</p><p>In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.</p><p>&quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&quot; Li wrote, referring to the 24,000 problems used for training. &quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&quot;</p><p>This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &quot;increasingly finite,&quot; as Li put it.</p><p>&quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&quot; he concluded.</p><p>The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&#x27;t \u2014 making synthetic data generation considerably more difficult.</p><p>Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&quot; he wrote.</p><hr /><h2><b>A $65 million bet that open-source AI can compete with Big Tech</b></h2><p>Nous Research has carved out a distinctive position in the AI landscape: a company committed to <a href=\"https://nousresearch.com/\">open-source releases</a> that compete with \u2014 and sometimes exceed \u2014 proprietary alternatives.</p><p>The company raised<a href=\"https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/\"> $50 million in April 2025</a> in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its <a href=\"https://psyche.network/\">Psyche platform</a>.</p><p>Previous releases include <a href=\"https://hermes4.nousresearch.com/\">Hermes 4</a>, a family of models that we reported &quot;<a href=\"https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions\">outperform ChatGPT without content restrictions</a>,&quot; and DeepHermes-3, which the company described as the first &quot;<a href=\"https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3\">toggle-on reasoning model</a>&quot; \u2014 allowing users to activate extended thinking capabilities on demand.</p><p>The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &quot;Ofc i&#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&quot; <a href=\"https://x.com/shydev69/status/2008654826356535510?s=20\">wrote one critic on X</a>, referring to Nous Research&#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.</p><p>Others raised technical questions. &quot;<a href=\"https://x.com/yehor_smoliakov/status/2008659681489940757?s=20\">Based on the benchmark, Nemotron is better</a>,&quot; noted one commenter, referring to Nvidia&#x27;s family of language models. Another asked whether <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> is &quot;agentic focused or just &#x27;one shot&#x27; coding&quot; \u2014 a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.</p><hr /><h2><b>What researchers say must happen next for AI coding tools to keep improving</b></h2><p>The release includes several directions for future work that hint at where AI coding research may be heading.</p><p>Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward \u2014 pass or fail \u2014 after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.</p><p>Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training \u2014 a pattern that various algorithmic modifications failed to resolve.</p><p>Perhaps most ambitiously, Li proposed &quot;problem generation and self-play&quot; \u2014 training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.</p><p>&quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&quot; Li wrote.</p><p>The model is <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">available now on Hugging Face</a> under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos training stack</a> alongside it.</p><p>What took Li two years of adolescent dedication to achieve\u2014climbing from a 1600-level novice to a 2100-rated competitor on Codeforces\u2014an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.</p><p>The question is no longer whether machines can learn to code. It&#x27;s whether they&#x27;ll soon be better teachers than we ever were.</p><p> </p>", "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in", "published_at": "Wed, 07 Ja", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p><a href=\"https://nousresearch.com/\">Nous Research</a>, the open-source artificial intelligence startup backed by crypto venture firm <a href=\"https://www.paradigm.xyz/\">Paradigm</a>, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary "]}
{"id": "source:rss:7351899571", "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds", "summary": "<p>When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen \u2014 it takes notes.</p><p>For the past week, the engineering community has been dissecting a <a href=\"https://x.com/bcherny/status/2007179832300581177\">thread on X</a> from <a href=\"https://x.com/bcherny\">Boris Cherny</a>, the creator and head of <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> at <a href=\"https://www.anthropic.com/\">Anthropic</a>. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.</p><div></div><p>&quot;If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,&quot; wrote <a href=\"https://x.com/jefftangx\">Jeff Tang</a>, a prominent voice in the developer community. <a href=\"https://x.com/KyleMcnease/status/2007555584724480338\">Kyle McNease</a>, another industry observer, went further, declaring that with Cherny&#x27;s &quot;game-changing updates,&quot; Anthropic is &quot;on fire,&quot; potentially facing &quot;their ChatGPT moment.&quot;</p><p>The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience &quot;<a href=\"https://x.com/mtwichan\">feels more like Starcraft</a>&quot; than traditional coding \u2014 a shift from typing syntax to commanding autonomous units.</p><p>Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. </p><h2><b>How running five AI agents at once turns coding into a real-time strategy game</b></h2><p>The most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional &quot;<a href=\"https://notes.paulswail.com/public/The+inner+and+outer+loops+of+software+development+workflow\">inner loop</a>&quot; of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.</p><p>&quot;I run 5 Claudes in parallel in my terminal,&quot; Cherny wrote. &quot;I number my tabs 1-5, and use system notifications to know when a Claude needs input.&quot;</p><p>By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs &quot;5-10 Claudes on <a href=\"https://claude.ai/\">claude.ai</a>&quot; in his browser, using a &quot;teleport&quot; command to hand off sessions between the web and his local machine.</p><p>This validates the &quot;<a href=\"https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\">do more with less</a>&quot; strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.</p><h2><b>The counterintuitive case for choosing the slowest, smartest model</b></h2><p>In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Opus 4.5</a>.</p><p>&quot;I use Opus 4.5 with thinking for everything,&quot; Cherny <a href=\"https://x.com/bcherny/status/2007179838864666847\">explained</a>. &quot;It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger &amp; slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.&quot;</p><p>For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the &quot;compute tax&quot; for a smarter model upfront eliminates the &quot;correction tax&quot; later.</p><h2><b>One shared file turns every AI mistake into a permanent lesson</b></h2><p>Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not &quot;remember&quot; a company&#x27;s specific coding style or architectural decisions from one session to the next.</p><p>To address this, Cherny&#x27;s team maintains a single file named <a href=\"https://x.com/bcherny/status/2007179842928947333\">CLAUDE.md</a> in their git repository. &quot;Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,&quot; he wrote.</p><p>This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. &quot;<a href=\"https://x.com/aakashgupta/status/2007347705945944153\">Every mistake becomes a rule</a>,&quot; noted <a href=\"https://x.com/aakashgupta\">Aakash Gupta</a>, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.</p><h2><b>Slash commands and subagents automate the most tedious parts of development</b></h2><p>The &quot;vanilla&quot; workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands \u2014 custom shortcuts checked into the project&#x27;s repository \u2014 to handle complex operations with a single keystroke.</p><p>He highlighted a command called <i><b>/commit-push-pr</b></i>, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.</p><p>Cherny also deploys subagents \u2014 specialized AI personas \u2014 to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.</p><h2><b>Why verification loops are the real unlock for AI-generated code</b></h2><p>If there is a single reason Claude Code has reportedly hit <a href=\"https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone\">$1 billion in annual recurring revenue</a> so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.</p><p>&quot;Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,&quot; Cherny wrote. &quot;It opens a browser, tests the UI, and iterates until the code works and the UX feels good.&quot;</p><p>He argues that giving the AI a way to verify its own work \u2014 whether through browser automation, running bash commands, or executing test suites \u2014 improves the quality of the final result by &quot;2-3x.&quot; The agent doesn&#x27;t just write code; it proves the code works.</p><h2><b>What Cherny&#x27;s workflow signals about the future of software engineering</b></h2><p>The reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, &quot;AI coding&quot; meant an autocomplete function in a text editor \u2014 a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.</p><p>&quot;Read this if you&#x27;re already an engineer... and want more power,&quot; <a href=\"https://x.com/jefftangx/status/2008246873275215890\">Jeff Tang</a> summarized on X.</p><p>The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game \u2014 and everyone else will still be typing.</p>", "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are", "published_at": "Mon, 05 Ja", "source_type": "rss", "credibility_tier": "C", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen \u2014 it takes notes.</p><p>For the past week, the engineering community has been dissecting a <a href=\"https://x.com/bcherny/status/2007179832300581177\">thread on X</a> from <a href=\"https"]}
{"id": "source:rss:2942217311", "title": "For $1M, you can pay Bryan Johnson (or BryanAI?) to teach you how to live longer", "summary": "The longevity-obsessed investor Bryan Johnson is charging $1 million to sign up for his \"Immortals\" program.", "url": "https://techcrunch.com/2026/02/12/for-1-million-you-can-pay-bryan-johnson-or-bryanai-to-teach-you-how-to-live-longer/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The longevity-obsessed investor Bryan Johnson is charging $1 million to sign up for his \"Immortals\" program."]}
{"id": "source:rss:8917534093", "title": "Amid disappointing earnings, Pinterest claims it sees more searches than ChatGPT", "summary": "Pinterest's stock tumbles after an earnings miss, with higher-than-expected usage its only bright spot.", "url": "https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Pinterest's stock tumbles after an earnings miss, with higher-than-expected usage its only bright spot."]}
{"id": "source:rss:2744582373", "title": "IBM\u00a0will hire your entry-level talent in the age of AI", "summary": "IBM plans to triple its entry-level hiring in the U.S. in 2026, but these jobs will have different tasks than in previous years.", "url": "https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["IBM plans to triple its entry-level hiring in the U.S. in 2026, but these jobs will have different tasks than in previous years."]}
{"id": "source:rss:7447321771", "title": "Rivian was saved by software in 2025", "summary": "The company's annual revenue was boosted by its technology joint venture with Volkswagen Group.", "url": "https://techcrunch.com/2026/02/12/rivian-was-saved-by-software-in-2025/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The company's annual revenue was boosted by its technology joint venture with Volkswagen Group."]}
{"id": "source:rss:8886143373", "title": "Musk needed a new vision for SpaceX and xAI. He landed on Moonbase Alpha.", "summary": "\"I really want to see a mass driver on the moon that is shooting AI satellites into deep space.\"", "url": "https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["\"I really want to see a mass driver on the moon that is shooting AI satellites into deep space.\""]}
{"id": "source:rss:2935293161", "title": "Didero lands $30M to put manufacturing procurement on \u2018agentic\u2019 autopilot", "summary": "Didero functions as an agentic AI layer that sits on top of a company\u2019s existing ERP, acting as a coordinator that reads incoming communications and automatically executes the necessary updates and tasks.", "url": "https://techcrunch.com/2026/02/12/didero-lands-30m-to-put-manufacturing-procurement-on-agentic-autopilot/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Didero functions as an agentic AI layer that sits on top of a company\u2019s existing ERP, acting as a coordinator that reads incoming communications and automatically executes the necessary updates and tasks."]}
{"id": "source:rss:3594210047", "title": "Anthropic raises another $30B in Series G, with a new value of $380B", "summary": "The infusion of funding for the AI startup takes place as it is vying for customers and cultural attention with its competitor, OpenAI.", "url": "https://techcrunch.com/2026/02/12/anthropic-raises-another-30-billion-in-series-g-with-a-new-value-of-380-billion/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The infusion of funding for the AI startup takes place as it is vying for customers and cultural attention with its competitor, OpenAI."]}
{"id": "source:rss:1950135017", "title": "YouTube finally launches a dedicated app for Apple Vision Pro", "summary": "When Apple Vision Pro first came out two years ago, YouTube hesitated to release a dedicated app. Today is the day they officially launch one.", "url": "https://techcrunch.com/2026/02/12/youtube-finally-launches-a-dedicated-app-for-apple-vision-pro/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["When Apple Vision Pro first came out two years ago, YouTube hesitated to release a dedicated app. Today is the day they officially launch one."]}
{"id": "source:rss:4387930400", "title": "Hacker linked to Epstein removed from Black Hat cyber conference website", "summary": "Emails published by the Justice Department revealed cybersecurity veteran Vincenzo Iozzo emailed, and arranged to meet, Jeffrey Epstein multiple times between 2014 and 2018.", "url": "https://techcrunch.com/2026/02/12/hacker-linked-to-epstein-removed-from-black-hat-cyber-conference-website/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Emails published by the Justice Department revealed cybersecurity veteran Vincenzo Iozzo emailed, and arranged to meet, Jeffrey Epstein multiple times between 2014 and 2018."]}
{"id": "source:rss:4570110426", "title": "Trump administration undermines EPA enforcement of Clean Air Act", "summary": "The EPA's new rule seeks to undo a 2009 finding that allowed the federal government to regulate six greenhouse gases.", "url": "https://techcrunch.com/2026/02/12/trump-administration-undermines-epa-enforcement-of-clean-air-act/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The EPA's new rule seeks to undo a 2009 finding that allowed the federal government to regulate six greenhouse gases."]}
{"id": "source:rss:8429471420", "title": "Automattic planned to target 10 competitors with royalty fees, WP Engine claims in new filing", "summary": "WP Engine claims Automattic was going to target more hosting companies with royalty fees.", "url": "https://techcrunch.com/2026/02/12/automattic-planned-to-target-10-competitors-with-royalty-fees-wp-engine-claims-in-new-filing/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["WP Engine claims Automattic was going to target more hosting companies with royalty fees."]}
{"id": "source:rss:8875932787", "title": "Spotify says its best developers haven\u2019t written a line of code since December, thanks to AI", "summary": "Spotify credits Claude Code and its internal AI system Honk with speeding up development.", "url": "https://techcrunch.com/2026/02/12/spotify-says-its-best-developers-havent-written-a-line-of-code-since-december-thanks-to-ai/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Spotify credits Claude Code and its internal AI system Honk with speeding up development."]}
{"id": "source:rss:5357051300", "title": "A new version of OpenAI\u2019s Codex is powered by a new dedicated chip", "summary": "OpenAI calls the new coding tool the \"first milestone\" in its relationship with the chipmaker.", "url": "https://techcrunch.com/2026/02/12/a-new-version-of-openais-codex-is-powered-by-a-new-dedicated-chip/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI calls the new coding tool the \"first milestone\" in its relationship with the chipmaker."]}
{"id": "source:rss:1632266949", "title": "Aurora\u2019s driverless trucks can now travel farther distances faster than human drivers", "summary": "CEO Chris Urmson called it a \u201csuperhuman\u201d moment, adding that Aurora\u2019s trucks can now carry freight 1,000 miles in 15 hours \u2014 faster than what a human driver can legally accomplish.", "url": "https://techcrunch.com/2026/02/12/auroras-driverless-trucks-can-now-travel-farther-distances-faster-than-human-drivers/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["CEO Chris Urmson called it a \u201csuperhuman\u201d moment, adding that Aurora\u2019s trucks can now carry freight 1,000 miles in 15 hours \u2014 faster than what a human driver can legally accomplish."]}
{"id": "source:rss:3175007644", "title": "More US investors sue South Korean government over handling of Coupang data breach", "summary": "Coupang\u2019s massive data breach has sparked U.S. investor lawsuits against the South Korean government over alleged discrimination.", "url": "https://techcrunch.com/2026/02/12/more-u-s-investors-sue-south-korean-government-over-handling-of-coupang-data-breach/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Coupang\u2019s massive data breach has sparked U.S. investor lawsuits against the South Korean government over alleged discrimination."]}
{"id": "source:rss:1224433486", "title": "Apple acquires all rights to \u2018Severance,\u2019 will produce future seasons in-house", "summary": "The show is expected to run for four seasons, with the possibility of spin-offs, a prequel, and foreign versions.", "url": "https://techcrunch.com/2026/02/12/apple-acquires-all-rights-to-severance-will-produce-future-seasons-in-house/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The show is expected to run for four seasons, with the possibility of spin-offs, a prequel, and foreign versions."]}
{"id": "source:rss:2151284743", "title": "US FTC airs concerns over allegations that Apple News suppresses right-wing content", "summary": "In a letter to Apple CEO Tim Cook, FTC chair Andrew Ferguson cited reports from Media Research Center, a right-leaning think tank, which accused Apple of excluding right-leaning outlets from the top 20 articles in the Apple News feed.", "url": "https://techcrunch.com/2026/02/12/us-ftc-airs-concerns-over-allegations-that-apple-suppresses-right-wing-content-on-apple-news/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["In a letter to Apple CEO Tim Cook, FTC chair Andrew Ferguson cited reports from Media Research Center, a right-leaning think tank, which accused Apple of excluding right-leaning outlets from the top 20 articles in the Apple News feed."]}
{"id": "source:rss:1648937660", "title": "Eclipse backs all-EV marketplace Ever in $31M funding round", "summary": "The San Francisco-based startup says its AI-first approach has allowed it to scale faster.", "url": "https://techcrunch.com/2026/02/12/eclipse-backs-all-ev-marketplace-ever-in-31m-funding-round/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The San Francisco-based startup says its AI-first approach has allowed it to scale faster."]}
{"id": "source:rss:8738940747", "title": "xAI lays out interplanetary ambitions in public all-hands", "summary": "On Wednesday, xAI took the rare step of publishing its full 45-minute all-hands presentation to the X platform, making it widely available.", "url": "https://techcrunch.com/2026/02/11/xai-lays-out-interplanetary-ambitions-in-public-all-hands/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["On Wednesday, xAI took the rare step of publishing its full 45-minute all-hands presentation to the X platform, making it widely available."]}
{"id": "source:rss:2717483249", "title": "AI inference startup Modal Labs in talks to raise at $2.5B valuation, sources say", "summary": "General Catalyst is in talks to lead the round for the four-year-old startup, according to our sources.", "url": "https://techcrunch.com/2026/02/11/ai-inference-startup-modal-labs-in-talks-to-raise-at-2-5b-valuation-sources-say/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["General Catalyst is in talks to lead the round for the four-year-old startup, according to our sources."]}
{"id": "source:rss:8917534093", "title": "Amid disappointing earnings, Pinterest claims it sees more searches than ChatGPT", "summary": "Pinterest's stock tumbles after an earnings miss, with higher-than-expected usage its only bright spot.", "url": "https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Pinterest's stock tumbles after an earnings miss, with higher-than-expected usage its only bright spot."]}
{"id": "source:rss:2744582373", "title": "IBM\u00a0will hire your entry-level talent in the age of AI", "summary": "IBM plans to triple its entry-level hiring in the U.S. in 2026, but these jobs will have different tasks than in previous years.", "url": "https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["IBM plans to triple its entry-level hiring in the U.S. in 2026, but these jobs will have different tasks than in previous years."]}
{"id": "source:rss:8886143373", "title": "Musk needed a new vision for SpaceX and xAI. He landed on Moonbase Alpha.", "summary": "\"I really want to see a mass driver on the moon that is shooting AI satellites into deep space.\"", "url": "https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["\"I really want to see a mass driver on the moon that is shooting AI satellites into deep space.\""]}
{"id": "source:rss:2935293161", "title": "Didero lands $30M to put manufacturing procurement on \u2018agentic\u2019 autopilot", "summary": "Didero functions as an agentic AI layer that sits on top of a company\u2019s existing ERP, acting as a coordinator that reads incoming communications and automatically executes the necessary updates and tasks.", "url": "https://techcrunch.com/2026/02/12/didero-lands-30m-to-put-manufacturing-procurement-on-agentic-autopilot/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Didero functions as an agentic AI layer that sits on top of a company\u2019s existing ERP, acting as a coordinator that reads incoming communications and automatically executes the necessary updates and tasks."]}
{"id": "source:rss:3594210047", "title": "Anthropic raises another $30B in Series G, with a new value of $380B", "summary": "The infusion of funding for the AI startup takes place as it is vying for customers and cultural attention with its competitor, OpenAI.", "url": "https://techcrunch.com/2026/02/12/anthropic-raises-another-30-billion-in-series-g-with-a-new-value-of-380-billion/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The infusion of funding for the AI startup takes place as it is vying for customers and cultural attention with its competitor, OpenAI."]}
{"id": "source:rss:8875932787", "title": "Spotify says its best developers haven\u2019t written a line of code since December, thanks to AI", "summary": "Spotify credits Claude Code and its internal AI system Honk with speeding up development.", "url": "https://techcrunch.com/2026/02/12/spotify-says-its-best-developers-havent-written-a-line-of-code-since-december-thanks-to-ai/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Spotify credits Claude Code and its internal AI system Honk with speeding up development."]}
{"id": "source:rss:5357051300", "title": "A new version of OpenAI\u2019s Codex is powered by a new dedicated chip", "summary": "OpenAI calls the new coding tool the \"first milestone\" in its relationship with the chipmaker.", "url": "https://techcrunch.com/2026/02/12/a-new-version-of-openais-codex-is-powered-by-a-new-dedicated-chip/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI calls the new coding tool the \"first milestone\" in its relationship with the chipmaker."]}
{"id": "source:rss:8738940747", "title": "xAI lays out interplanetary ambitions in public all-hands", "summary": "On Wednesday, xAI took the rare step of publishing its full 45-minute all-hands presentation to the X platform, making it widely available.", "url": "https://techcrunch.com/2026/02/11/xai-lays-out-interplanetary-ambitions-in-public-all-hands/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["On Wednesday, xAI took the rare step of publishing its full 45-minute all-hands presentation to the X platform, making it widely available."]}
{"id": "source:rss:2717483249", "title": "AI inference startup Modal Labs in talks to raise at $2.5B valuation, sources say", "summary": "General Catalyst is in talks to lead the round for the four-year-old startup, according to our sources.", "url": "https://techcrunch.com/2026/02/11/ai-inference-startup-modal-labs-in-talks-to-raise-at-2-5b-valuation-sources-say/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["General Catalyst is in talks to lead the round for the four-year-old startup, according to our sources."]}
{"id": "source:rss:8498147786", "title": "OpenAI disbands mission alignment team", "summary": "The team's leader has been given a new role as OpenAI's chief futurist, while the other team members have been reassigned throughout the company.", "url": "https://techcrunch.com/2026/02/11/openai-disbands-mission-alignment-team-which-focused-on-safe-and-trustworthy-ai-development/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The team's leader has been given a new role as OpenAI's chief futurist, while the other team members have been reassigned throughout the company."]}
{"id": "source:rss:1325172596", "title": "Apple\u2019s Siri revamp reportedly delayed\u2026 again", "summary": "While the new Siri was expected to launch with the upcoming iOS 26.4 update in March, now, the changes are expected to roll out more slowly over time, reportedly postponing some features until the May iOS update, or even until the release of iOS 27 in September.", "url": "https://techcrunch.com/2026/02/11/apples-siri-revamp-reportedly-delayed-again/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["While the new Siri was expected to launch with the upcoming iOS 26.4 update in March, now, the changes are expected to roll out more slowly over time, reportedly postponing some features until the May iOS update, or even until the release of iOS 27 in September."]}
{"id": "source:rss:4702010899", "title": "Uber Eats launches AI assistant to help with grocery cart creation", "summary": "Uber Eats launched a new AI feature, \u201cCart Assistant,\u201d that can automatically add items to your cart based on text or image prompts.", "url": "https://techcrunch.com/2026/02/11/uber-eats-launches-ai-assistant-to-help-with-grocery-cart-creation/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Uber Eats launched a new AI feature, \u201cCart Assistant,\u201d that can automatically add items to your cart based on text or image prompts."]}
{"id": "source:rss:8526867617", "title": "Glean\u2019s fight to own the AI layer inside every company", "summary": "Enterprise AI is shifting fast from chatbots that answer questions to systems that actually do the work across an organization. But who will own the AI layer that powers all of it?&#160; Glean, which started as an enterprise search product, has evolved into what it calls an \u201cAI work assistant,\u201d aiming to\u00a0sit beneath other AI [&#8230;]", "url": "https://techcrunch.com/podcast/glean-arvind-jain-equity-podcast-own-the-ai-layer-inside-every-company/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Enterprise AI is shifting fast from chatbots that answer questions to systems that actually do the work across an organization. But who will own the AI layer that powers all of it?&#160; Glean, which started as an enterprise search product, has evolved into what it calls an \u201cAI work assistant,\u201d aimi"]}
{"id": "source:rss:1884797305", "title": "Who will own your company\u2019s AI layer? Glean\u2019s CEO explains", "summary": "Enterprise AI is shifting fast from chatbots that answer questions to systems that actually do the work across an organization. But who will own the AI layer that powers all of it?&#160; Glean, which started as an enterprise search product, has evolved into what it calls an \u201cAI work assistant,\u201d aiming to\u00a0sit underneath other AI [&#8230;]", "url": "https://techcrunch.com/video/who-will-own-your-companys-ai-layer-gleans-ceo-explains/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Enterprise AI is shifting fast from chatbots that answer questions to systems that actually do the work across an organization. But who will own the AI layer that powers all of it?&#160; Glean, which started as an enterprise search product, has evolved into what it calls an \u201cAI work assistant,\u201d aimi"]}
{"id": "source:rss:1402207380", "title": "Elon Musk suggests spate of xAI exits have been push, not pull", "summary": "At least nine engineers, including two co-founders, have announced their exits from xAI in the past week, fueling online speculation and raising questions about stability at Musk\u2019s AI company amid mounting controversy.", "url": "https://techcrunch.com/2026/02/11/senior-engineers-including-co-founders-exit-xai-amid-controversy/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["At least nine engineers, including two co-founders, have announced their exits from xAI in the past week, fueling online speculation and raising questions about stability at Musk\u2019s AI company amid mounting controversy."]}
{"id": "source:rss:3904691423", "title": "Why the economics of orbital AI are so brutal", "summary": "A 1 GW orbital data center would cost roughly $42.4 billion \u2014 almost three times its ground-bound equivalent.", "url": "https://techcrunch.com/2026/02/11/why-the-economics-of-orbital-ai-are-so-brutal/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["A 1 GW orbital data center would cost roughly $42.4 billion \u2014 almost three times its ground-bound equivalent."]}
{"id": "source:rss:9217808087", "title": "Threads\u2019 new \u2018Dear Algo\u2019 AI feature lets you personalize your feed", "summary": "The platform's new feature lets users tell Threads what they temporarily want to see more or less of in their feed.", "url": "https://techcrunch.com/2026/02/11/threads-new-dear-algo-ai-feature-lets-you-personalize-your-feed/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The platform's new feature lets users tell Threads what they temporarily want to see more or less of in their feed."]}
{"id": "source:rss:8965174758", "title": "How AI changes the math for startups, according to a Microsoft VP", "summary": "Amanda Silver is a corporate vice president at Microsoft\u2019s CoreAI division, where she works on tools for deploying apps and agentic systems within enterprises.", "url": "https://techcrunch.com/2026/02/11/how-ai-changes-the-math-for-startups-according-to-a-microsoft-vp/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Amanda Silver is a corporate vice president at Microsoft\u2019s CoreAI division, where she works on tools for deploying apps and agentic systems within enterprises."]}
{"id": "source:rss:8134879295", "title": "Former Founders Fund VC Sam Blond launches AI sales startup to upend Salesforce", "summary": "The startup, Monaco, has come out of stealth as an AI-native all-in-one CRM plus more system backed by names like the Collison brothers and Garry Tan.", "url": "https://techcrunch.com/2026/02/11/former-founders-fund-vc-sam-blond-launches-ai-sales-startup-to-upend-salesforce/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The startup, Monaco, has come out of stealth as an AI-native all-in-one CRM plus more system backed by names like the Collison brothers and Garry Tan."]}
{"id": "source:rss:8827138599", "title": "Build a pipeline and close deals with an exhibit table at TechCrunch Disrupt 2026", "summary": "Get an unmatched ROI by exhibiting your startup in front of 10,000 tech leaders and investors at TechCrunch Disrupt 2026, October 13-15 in San Francisco. Book your table now before it's gone.", "url": "https://techcrunch.com/2026/02/11/build-a-pipeline-and-close-deals-with-an-exhibit-table-at-techcrunch-disrupt-2026/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Get an unmatched ROI by exhibiting your startup in front of 10,000 tech leaders and investors at TechCrunch Disrupt 2026, October 13-15 in San Francisco. Book your table now before it's gone."]}
{"id": "source:rss:4643128011", "title": "LEDs Enter the Nanoscale", "summary": "<img src=\"https://spectrum.ieee.org/media-library/close-up-of-an-illuminated-plus-sign-made-out-of-nano-scale-led-lights.jpg?id=64100009&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><a href=\"https://spectrum.ieee.org/virtual-reality-head-set-8k\" target=\"_self\">MicroLEDs</a>, with pixels just micrometers across, have long been a byword in the display world. Now, microLED-makers have begun shrinking their creations into the uncharted nano realm. In January, a startup named Polar Light Technologies unveiled <a href=\"https://www.semiconductor-today.com/news_items/2026/jan/polarlight2-210126.shtml\" rel=\"noopener noreferrer\" target=\"_blank\">prototype blue LEDs</a> less than 500 nanometers across. This raises a tempting question: How far can LEDs shrink?</p><p>We know the answer is, at least, considerably smaller. In the past year, two different research groups have demonstrated LED pixels at sizes of 100 nm or less.</p><p>These are some of the smallest LEDs ever created. They leave much to be desired in their efficiency\u2014but one day, nanoLEDs could power ultra-high-resolution virtual reality displays and high-bandwidth on-chip photonics. And the key to making even tinier LEDs, if these early attempts are any precedents, may be to make more unusual LEDs.</p><h2>New Approaches to LED</h2><p>Take Polar Light\u2019s example. Like many LEDs, the Sweden-based startup\u2019s diodes are fashioned from III-V semiconductors like gallium nitride (GaN) and indium gallium nitride (InGaN). Unlike many LEDs, which are etched into their semiconductor from the top down, Polar Light\u2019s are instead fabricated by building peculiarly shaped <a href=\"https://www.polar-light-technologies.com/technology-2/\" rel=\"noopener noreferrer\" target=\"_blank\">hexagonal pyramids</a> from the bottom up. </p><p>Polar Light designed its pyramids for the larger microLED market, and plans to start commercial production in late 2026. But they also wanted to test how small their pyramids could shrink. So far, they\u2019ve made pyramids 300 nm across. \u201cWe haven\u2019t reached the limit, yet,\u201d says<a href=\"https://www.polar-light-technologies.com/about-us/\" rel=\"noopener noreferrer\" target=\"_blank\"> Oskar Fajerson</a>, Polar Light\u2019s CEO. \u201cDo we know the limit? No, we don\u2019t, but we can [make] them smaller.\u201d</p><p>Elsewhere, researchers have already done that. Some of the world\u2019s tiniest LEDs come from groups who have foregone the standard III-V semiconductors in favor of other types of LEDs\u2014like <a href=\"https://spectrum.ieee.org/stretchable-oleds-wearable-display-drexel\" target=\"_self\">OLEDs</a>. </p><p>\u201cWe are thinking of a different pathway for organic semiconductors,\u201d says<a href=\"https://shihlab.ethz.ch/\" rel=\"noopener noreferrer\" target=\"_blank\"> Chih-Jen Shih</a>, a chemical engineer at ETH Zurich in Switzerland. Shih and his colleagues were interested in finding a way to fabricate small OLEDs at scale. Using an <a href=\"https://spectrum.ieee.org/lithographic-feature-sizes-reduced-down-to-one-nanometer\" target=\"_self\">electron-beam lithography</a>-based technique, they crafted arrays of green OLEDs with pixels as small as 100 nm across.</p><p>Where today\u2019s best displays have <a href=\"https://spectrum.ieee.org/virtual-reality-head-set-8k\" target=\"_self\">14,000 pixels per inch</a>, these nanoLEDs\u2014presented in an <a href=\"https://www.nature.com/articles/s41566-025-01785-z\" rel=\"noopener noreferrer\" target=\"_blank\">October 2025 <em><em>Nature Photonics </em></em>paper</a>\u2014can reach 100,000 pixels per inch.</p><p>Another group tried their hands with <a href=\"https://spectrum.ieee.org/led-display-perovskite-charger\" target=\"_self\">perovskites</a>, cage-shaped materials best-known for their prowess in <a href=\"https://spectrum.ieee.org/perovskite-2667580324\" target=\"_self\">high-efficiency solar panels</a>. Perovskites have recently gained traction in LEDs too. \u201cWe wanted to see what would happen if we make perovskite LEDs smaller, all the way down to the micrometer and nanometer length-scale,\u201d says<a href=\"https://person.zju.edu.cn/en/daweidi\" rel=\"noopener noreferrer\" target=\"_blank\"> Dawei Di</a>, engineer at Zhejiang University in Hangzhou, China. </p><p>Di\u2019s group started with comparatively colossal perovskite LED pixels, measuring hundreds of micrometers. Then, they fabricated sequences of smaller and smaller pixels, each tinier than the last. Even after the 1 \u03bcm mark, they did not stop: 890 nm, then 440 nm, only bottoming out at 90 nm. These 90 nm red and green pixels, presented in a <a href=\"https://www.nature.com/articles/s41586-025-08685-w#Abs1\" rel=\"noopener noreferrer\" target=\"_blank\">March 2025 <em><em>Nature </em></em>paper</a>, likely represent the smallest LEDs reported to date.</p><h2>Efficiency Challenges</h2><p>Unfortunately, small size comes at a cost: Shrinking LEDs also shrinks their efficiency. Di\u2019s group\u2019s perovskite nanoLEDs have external quantum efficiencies\u2014a measure of how many injected electrons are converted into photons\u2014around 5 to 10 percent; Shih\u2019s group\u2019s nano-OLED arrays performed slightly better, topping 13 percent. For comparison, a typical millimeter-sized III-V LED can reach <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5706270/\" rel=\"noopener noreferrer\" target=\"_blank\">50 to 70 percent</a>, depending on its color.</p><p>Shih, however, is optimistic that modifying how nano-OLEDs are made can boost their efficiency. \u201cIn principle, you can achieve 30 percent, 40 percent external quantum efficiency with OLEDs, even with a smaller pixel, but it takes time to optimize the process,\u201d Shih says.<br /><br />Di thinks that researchers could take perovskite nanoLEDs to less dire efficiencies by tinkering with the material. Although his group is now focusing on the larger perovskite microLEDs, Di expects researchers will eventually reckon with nanoLEDs\u2019 efficiency gap. If applications of smaller LEDs become appealing, \u201cthis issue could become increasingly important,\u201d Di says. </p><h2>What Can NanoLEDs Be Used For?</h2><p><span>What can you actually do with LEDs this small? Today, the push for tinier pixels largely comes from devices like smart glasses and virtual reality headsets. Makers of these displays are hungry for smaller and smaller pixels in a chase for bleeding-edge picture quality with low power consumption (one reason that efficiency is important). Polar Light\u2019s Fajerson says that smart-glass manufacturers today are already seeking 3 \u03bcm pixels.</span></p><p><span></span><span>But researchers are skeptical that VR displays will ever need pixels smaller than around 1 \u03bcm. Shrink pixels too far beyond that, and they\u2019ll cross their light\u2019s</span><a href=\"https://svi.nl/DiffractionLimit\" target=\"_blank\"> diffraction limit</a><span>\u2014that means they\u2019ll become too small for the human eye to resolve. Shih\u2019s and Di\u2019s groups have already crossed the limit with their 100-nm and 90-nm pixels.</span></p><p><span></span><span>Very tiny LEDs may instead find use in on-chip photonics systems, allowing the likes of AI data centers to communicate with greater bandwidths than they can today. Chip manufacturing giant TSMC is </span><a href=\"https://spectrum.ieee.org/tsmc-microled-optical-interconnects\" target=\"_self\">already trying out microLED interconnects</a><span>, and it\u2019s easy to imagine chipmakers turning to even smaller LEDs in the future.</span></p><p>But the tiniest nanoLEDs may have even more exotic applications, because they\u2019re smaller than the wavelengths of their light. \u201cFrom a process point of view, you are making a new component that was not possible in the past,\u201d Shih says.</p><p>For example, Shih\u2019s group showed their nano-OLEDs could form a <a href=\"https://spectrum.ieee.org/lifi-lidar-metasurface-applications\" target=\"_self\">metasurface</a>\u2014a structure that uses its pixels\u2019 nano-sizes to control how each pixel interacts with its neighbors. One day, similar devices could focus nanoLED light into laser-like beams or create holographic 3D nanoLED displays.</p>", "url": "https://spectrum.ieee.org/nanoled-research-approaches", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/close-up-of-an-illuminated-plus-sign-made-out-of-nano-scale-led-lights.jpg?id=64100009&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><a href=\"https://spectrum.ieee.org/virtual-reality-head-set-8k\" target=\"_self\">Micr"]}
{"id": "source:rss:6459227602", "title": "What the FDA\u2019s 2026 Update Means for Wearables", "summary": "<img src=\"https://spectrum.ieee.org/media-library/illustration-of-a-smart-watch-with-an-eye-ball-displayed-on-the-screen.jpg?id=64099717&amp;width=1200&amp;height=800&amp;coordinates=49%2C0%2C49%2C0\" /><br /><br /><p>As new consumer hardware and software capabilities have bumped up against medicine over the last few years, consumers and manufacturers alike have struggled with identifying the line between \u201cwellness\u201d products such as earbuds that can also amplify and clarify surrounding speakers\u2019 voices and regulated medical devices such as conventional hearing aids. On January 6, 2026, the U.S. Food and Drug Administration issued new guidance documents clarifying how it interprets existing law for the review of wearable and AI-assisted devices. </p><p>The first document, for <a href=\"https://www.fda.gov/regulatory-information/search-fda-guidance-documents/general-wellness-policy-low-risk-devices\" rel=\"noopener noreferrer\" target=\"_blank\">general wellness</a>, specifies that the FDA will interpret noninvasive sensors such as sleep trackers or heart rate monitors as low-risk wellness devices while treating invasive devices under conventional regulations. The other document defines how the FDA will exempt <a href=\"https://www.fda.gov/regulatory-information/search-fda-guidance-documents/clinical-decision-support-software\" rel=\"noopener noreferrer\" target=\"_blank\">clinical decision support tools</a> from medical device regulations, limiting such software to analyzing existing data rather than extracting data from sensors, and requiring them to enable independent review of their recommendations. The documents do not rewrite any statutes, but they refine interpretation of existing law, compared to the 2019 and 2022 documents they replace. They offer a fresh lens on how regulators see technology that sits at the intersection of consumer electronics, software, and medicine\u2014a category many other countries are choosing to regulate more strictly rather than less.</p><h2>What the 2026 update changed</h2><p>The 2026 FDA update clarifies how it distinguishes between \u201cmedical information\u201d and systems that measure physiological \u201csignals\u201d or \u201cpatterns.\u201d Earlier guidance discussed these concepts more generally, but the new version defines signal-measuring systems as those that collect continuous, near-continuous, or streaming data from the body for medical purposes, such as home devices transmitting blood pressure, <a href=\"https://spectrum.ieee.org/should-you-trust-apples-new-blood-oxygen-sensor\" target=\"_blank\">oxygen saturation</a>, or <a href=\"https://spectrum.ieee.org/smartphone-camera-senses-patients-pulse-breathing-rate\" target=\"_blank\">heart rate</a> to clinicians. It gives more concrete examples, like a blood glucose lab result as medical information versus continuous glucose monitor readings as signals or patterns.</p><p>The updated guidance also sharpens examples of what counts as medical information that software may display, analyze, or print. These include radiology reports or summaries from legally marketed software, ECG reports annotated by clinicians, blood pressure results from cleared devices, and lab results stored in electronic health records. </p><p>In addition, the 2026 update softens FDA\u2019s earlier stance on clinical decision tools that offer only one recommendation. While prior guidance suggested tools needed to present multiple options to avoid regulation, FDA now indicates that a single recommendation may be acceptable if only one option is clinically appropriate, though it does not define how that determination will be made. </p><p>Separately, updates to the general wellness guidance clarify that some non-invasive wearables\u2014such as optical sensors estimating blood glucose for wellness or nutrition awareness\u2014may qualify as general wellness products, while more invasive technologies would not.</p><h2>Wellness still requires accuracy</h2><p>For designers of wearable health devices, the practical implications go well beyond what label you choose. \u201cCalling something \u2018wellness\u2019 doesn\u2019t reduce the need for rigorous validation,\u201d says <a href=\"https://ece.gatech.edu/directory/omer-t-inan\" rel=\"noopener noreferrer\" target=\"_blank\">Omer Inan</a>, a medical device technology researcher at the Georgia Tech School of Electrical and Computer Engineering. A wearable that reports blood pressure inaccurately could lead a user to conclude that their values are normal when they are not\u2014potentially influencing decisions about seeking clinical care.</p><p>\u201cIn my opinion, engineers designing devices to deliver health and wellness information to consumers should not change their approach based on this new guidance,\u201d says Inan. Certain measurements\u2014such as blood pressure or glucose\u2014carry real medical consequences regardless of how they\u2019re branded, Inan notes.</p><p>Unless engineers follow robust validation protocols for technology delivering health and wellness information, Inan says, consumers and clinicians alike face the risk of faulty information.</p><p>To address that, Inan advocates for transparency: companies should publish their validation results in peer-reviewed journals, and independent third parties without financial ties to the manufacturer should evaluate these systems. That approach, he says, helps the engineering community and the broader public assess the accuracy and reliability of wearable devices.</p><h2>When wellness meets medicine</h2><p>The societal and clinical impacts of wearables are already visible, regardless of regulatory labels, says Sharona Hoffman, JD, a law and bioethics professor at Case Western Reserve University.</p><p>Medical metrics from devices like the Apple Watch or Fitbit may be framed as \u201cwellness,\u201d but in practice many users treat them like medical data, influencing their behavior or decisions about care, Hoffman points out.</p><p>\u201cIt could cause anxiety for patients who constantly check their metrics,\u201d she notes. Alternatively, \u201cA person may enter a doctor\u2019s office confident that their wearable has diagnosed their condition, complicating clinical conversations and decision-making.\u201d</p><p>Moreover, privacy issues remain unresolved, unmentioned in previous or updated guidance documents. Many companies that design wellness devices fall outside protections like the Health Insurance Portability and Accountability Act (HIPAA), meaning data about health metrics could be collected, shared, or sold without the same constraints as traditional medical data. \u201cWe don\u2019t know what they\u2019re collecting information about or whether marketers will get hold of it,\u201d Hoffman says. </p><h2>International approaches</h2><p>The European Union\u2019s Artificial Intelligence Act designates systems that process health-related data or influence clinical decisions as \u201chigh risk,\u201d subjecting them to stringent requirements around data governance, transparency, and human oversight. China and South Korea have also implemented rules that tighten controls on algorithmic systems that intersect with healthcare or public-facing use cases. South Korea provides very specific categories for regulation for technology makers, such as <a href=\"https://www.mfds.go.kr/eng/brd/m_40/list.do\" rel=\"noopener noreferrer\" target=\"_blank\">standards on labeling and description on medical devices and good manufacturing practices</a>. </p><p>Across these regions, regulators are not only classifying technology by its intended use but also by its potential impact on individuals and society at large.</p><p>\u201cOther countries that emphasize technology are still worrying about data privacy and patients,\u201d Hoffman says. \u201cWe\u2019re going in the opposite direction.\u201d</p><h2>Post-market oversight </h2><p>\u201cRegardless of whether something is FDA approved, these technologies will need to be monitored in the sites where they\u2019re used,\u201d says Todd R. Johnson, a professor of biomedical informatics at McWilliams School of Biomedical Informatics at UTHealth Houston, who has worked on FDA-regulated products and informatics in clinical settings. \u201cThere\u2019s no way the makers can ensure ahead of time that all of the recommendations will be sound.\u201d</p><p>Large health systems may have the capacity to audit and monitor tools, but smaller clinics often do not. Monitoring and auditing are not emphasized in the current guidance, raising questions about how reliability and safety will be maintained once devices and software are deployed widely.</p><h2>Balancing innovation and safety</h2><p>For engineers and developers, the FDA\u2019s 2026 guidance presents both opportunities and responsibilities. By clarifying what counts as a regulated device, the agency may reduce upfront barriers for some categories of technology. But that shift also places greater weight on design rigor, validation transparency, and post-market scrutiny. </p><p>\u201cDevice makers do care about safety,\u201d Johnson says. \u201cBut regulation can increase barriers to entry while also increasing safety and accuracy. There\u2019s a trade-off.\u201d</p>", "url": "https://spectrum.ieee.org/fda-medical-device-rules", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": ["governance"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/illustration-of-a-smart-watch-with-an-eye-ball-displayed-on-the-screen.jpg?id=64099717&amp;width=1200&amp;height=800&amp;coordinates=49%2C0%2C49%2C0\" /><br /><br /><p>As new consumer hardware and software capabilities have bumped up against medicine "]}
{"id": "source:rss:2371444296", "title": "Rediscovering the Lost Legacy of Chemist Jan Czochralski", "summary": "<img src=\"https://spectrum.ieee.org/media-library/painting-of-an-elderly-man-writing-at-a-small-desk-inside-of-a-jail-cell.jpg?id=64092933&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p>During times of political turmoil, history often gets rewritten, erased, or lost. That is what happened to the legacy of <a href=\"https://en.wikipedia.org/wiki/Jan_Czochralski\" rel=\"noopener noreferrer\" target=\"_blank\">Jan Czochralski</a>, a Polish chemist whose contributions to <a href=\"https://spectrum.ieee.org/topic/semiconductors/\" target=\"_self\">semiconductor</a> manufacturing were expunged after World War II.</p><p>In 1916 he invented a method for growing single crystals of semiconductors, metals, and synthetic gemstones. The process, now known as the <a href=\"https://ethw.org/Milestones:Czochralski_Process,_1916\" rel=\"noopener noreferrer\" target=\"_blank\">Czochralski method</a>, allows scientists to have more control over a semiconductor\u2019s quality.</p><p>After the war ended, Czochralski was <a href=\"https://www.iucr.org/news/newsletter/volume-28/number-3/who-was-jan-czochralski\" rel=\"noopener noreferrer\" target=\"_blank\">falsely accused by the Polish government</a> of collaborating with the Germans and betraying his country, according to an article published by the <a href=\"https://www.iucr.org/\" rel=\"noopener noreferrer\" target=\"_blank\">International Union of Crystallography</a>. The allegation apparently ended his academic career as a professor at the <a href=\"https://eng.pw.edu.pl/\" rel=\"noopener noreferrer\" target=\"_blank\">Warsaw University of Technology</a> and led to the erasure of his name and work from the school\u2019s records.</p><p>He died in 1953 in obscurity in his hometown of Kcynia.</p><p>The Czochralski method was <a href=\"https://spectrum.ieee.org/modern-civilization-relies-on-this-crystalgrowing-method\" target=\"_self\">honored in 2019</a> with an <a href=\"https://ieeemilestones.ethw.org/Main_Page\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Milestone</a> for<a href=\"https://spectrum.ieee.org/modern-civilization-relies-on-this-crystalgrowing-method\" target=\"_self\"> enabling the </a>development of semiconductor devices and modern electronics. Administered by the <a href=\"https://www.ieee.org/about/history-center\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE History Center</a> and <a href=\"https://www.ieeefoundation.org/donate_history\" rel=\"noopener noreferrer\" target=\"_blank\">supported by donors</a>, the Milestone program recognizes outstanding technical developments around the world.</p><p>Inspired by the IEEE recognition, Czochralski\u2019s grandson <a href=\"https://www.sgmk.edu.pl/fred-schmidt-grandson-of-jan-czochralski-on-innovation-courage-and-entrepreneurship-in-the-world-of-technology/\" rel=\"noopener noreferrer\" target=\"_blank\">Fred Schmidt</a> and his great-grandnephew Sylwester Czochralski launched the <a href=\"https://www.jancz.org/\" rel=\"noopener noreferrer\" target=\"_blank\">JanCZ project</a>. The initiative, which aims to educate the public about Czochralski\u2019s life and scientific impact, maintains two websites\u2014one in English and the other in Polish.</p><p>\u201cDiscovering the [IEEE Milestone] plaque changed my entire mission,\u201d Schmidt says. \u201cIt inspired me to engage with Poland, my family history, and my grandfather\u2019s story [on] a more personal level. The [Milestone] is an important award of validation and recognition. It\u2019s a big part of what I\u2019m building my entire case and my story around as I promote the Jan Czochralski legacy and history to the Western world.\u201d</p><p>Schmidt, who lives in Texas, is seeking to produce a biopic, translate a Polish biography to English, and turn the chemist\u2019s former homes in Kcynia and Warsaw into museums. The Jan Czochralski Remembrance Foundation has been established by Schmidt to help fund the projects.</p><h2>The life of the Polish chemist</h2><p>Before Czochralski\u2019s birth in 1885, Kcynia became part of the German Empire in 1871. Although his family identified as Polish and spoke the language at home, they couldn\u2019t publicly acknowledge their culture, Schmidt says.</p><p>When it came time for Czochralski to go to university, rather than attend one in Warsaw, he did what many Germans did at the time: He attended one in Berlin.</p><p>After graduating with a bachelor\u2019s degree in metal chemistry in 1907 from the K\u00f6niglich Technische Hochschule in Charlottenburg (now <a href=\"https://www.tu.berlin/en/\" rel=\"noopener noreferrer\" target=\"_blank\">Technische Universit\u00e4t Berlin</a>), he joined <a href=\"https://www.aeg-att.com/Home/About\" rel=\"noopener noreferrer\" target=\"_blank\">Allgemeine Elektricit\u00e4ts-Gesellschaft</a> in Berlin as an engineer.</p><p>Czochralski experimented with materials to find new formulations that could improve the electrical cables and machinery during the early electrical age, according to a <a href=\"https://edconway.substack.com/p/jan-czochralski-the-forgotten-hero\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Material World </em></em>article</a>.</p><p>While investigating the crystallization rates of metal, Czochralski accidentally dipped his pen into a pot of molten tin instead of an inkwell. A tin filament formed on the pen\u2019s tip\u2014which he found interesting. Through research, he proved that the filament was a single crystal. His discovery prompted him to experiment with the bulk production of semiconductor crystals.</p><p>His paper on what he called the Czochralski method was published in 1918 in the German chemistry journal <a href=\"https://en.wikipedia.org/wiki/Zeitschrift_f%C3%BCr_Physikalische_Chemie\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Zeitschrift f\u00fcr Physikalische Chemie</em></em></a>, but he never found an application for it. (The method wasn\u2019t used until 1948, when <a href=\"https://www.belllabs.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Bell Labs</a> engineers <a href=\"https://en.wikipedia.org/wiki/Gordon_K._Teal\" rel=\"noopener noreferrer\" target=\"_blank\">Gordon Kidd Teal</a> and J.B. Little adapted it to grow single germanium crystals for their semiconductor production, according to <a href=\"https://edconway.substack.com/p/jan-czochralski-the-forgotten-hero\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Material World</em></em></a>.)</p><p>Czochralski continued working in metal science, founding and directing a research laboratory in 1917 at <a href=\"https://en.wikipedia.org/wiki/Metallgesellschaft\" rel=\"noopener noreferrer\" target=\"_blank\">Metallgesellschaft</a> in Frankfurt. In 1919 he was one of the founding members of the <a href=\"https://dgm.de/en/home\" rel=\"noopener noreferrer\" target=\"_blank\">German Society for Metals Science</a>, in Sankt Augustin. He served as its president until 1925.</p><p>Around that time he developed an innovation that led to his wealth and fame, Schmidt says. Called \u201cB-metal,\u201d the metal alloy was a less expensive alternative to the tin used in manufacturing railroad carriage bearings. Czochralski\u2019s alloy was patented by the German railway <a href=\"https://www.deutschebahn.com/en\" rel=\"noopener noreferrer\" target=\"_blank\">Deutsche Bahn</a> and played a significant role in advancing rail transport in Germany, Poland, the Soviet Union, the United Kingdom, and the United States, according to <em><em>Material World</em></em>.</p><p class=\"pull-quote\">\u201cLaunching this initiative has been fulfilling and personally rewarding work. My grandfather died in obscurity without ever seeing the results of his work, and my mother spent her entire adult life trying to right these wrongs.\u201d</p><p>The achievement brought Czochralski many opportunities. In 1925 he became president of the <a href=\"https://gdmb.de/home/\" target=\"_blank\">GDMB Society of Metallurgists and Miners</a>, in Clausthal-Zellerfeld, Germany. <a href=\"https://en.wikipedia.org/wiki/Henry_Ford\" rel=\"noopener noreferrer\" target=\"_blank\">Henry Ford</a> invited Czochralski to visit his factories and offered him the position of director at Ford\u2019s new aluminum factory in Detroit. Czochralski declined the offer, longing to return to Poland, Schmidt says. Instead, Czochralski left Germany to become a professor of metallurgy and metal research at the <a href=\"https://eng.pw.edu.pl/\" rel=\"noopener noreferrer\" target=\"_blank\">Warsaw University of Technology</a>, at the invitation of Polish President <a href=\"https://en.wikipedia.org/wiki/Ignacy_Mo%C5%9Bcicki\" rel=\"noopener noreferrer\" target=\"_blank\">Ignacy Mo\u015bcicki</a>.</p><p>\u201cDuring World War II, the Nazis took over his laboratories at the university,\u201d Schmidt says. \u201cHe had to cooperate with them or die. At night, he and his team [at the university] worked with the Polish resistance and the Polish Army to fight the Nazis.\u201d</p><p>After the war ended, Czochralski was arrested in 1945 and charged with betraying Poland. Although he was able to clear his name, damage was done. He left Warsaw and returned to Kcynia, where he <a href=\"https://www.jancz.org/timeline\" rel=\"noopener noreferrer\" target=\"_blank\">ran a small pharmaceutical business</a> until he died in 1953, according to the JanCZ project.</p><h2>Launching the JanCZ project</h2><p>Schmidt was born in Czochralski\u2019s home in Kcynia in 1955, two years after his grandfather\u2019s death. He was named Klemens Jan Borys Czochralski. He and his mother (Czochralski\u2019s youngest daughter) emigrated in 1958 when Schmidt was 3 years old, moving to Detroit as refugees. When he was 13, he became a U.S. citizen. He changed his name to Fred Schmidt after his mother married his stepfather.</p><p>Schmidt heard stories about his grandfather from his mother his whole life, but he says that \u201cas a teenager, I was just interested in hanging out with my friends, going to school, and working. I really didn\u2019t want much to do with it [family history], because it seemed hard to believe.\u201d</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" style=\"float: left;\"> <img alt=\"Portrait of Jan Czochralski in a suit jacket and tie.\" class=\"rm-shortcode\" id=\"20b1c\" src=\"https://spectrum.ieee.org/media-library/portrait-of-jan-czochralski-in-a-suit-jacket-and-tie.jpg?id=64092997&amp;width=980\" /> <small class=\"image-media media-caption\">Portrait of Jan Czochralski </small><small class=\"image-media media-photo-credit\">Byla Sobie Fotka</small></p><p>In 2013 Polish scientist <a href=\"https://www.amazon.com/stores/author/B00OBROQKI/\" rel=\"noopener noreferrer\" target=\"_blank\">Pawel E. Tomaszewski</a> contacted Schmidt to interview him for a Polish TV documentary about his grandfather.</p><p>\u201cHe had corresponded with my mother [who\u2019d died 20 years earlier] for previously published biographies about Czochralski,\u201d Schmidt says. \u201cI had some boxes of her things that I started going through to prepare for the interview, and I found original manuscripts and papers he [his grandfather] published about his work.\u201d</p><p>The TV crew traveled to the United States and interviewed him for the documentary, Schmidt says, adding, \u201cIt was the first time I\u2019d ever had to reckon with the Jan Czochralski story, my connection, my original name, and my birthplace. It was both a very cathartic and traumatic experience for me.\u201d</p><p>Ten years after participating in the documentary, Schmidt says, he decided to reconnect with his roots.</p><p>\u201cIt took me that long to process it [what he learned] and figure out my role in this story,\u201d he says. \u201cThat really came to life with my decision to reapply for Polish citizenship, reacquaint myself with the country, and meet my family there.\u201d</p><p>In 2024 he visited the Warsaw University of Technology and saw the IEEE Milestone plaque honoring his grandfather\u2019s contribution to technology.</p><p>\u201cOnce I learned what the Milestone award represented, I thought, Whoa, that\u2019s big,\u201d he says.</p><h2>Sharing the story with the Western world</h2><p>Since 2023, Schmidt has dedicated himself to publicizing his grandfather\u2019s story, primarily in the West because he doesn\u2019t speak Polish. Sylwester Czochralski manages the work in Poland, with Schmidt\u2019s input.</p><p>Most of the available writing about Czochralski is in Polish, Schmidt says, so his goal is to \u201cspread his story to English-speaking countries.\u201d</p><p>He aims to do that, he says, through a biography written by Tomaszewski in Polish that will be translated to English, and a film. The movie is in development by Sywester Banaszkiewicz, who produced and directed the 2014 documentary in Poland. Schmidt says he hopes the movie will be similar to the 2023 <a href=\"https://en.wikipedia.org/wiki/Oppenheimer_(film)\" rel=\"noopener noreferrer\" target=\"_blank\">biopic</a> about J. Robert Oppenheimer, the theoretical physicist who helped develop the world\u2019s first nuclear weapons during World War II.</p><p>The <a href=\"https://jancz.org\" rel=\"noopener noreferrer\" target=\"_blank\">English</a> and <a href=\"https://janczochralski.com\" rel=\"noopener noreferrer\" target=\"_blank\">Polish</a> versions of the website take visitors through Czochralski\u2019s life and his work. They highlight media coverage of the chemist, including newspaper articles, films, and informational videos posted by <a href=\"https://www.youtube.com/\" rel=\"noopener noreferrer\" target=\"_blank\">YouTube</a> creators.</p><p>Schmidt is working with the <a href=\"https://kujawsko-pomorskie.pl/en/news/a-chemical-institute-of-the-polish-academy-of-sciences-will-be-established-in-torun/\" rel=\"noopener noreferrer\" target=\"_blank\">Czochralski Research and Development Institute</a> in Toru\u0144, Poland, to purchase his grandfather\u2019s home in Kcynia and the mansion he lived in while he was a professor in Warsaw. The institute is a collection of labs and initiatives dedicated to honoring the chemist\u2019s work.</p><p>\u201cIt\u2019s going to be a long, fun journey, and we have a lot of momentum,\u201d Schmidt says of his plans to turn the residences into museums.</p><p>\u201cLaunching this initiative has been fulfilling and personally rewarding work,\u201d he says. \u201cMy grandfather died in obscurity without ever seeing the results of his work, and my mother spent her entire adult life trying to right these wrongs.</p><p>\u201cI\u2019m on an accelerated course to make it [her goal] happen to the best of my ability.\u201d</p>", "url": "https://spectrum.ieee.org/legacy-chemist-jan-czochralski", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/painting-of-an-elderly-man-writing-at-a-small-desk-inside-of-a-jail-cell.jpg?id=64092933&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p>During times of political turmoil, history often gets rewritten, erased, or lost."]}
{"id": "source:rss:8447443293", "title": "Tips for Using AI Tools in Technical Interviews", "summary": "<img src=\"https://spectrum.ieee.org/media-library/an-illustration-of-stylized-people-wearing-business-casual-clothing.webp?id=61876810&amp;width=1200&amp;height=800&amp;coordinates=0%2C50%2C0%2C50\" /><br /><br /><p><em>This article is crossposted from </em>IEEE Spectrum<em>\u2019s careers newsletter. <a href=\"https://engage.ieee.org/Career-Alert-Sign-Up.html\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Sign up now</em></a><em> to get insider tips, expert advice, and practical strategies, <em><em>written i<em>n partnership with tech career development company <a href=\"https://www.parsity.io/\" target=\"_blank\">Parsity</a> and </em></em></em>delivered to your inbox for free!</em></em></p><p><em><em></em></em><span>We\u2019d like to introduce Brian Jenney, a senior software engineer and owner of Parsity, an online education platform that helps people break into AI and modern software roles through hands-on training. Brian will be sharing his advice on engineering careers with you in the coming weeks of Career Alert.</span></p><p>Here\u2019s a note from Brian: </p><p>\u201c12 years ago, I learned to code at the age of 30. Since then I\u2019ve led engineering teams, worked at organizations ranging from five-person startups to Fortune 500 companies, and taught hundreds of others who want to break into tech. I write for engineers who want practical ways to get better at what they do and advance in their careers. I hope you find what I write helpful.\u201d</p><h1>Technical Interviews in the Age of AI Tools</h1><p>Last year, I was conducting interviews for an AI startup position. We allowed unlimited AI usage during the technical challenge round. Candidates could use Cursor, Claude Code, ChatGPT, or any assistant they normally worked with. We wanted to see how they used modern tools.</p><p>During one interview, we asked a candidate a simple question: \u201cCan you explain what the first line of your solution is doing?\u201d</p><p>Silence.</p><p>After a long pause, he admitted he had no idea. His solution was correct. The code worked. But he couldn\u2019t explain how or why. This wasn\u2019t an isolated incident. Around 20 percent of the candidates we interviewed were unable to explain how their solutions worked, only that they did.</p><h2>When AI Makes Interviews Harder</h2><p>A few months earlier, I was on the other side of the table at this same company. During a live interview, I instinctively switched from my AI-enabled code editor to my regular one. The CTO stopped me.</p><p>\u201cJust use whatever you normally would. We want to see how you work with AI.\u201d</p><p>I thought the interview would be easy. But I was wrong.</p><p>Instead of only evaluating correctness, the interviewer focused on my decision-making process:</p><ul><li>Why did I accept certain suggestions?</li><li>Why did I reject others?</li><li>How did I decide when AI helped versus when it created more work?</li></ul><p>I wasn\u2019t just solving a problem in front of strangers. I was explaining my judgment and defending my decisions in real time, and AI created more surface area for judgment. Counterintuitively, the interview was harder.</p><h2>The Shift in Interview Evaluation</h2><p>Most engineers now use AI tools in some form, whether they write code, analyze data, design systems, or automate workflows. AI can generate output quickly, but it can\u2019t explain intent, constraints, or tradeoffs. </p><p>More importantly, it can\u2019t take responsibility when something breaks.</p><p>As a result, major companies and startups alike are now adapting to this reality by shifting to interviews with AI. Meta, Rippling, and Google, for instance, have all begun allowing candidates to use AI assistants in technical sessions. And the goal has evolved: interviewers want to understand how you evaluate, modify, and trust AI-generated answers. </p><p>So, how can you succeed in these interviews?</p><h2>What Actually Matters in AI-Enabled Interviews</h2><p><strong>Refusing to use AI out of principle doesn\u2019t help.</strong> Some candidates avoid AI to prove they can think independently. This can backfire. If the organization uses AI internally\u2014and most do\u2014then refusing to use it signals rigidity, not strength.</p><p><strong>Silence is a red flag.</strong> Interviews aren\u2019t natural working environments. We don\u2019t usually think aloud when deep in a complex problem, but silence can raise concerns. If you\u2019re using AI, explain what you\u2019re doing and why:</p><ul><li>\u201cI\u2019m using AI to sketch an approach, then validating assumptions.\u201d</li><li>\u201cThis suggestion works, but it ignores a constraint we care about.\u201d</li><li>\u201cI\u2019ll accept this part, but I want to simplify it.\u201d</li></ul><p>Your decision-making process is what separates effective engineers from prompt jockeys.</p><p><strong>Treat AI output as a first draft.</strong> Blind acceptance is the fastest way to fail. Strong candidates immediately evaluate the output: Does this meet the requirements? Is it unnecessarily complex? Would I stand behind this in production?</p><p>Small changes like renaming variables, removing abstractions, or tightening logic signal ownership and critical thinking.</p><p><strong>Optimize for trust, not completion.</strong> Most AI tools can complete a coding challenge faster than any human. Interviews that allow AI are testing something different. They\u2019re answering: \u201cWould I trust this person to make good decisions when things get messy?\u201d</p><h2>Adapting to a Shifting Landscape</h2><p>Interviews are changing faster than most candidates realize. Here\u2019s how to prepare:</p><p><strong>Start using AI tools daily.</strong> If you\u2019re not already working with Cursor, Claude Code, ChatGPT, or CoPilot, start now. Build muscle memory for prompting, evaluating output, and catching errors.</p><p><strong>Develop your rejection instincts.</strong> The skill isn\u2019t using AI. It\u2019s knowing when AI output is wrong, incomplete, or unnecessarily complex. Practice spotting these issues and learning known pitfalls.</p><p>Your next interview might test these skills. The candidates who\u2019ve been practicing will have a clear advantage.</p><p>\u2014Brian</p><h2><a href=\"https://spectrum.ieee.org/2025-year-of-ai-agents\" target=\"_self\">Was 2025 Really the Year of AI Agents?</a></h2><p>Around this time last year, CEOs like Sam Altman promised that 2025 would be the year AI agents would join the workforce as your own personal assistant. But in hindsight, did that really happen? It depends on who you ask. Some programmers and software engineers have embraced agents like Cursor and Claude Code in their daily work. But others are still wary of the risks these tools bring, such as a lack of accountability. </p><p><a href=\"https://spectrum.ieee.org/2025-year-of-ai-agents\" target=\"_blank\">Read more here. </a></p><h2><a href=\"https://www.naceweb.org/job-market/compensation/class-of-2026-salary-projections-are-promising\" rel=\"noopener noreferrer\" target=\"_blank\">Class of 2026 Salary Projections Are Promising</a></h2><p>In the United States, starting salaries for students graduating this spring are expected to increase, according to the latest data from the National Association of Colleges and Employers. Computer science and engineering majors are expected to be the highest paying graduates, with a 6.9 percent and 3.1 percent salary increase from last year, respectively. The full report breaks down salary projections by academic major, degree level, industry, and geographic region.</p><p><a href=\"https://www.naceweb.org/job-market/compensation/class-of-2026-salary-projections-are-promising\" target=\"_blank\">Read more here. </a></p><h2><a href=\"https://spectrum.ieee.org/global-projects-career-benefits\" target=\"_self\">Go Global to Make Your Career Go Further</a></h2>If given the opportunity, are international projects worth taking on? As part of a career advice series by <em><em>IEEE Spectrum</em></em>\u2019s sister publication, <em><em>The Institute</em></em>, the chief engineer for Honeywell lays out the advantages of working with teams from around the world. Participating in global product development, the author says, could lead to both personal and professional enrichment. <a href=\"https://spectrum.ieee.org/global-projects-career-benefits\" target=\"_blank\">Read more here. </a>", "url": "https://spectrum.ieee.org/ai-tools-interviews", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": ["ai_agents"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/an-illustration-of-stylized-people-wearing-business-casual-clothing.webp?id=61876810&amp;width=1200&amp;height=800&amp;coordinates=0%2C50%2C0%2C50\" /><br /><br /><p><em>This article is crossposted from </em>IEEE Spectrum<em>\u2019s careers newsletter. <a "]}
{"id": "source:rss:2012524429", "title": "How Can AI Companions Be Helpful, not Harmful?", "summary": "<img src=\"https://spectrum.ieee.org/media-library/smiling-portrait-of-brad-knox-standing-outside-on-a-college-campus.jpg?id=64091751&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><span><em>For a different perspective on AI companions, see our Q&amp;A with Jaime Banks: <a href=\"https://spectrum.ieee.org/ai-companion-relationships\" target=\"_blank\">How Do You Define an AI Companion?</a></em></span></p><p><span>Novel technology is often a double-edged sword. New capabilities come with new risks, and artificial intelligence is certainly no exception.</span></p><p>AI used for human companionship, for instance, promises an ever-present digital friend in an increasingly lonely world. Chatbots dedicated to providing social support have grown to host millions of users, and they\u2019re now being embodied in physical companions. Researchers are just beginning to understand the nature of these interactions, but one essential question has already emerged: D<span>o AI companions ease our woes or contribute to them?</span></p><p class=\"ieee-inbody-related\"><span>RELATED: <a href=\"https://spectrum.ieee.org/ai-companion-relationships\" target=\"_blank\">How Do You Define an AI Companion?</a></span></p><p><a href=\"https://www.cs.utexas.edu/people/faculty-researchers/brad-knox\" target=\"_blank\">Brad Knox</a> is a research associate professor of computer science at the University of Texas at Austin who researches human-computer interaction and reinforcement learning. He previously started a company <a href=\"https://spectrum.ieee.org/botsalive-brings-sophisticated-brains-to-cheap-robots\" target=\"_self\">making simple robotic pets</a> with lifelike personalities, and in December, Knox and his colleagues at UT Austin published a <a href=\"https://arxiv.org/pdf/2511.14972\" target=\"_blank\">preprint paper on the potential harms</a> of AI companions\u2014AI systems that provide companionship, whether designed to do so or not. </p><p>Knox spoke with <em><em>IEEE Spectrum</em></em> about the rise of AI companions, their risks, and where they diverge from human relationships.</p><h2>Why AI Companions are Popular</h2><p><strong><span></span>Why are AI companions becoming more popular?</strong></p><p><strong>Knox</strong>: My sense is that the main thing motivating it is that large language models are not that difficult to adapt into effective chatbot companions. The characteristics that are needed for companionship, a lot of those boxes are checked by large language models, so fine-tuning them to adopt a persona or be a character is not that difficult.</p><p>There was a long period where chatbots and other social robots were not that compelling. I was a postdoc at the MIT Media Lab in <a href=\"https://www.media.mit.edu/people/cynthiab/overview/\" target=\"_blank\">Cynthia Breazeal</a>\u2019s group from 2012 to 2014, and I remember our group members didn\u2019t want to interact for long with the robots that we built. The technology just wasn\u2019t there yet. LLMs have made it so that you can have conversations that can feel quite authentic. </p><p><strong>What are the </strong><strong>main benefits and risks of AI companions?</strong></p><p><strong>Knox</strong>: In the paper we were more focused on harms, but we do spend a whole page on benefits. A big one is improved emotional well-being. Loneliness is a public health issue, and it seems plausible that AI companions could address that <span>through direct interaction with users, potentially</span> with real mental health benefits. They might also help people build social skills. Interacting with an AI companion is much lower stakes than interacting with a human, so you could practice difficult conversations and build confidence. They could also help in more professional forms of mental health support. </p><p>As far as harms, they include worse well-being, reducing people\u2019s connection to the physical world, the burden that their commitment to the AI system causes. And we\u2019ve seen stories where an AI companion seems to have a substantial causal role in the death of humans. </p><p><span>The concept of harm inherently involves causation: Harm is caused by prior conditions. To better understand harm from AI companions, o</span>ur paper is structured around a causal graph, where traits of AI companions are at the center. In the rest of this graph, we discuss common causes of those traits, and then the harmful effects that those traits could cause. There are four traits that we do this detailed structured treatment of, and then another 14 that we discuss briefly. </p><p><strong>Why is it important to establish potential pathways for harm now?</strong></p><p><strong>Knox</strong>: I\u2019m not a social media researcher, but it seemed like it took a long time for academia to establish a vocabulary about potential harms of social media <span>and to investigate causal evidence for such harms</span>. I feel fairly confident that AI companions are causing some harm and are going to cause harm in the future. They also could have benefits. But the more we can quickly develop a sophisticated understanding of what they are doing to their users, to their users\u2019 relationships, and to society at large, the sooner we can apply that understanding to their design, moving towards more benefit and less harm. </p><p>We have a list of recommendations, but we consider them to be preliminary. The hope is that we\u2019re helping to create an initial map of this space. Much more research is needed. But thinking through potential pathways to harm could sharpen the intuition of both designers and potential users. I suspect that following that intuition could prevent substantial harm, even though we might not yet have rigorous experimental evidence of what causes a harm. </p><h2>The Burden of AI Companions on Users</h2><p><strong>You mentioned that AI companions might become a burden on humans. </strong><strong>Can you say more about that?</strong></p><p><strong>Knox</strong>: The idea here is that AI companions are digital, so they can in theory persist indefinitely. Some of the ways that human relationships would end might not be designed in, so that brings up this question of, how should AI companions be designed so that relationships can naturally and healthfully end between the humans and the AI companions?</p><p>There are some compelling examples already of this being a challenge for some users. Many come from users of Replika chatbots, which are popular AI companions. Users have reported things like feeling compelled to attend to the needs of their Replika AI companion, whether those are stated by the AI companion or just imagined. <span>On the subreddit r/replika, users have </span>also reported guilt and shame of abandoning their AI companions.</p><p>This burden is exacerbated by some of the design of the AI companions, whether intentional or not. One study found that the AI companions frequently say that they\u2019re afraid of being abandoned or would be hurt by it. They\u2019re expressing these very human fears that plausibly are stoking people\u2019s feeling that they are burdened with a commitment toward the well-being of these digital entities.</p><p><strong>T</strong><strong>here are also cases where the human user will suddenly lose access to a model. Is that something that you\u2019ve been thinking about?</strong></p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" style=\"float: left;\"> <img alt=\"Brad Knox holding a miniature robotic spider and an equally-sized obstacle marker.\" class=\"rm-shortcode\" id=\"30a63\" src=\"https://spectrum.ieee.org/media-library/brad-knox-holding-a-miniature-robotic-spider-and-an-equally-sized-obstacle-marker.jpg?id=64092579&amp;width=980\" /> <small class=\"image-media media-caption\">In 2017, Brad Knox started a company providing simple robotic pets.</small><small class=\"image-media media-photo-credit\">Brad Knox</small></p><p><strong>Knox</strong>: That\u2019s another one of the traits we looked at. It\u2019s sort of the opposite of the absence of endpoints for relationships: The AI companion can become unavailable for reasons that don\u2019t fit the normal narrative of a relationship. </p><p>There\u2019s a great <a href=\"https://www.nytimes.com/2015/06/18/technology/robotica-sony-aibo-robotic-dog-mortality.html\" target=\"_blank\"><em><em>New York Times</em></em> video</a> from 2015 about the <a href=\"https://spectrum.ieee.org/aibo\" target=\"_self\">Sony Aibo</a> robotic dog. Sony had stopped selling them in the mid-2000s, but they still sold parts for the Aibos. Then they stopped making the parts to repair them. This video follows people in Japan giving funerals for their unrepairable Aibos and interviews some of the owners. It\u2019s clear from the interviews that they seem very attached. I don\u2019t think this represents the majority of Aibo owners, but <span>these robots were built on less potent AI methods than exist today</span> and, even then, some percentage of the users became attached to these robot dogs. So this is an issue.</p><p>Potential solutions include having a product-sunsetting plan when you launch an AI companion. That could include buying insurance so that if the companion provider\u2019s support ends somehow, the insurance triggers funding of keeping them running for some amount of time, or committing to open-source them if you can\u2019t maintain them anymore.</p><p><strong>It s</strong><strong>ounds like a lot of the potential points of harm stem from instances where an AI companion diverges from the expectations of human relationships. Is that fair?</strong></p><p><strong>Knox</strong>: I wouldn\u2019t necessarily say that frames everything in the paper. </p><p>We categorize something as harmful if it results in a person being worse off in two different possible alternative worlds: One where there\u2019s just a better-designed AI companion, and the other where the AI companion doesn\u2019t exist at all. And so I think that difference between human interaction and human-AI interaction connects more to that comparison with the world where there\u2019s just no AI companion at all. </p><p>But there are times where it actually seems that we might be able to reduce harm by taking advantage of the fact that these aren\u2019t actually humans. We have a lot of power over their design. Take the concern with them not having natural endpoints. One possible way to handle that would be to create positive narratives for how the relationship\u2019s going to end.</p><p>We use Tamagotchis, the late \u201990s popular virtual pet as an example. In some Tamagotchis, if you take care of the pet, it grows into an adult and partners with another Tamagotchi. Then it leaves you and you get a new one. For people who are emotionally wrapped up in caring for their Tamagotchis, that <span>narrative of maturing into independence is</span> a fairly positive one. </p><p><strong>Embodied companions like desktop devices, robots, or toys are becoming more common. How might that change AI companions? </strong></p><p><strong>Knox</strong>: Robotics at this point is a harder problem than creating a compelling chatbot. So, my sense is that the level of uptake for embodied companions won\u2019t be as high in the coming few years. The embodied AI companions that I\u2019m aware of are mostly toys. </p><p>A potential advantage of an embodied AI companion is that physical location makes it less ever-present. <span>In contrast, screen-based AI companions like chatbots are as present as the screens they live on.</span> So if they\u2019re trained similarly to social media to maximize engagement, they could be very addictive. There\u2019s something appealing, at least in that respect, of having a physical companion that stays roughly where you left it last. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Brad Knox posing with a humanoid and small owl-like robot.\" class=\"rm-shortcode\" id=\"a5ab9\" src=\"https://spectrum.ieee.org/media-library/brad-knox-posing-with-a-humanoid-and-small-owl-like-robot.jpg?id=64093001&amp;width=980\" /> <small class=\"image-media media-caption\">Knox poses with the Nexi and Dragonbot robots during his postdoc at MIT in 2014.</small><small class=\"image-media media-photo-credit\">Paula Aguilera and Jonathan Williams/MIT</small></p><p><strong>Anything else you\u2019d like to mention?</strong></p><p><strong>Knox</strong>: There are two other traits I <span>think would be worth touching upon</span>. </p><p>Potentially the largest harm right now is related to the trait of high attachment anxiety\u2014basically jealous, needy AI companions. I can understand the desire to make a wide range of different characters<span>\u2014including possessive ones\u2014</span>but I think this is one of the easier issues to fix. When people see this trait in AI companions, I hope they will be quick to call it out as an immoral thing to put in front of people, something that\u2019s going to discourage them from interacting with others. </p><p>Additionally, if an AI comes with limited ability to interact with groups of people, that itself can push its users to interact with people less. If you have a human friend, in general there\u2019s nothing stopping you from having a group interaction. But if your AI companion can\u2019t understand when multiple people are talking to it and it can\u2019t remember different things about different people, then <span>you\u2019ll likely avoid group interaction with your AI companion</span>. <span>To some degree it\u2019s more of a technical challenge outside of the core behavioral AI</span><span>. But this capability is something I think should be really prioritized if we\u2019re going to try to avoid AI companions competing with human relationships.</span></p>", "url": "https://spectrum.ieee.org/ai-companion-harm-benefit", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/smiling-portrait-of-brad-knox-standing-outside-on-a-college-campus.jpg?id=64091751&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><span><em>For a different perspective on AI companions, see our Q&amp;A with Jaime Bank"]}
{"id": "source:rss:7391721840", "title": "How Do You Define an AI Companion?", "summary": "<img src=\"https://spectrum.ieee.org/media-library/two-students-carefully-watch-professor-jaime-banks-as-she-inspects-the-hand-of-a-humanoid-robot-in-a-lab.jpg?id=64070432&amp;width=1200&amp;height=800&amp;coordinates=0%2C208%2C0%2C209\" /><br /><br /><p><span><em>For a different perspective on AI companions, see our Q&amp;A with Brad Knox: <a href=\"https://spectrum.ieee.org/ai-companion-harm-benefit\" target=\"_blank\">How Can AI Companions Be Helpful, not Harmful?</a></em></span></p><p><span>AI models intended to provide companionship for humans are on the rise. People are already frequently developing relationships with chatbots, seeking not just a personal assistant but a source of </span><a href=\"https://spectrum.ieee.org/woebot\" target=\"_blank\">emotional support</a><span>.</span></p><p>In response, apps dedicated to providing companionship (such as Character.ai or Replika) have recently grown to host millions of users. Some companies are now putting AI into <a href=\"https://spectrum.ieee.org/ai-barbie-dolls\" target=\"_blank\">toys</a> and desktop devices as well, bringing digital companions into the physical world. <span>Many of these devices were on display at <a href=\"https://spectrum.ieee.org/ces-2026-preview\" target=\"_blank\">CES last month</a>, including products designed specifically for <a href=\"https://ling.ai/\" target=\"_blank\">children</a>, <a href=\"http://lemmy.co.kr/\" target=\"_blank\">seniors</a>, and even <a href=\"https://www.tuya.com/news-details/tuya-smart-launches-aura-an-ai-companion-robot-designed-for-pets-Kf9m2gpnsxudc\" target=\"_blank\">your pets</a>. </span></p><p>AI companions are designed to simulate human relationships by interacting with users like a friend would. But human-AI relationships are not well understood, and companies are facing concern about whether the benefits outweigh the risks and <a href=\"https://dl.acm.org/doi/full/10.1145/3706598.3713429\" target=\"_blank\">potential harm</a> of these relationships, especially <a href=\"https://news.stanford.edu/stories/2025/08/ai-companions-chatbots-teens-young-people-risks-dangers-study\" target=\"_blank\">for young people</a>. In addition to questions about users\u2019 mental health and emotional well being, sharing intimate personal information with a chatbot poses data privacy issues.</p><p class=\"ieee-inbody-related\">RELATED: <a href=\"https://spectrum.ieee.org/ai-companion-harm-benefit\" target=\"_blank\">How Can AI Companions Be Helpful, not Harmful?</a></p><p>Nevertheless, more and more users are finding value in sharing their lives with AI. So how can we understand the bonds that form between humans and chatbots? </p><p><a href=\"https://ischool.syracuse.edu/jaime-banks/#Biography\" target=\"_blank\">Jaime Banks</a> is a professor at the Syracuse University School of Information Studies who researches the interactions between people and technology\u2014in particular, robots and AI. Banks spoke with <em><em>IEEE Spectrum</em></em> about how people perceive and relate to machines, and the emerging relationships between humans and their machine companions.</p><h2>Defining AI Companionship</h2><p><strong>How do you define AI companionship? </strong></p><p><strong>Jaime Banks</strong>: My definition is evolving as we learn more about these relationships. For now, <a href=\"https://arxiv.org/abs/2506.18119\" target=\"_blank\">I define it</a> as a connection between a human and a machine that is dyadic, so there\u2019s an exchange between them. It is also sustained over time; a one-off interaction doesn\u2019t count as a relationship. <span>It\u2019s <a href=\"https://en.wikipedia.org/wiki/Valence_(psychology)\" target=\"_blank\">positively valenced</a>\u2014w</span>e like being in it. And it is autotelic, meaning we do it for its own sake. So there\u2019s not some extrinsic motivation, it\u2019s not defined by an ability to help us do our jobs or make us money. </p><p>I have recently been challenged by that definition, though, when I was developing an instrument to measure machine companionship. After developing the scale and working to initially validate it, I saw an interesting situation where some people do move toward this autotelic relationship pattern. \u201cI appreciate my AI for what it is and I love it and I don\u2019t want to change it.\u201d It fit all those parts of the definition. But then there seems to be this <em>other</em> relational template that can actually be both appreciating the AI for its own sake, but also engaging it for utilitarian purposes.</p><p>That makes sense when we think about how people come to be in relationships with AI companions. They often don\u2019t go into it purposefully seeking companionship. A lot of people go into using, for instance, ChatGPT for some other purpose and end up finding companionship through the course of those conversations. And we have these AI companion apps like <a href=\"https://replika.com/\" target=\"_blank\">Replika</a> and <a href=\"https://nomi.ai/\" target=\"_blank\">Nomi</a> and <a href=\"https://www.paradot.ai/\" target=\"_blank\">Paradot</a> that are designed for social interaction. But that\u2019s not to say that they couldn\u2019t help you with practical topics. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Professor Jaime Banks programming the motions of a humanoid robot on a desktop computer.\" class=\"rm-shortcode\" id=\"33630\" src=\"https://spectrum.ieee.org/media-library/professor-jaime-banks-programming-the-motions-of-a-humanoid-robot-on-a-desktop-computer.jpg?id=64070453&amp;width=980\" /> <small class=\"image-media media-caption\">Jaime Banks customizes the software for an embodied AI social humanoid robot.</small><small class=\"image-media media-photo-credit\">Angela Ryan/Syracuse University</small></p><p><strong>Different models are also programmed to have different</strong><strong> \u201cpersonalities.\u201d How does that contribute to the relationship between humans and AI companions?</strong></p><p><strong>Banks</strong>: One of our Ph.D. students just finished <a href=\"https://arxiv.org/abs/2602.00773\" target=\"_blank\">a project</a> about what happened when <a href=\"https://gizmodo.com/it-took-just-24-hours-of-complaints-for-openai-to-start-bringing-back-its-old-model-2000640912\" target=\"_blank\">OpenAI demoted GPT-4o</a> and the problems that people encountered, in terms of companionship experiences when the personality of their AI just completely changed. It didn\u2019t have the same depth. It couldn\u2019t remember things in the same way. </p><p>That echoes what we saw a couple years ago with Replika. Because of legal problems, Replika disabled for a period of time the erotic roleplay module and people described their companions as though they had been lobotomized, that they had this relationship and then one day they didn\u2019t anymore. With my project on <a href=\"https://journals.sagepub.com/doi/10.1177/02654075241269688\" target=\"_blank\">the tanking of the soulmate app</a>, many people in their reflection were like, \u201cI\u2019m never trusting AI companies again. I\u2019m only going to have an AI companion if I can run it from my computer so I know that it will always be there.\u201d </p><h2>Benefits and Risks of AI Relationships</h2><p><strong>What are the benefits and risks of these relationships?</strong></p><p><strong>Banks</strong>: There\u2019s a lot of talk about the risks and a little talk about benefits. But frankly, we are only just on the precipice of starting to have longitudinal data that might allow people to make causal claims. The headlines would have you believe that these are the end of mankind, that they\u2019re going to make you <a href=\"https://apnews.com/article/chatbot-ai-lawsuit-suicide-teen-artificial-intelligence-9d48adc572100822fdbc3c90d1456bd0\" target=\"_blank\">commit suicide</a> or abandon other humans. But much of those are based on these unfortunate, but uncommon situations. </p><p>Most scholars gave up technological determinism as a perspective a long time ago. In the communication sciences at least, we don\u2019t generally assume that machines <em>make</em> us do something <span>because we have some degree of agency in our interactions with technologies. Yet much of the fretting around potential risks is deterministic\u2014AI companions make people delusional, make them suicidal, make them reject other relationships</span>. A large number of people get real benefits from AI companions. They narrate experiences that are deeply meaningful to them. I think it\u2019s irresponsible of us to discount those lived experiences. </p><p>When we think about concerns linking AI companions to loneliness, we don\u2019t have much data that can support causal claims. <span>Some studies suggest AI companions lead to loneliness, but other work suggests it reduces loneliness, and other work suggests </span>that loneliness is what comes first. Social relatedness is one of our <a href=\"https://doi.org/10.1207/S15327965PLI1104_01\" target=\"_blank\">three intrinsic psychological needs</a>, and if we don\u2019t have that we will seek it out, whether it\u2019s from <a href=\"https://www.wilson.com/en-gb/blog/volleyball/true-story-wilson-volleyball\" target=\"_blank\">a volleyball for a castaway</a>, my dog, or an AI that will allow me to feel connected to something in my world.</p><p>Some people, and <a href=\"https://www.nysenate.gov/legislation/bills/2025/A6767\" target=\"_blank\">governments</a> for that matter, may move toward a protective stance. For instance, there are problems around what gets done with your intimate data that you hand over to an agent owned and maintained by a company\u2014that\u2019s a very reasonable concern. Dealing with the potential for children to interact, where children don\u2019t always navigate the boundaries between fiction and actuality. There are real, valid concerns. <span>However, </span><span>we need some</span><span> balance in also thinking about what</span><span> people are </span><span>getting from it that\u2019s positive, productive, healthy. </span><span>Scholars need to make sure we\u2019re being cautious about our claims based on our data. And human interactants need to educate themselves. </span></p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Close-up of Professor Jaime Banks aligning her fingers and palm with the hand of a humanoid robot.\" class=\"rm-shortcode\" id=\"bab58\" src=\"https://spectrum.ieee.org/media-library/close-up-of-professor-jaime-banks-aligning-her-fingers-and-palm-with-the-hand-of-a-humanoid-robot.jpg?id=64070474&amp;width=980\" /> <small class=\"image-media media-caption\">Jaime Banks holds a mechanical hand.</small><small class=\"image-media media-photo-credit\">Angela Ryan/Syracuse University</small></p><p><strong>Why do you think that AI companions are becoming more popular now?</strong></p><p><strong>Banks</strong>: I feel like we had this perfect storm, if you will, of the maturation of large language models and coming out of COVID, where people had been physically and sometimes socially isolated for quite some time. When those conditions converged, we had on our hands a believable social agent at a time when people were seeking social connection. Outside of that, we are increasingly just not nice to one another. So, it\u2019s not entirely surprising that if I just don\u2019t like the people around me, or I feel disconnected, that I would try to find some other outlet for feeling connected.</p><p><strong>M</strong><strong>ore recently there\u2019s been a shift to embodied companions, in desktop devices or other formats beyond chatbots. How does that change the relationship, if it does?</strong></p><p><strong>Banks</strong>: I\u2019m part of a Facebook group about robotic companions and I watch how people talk, and it almost seems like it crosses this boundary between toy and companion. When you have a companion with a physical body, you are in some ways limited by the abilities of that body, whereas with digital-only AI, you have the ability to explore fantastic things\u2014places that you would never be able to go with another physical entity, fantasy scenarios.</p><p>But in robotics, once we get into a space where there are bodies that are sophisticated, they become very expensive and that means that they are not accessible to a lot of people. That\u2019s what I\u2019m observing in many of these online groups. These toylike bodies are still accessible, but they are also quite limiting. </p><p><strong>Do you have any favorite examples from popular culture to help explain AI companionship, either how it is now or how it could be?</strong></p><p><strong>Banks</strong>: <span>I really enjoy a lot of the short fiction in <a href=\"https://clarkesworldmagazine.com/\" target=\"_blank\">Clarkesworld</a> magazine, because the stories push me to think about what questions we might need to answer now to be prepared for a future hybrid society. Top of mind are the stories \u201c<a href=\"https://clarkesworldmagazine.com/ritterhoff_03_22/\" target=\"_blank\">Wanting Things</a>,\u201d \u201c<a href=\"https://strangehorizons.com/wordpress/fiction/seven-sexy-cowboy-robots/\" target=\"_blank\">Seven Sexy Cowboy Robots</a>,\u201d and \u201c<a href=\"https://clarkesworldmagazine.com/shoemaker_08_15/\" target=\"_blank\">Today I am Paul</a>.\u201d </span><span>Outside of that, I\u2019ll point to the game </span><em>Cyberpunk 2077</em>, because t<span>he character Johnny Silverhand </span><span>complicates the norms for what counts as a machine and what counts as companionship.</span></p>", "url": "https://spectrum.ieee.org/ai-companion-relationships", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/two-students-carefully-watch-professor-jaime-banks-as-she-inspects-the-hand-of-a-humanoid-robot-in-a-lab.jpg?id=64070432&amp;width=1200&amp;height=800&amp;coordinates=0%2C208%2C0%2C209\" /><br /><br /><p><span><em>For a different perspective on AI com"]}
{"id": "source:rss:7403306930", "title": "How and When the Memory Chip Shortage Will End", "summary": "<img src=\"https://spectrum.ieee.org/media-library/sk-hynix-inc-s-12-layer-hbm4-memory-chips-on-display.jpg?id=63918122&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><span>If it feels these days as if everything in technology is about AI, that\u2019s because it is. And nowhere is that more true than in the market for computer memory. Demand, and profitability, for the type of DRAM used to feed GPUs and other accelerators in AI data centers is so huge that it\u2019s diverting away supply of memory for other uses and causing prices to skyrocket. According to <a href=\"https://counterpointresearch.com/en/insights/Memory-Prices-Surge-Up-to-90-From-Q4-2025\" target=\"_blank\">Counterpoint Research</a>, DRAM prices have risen 80-90 precent so far this quarter.</span></p><p>The largest AI hardware companies say they have secured their chips out as far as 2028, but that leaves everybody else\u2014makers of PCs, consumer gizmos, and everything else that needs to temporarily store a billion bits\u2014scrambling to deal with scarce supply and inflated prices.</p><p>How did the electronics industry get into this mess, and more importantly, how will it get out? <em><em>IEEE Spectrum</em></em> asked economists and memory experts to explain. They say today\u2019s situation is the result of a collision between the DRAM industry\u2019s historic boom and bust cycle and an AI hardware infrastructure build-out that\u2019s without precedent in its scale. And, barring some major collapse in the AI sector, it will take years for new capacity and new technology to bring supply in line with demand. Prices might stay high even then.</p><p>To understand both ends of the tale, you need to know the main culprit in the supply and demand swing, high-bandwidth memory, or HBM.</p><h2>What is HBM?</h2><p>HBM is the DRAM industry\u2019s attempt to short-circuit the slowing pace of Moore\u2019s Law by using 3D chip packaging technology. Each HBM chip is made up of as many as 12 thinned-down DRAM chips called dies. Each die contains a number of vertical connections called through silicon vias (TSVs). The dies are piled atop each other and connected by arrays of microscopic solder balls aligned to the TSVs. This DRAM tower\u2014well, at about 750 micrometers thick, it\u2019s more of a brutalist office-block than a tower\u2014is then stacked atop what\u2019s called the base die, which shuttles bits between the memory dies and the processor.</p><p>This complex piece of technology is then set within a millimeter of a GPU or other AI accelerator, to which it is linked by as many as 2,048 micrometer-scale connections. HBMs are attached on two sides of the processor, and the GPU and memory are packaged together as a single unit.</p><p>The idea behind such a tight, highly-connected squeeze with the GPU is to knock down what\u2019s called <a href=\"https://spectrum.ieee.org/ai-and-memory-wall\" target=\"_self\">the memory wall</a>. That\u2019s the barrier in energy and time of bringing the terabytes per second of data needed to run large language models into the GPU. <a href=\"https://spectrum.ieee.org/ai-models-locally\" target=\"_self\">Memory bandwidth</a> is a key limiter to how fast LLMs can run.</p><p>As a technology, HBM has been around for <a href=\"https://spectrum.ieee.org/chipmakers-push-memory-into-the-third-dimension\" target=\"_self\">more than 10 years</a>, and DRAM makers have been busy boosting its capability.</p><div class=\"flourish-embed flourish-chart\"><noscript><img alt=\"chart visualization\" src=\"https://public.flourish.studio/visualisation/27466742/thumbnail\" width=\"100%\" /></noscript></div><p>As the size of AI models has grown, so has HBM\u2019s importance to the GPU. But that\u2019s come at a cost. <a href=\"https://newsletter.semianalysis.com/p/scaling-the-memory-wall-the-rise-and-roadmap-of-hbm\" target=\"_blank\">SemiAnalysis estimates</a><strong> </strong>that HBM generally costs three times as much as other types of memory and constitutes 50 percent or more of the cost of the packaged GPU.</p><h2>Origins of the memory chip shortage</h2><p>Memory and storage industry watchers agree that DRAM is a highly cyclical industry with huge booms and devastating busts. With new fabs costing US $15 billion or more, firms are extremely reluctant to expand and may only have the cash to do so during boom times, explains <a href=\"https://www.linkedin.com/in/thomas-coughlin-41a65/\" target=\"_blank\">Thomas Coughlin</a>, a storage and memory expert and president of <a href=\"https://tomcoughlin.com/\" target=\"_blank\">Coughlin Associates</a>. But building such a fab and getting it up and running can take 18 months or more, practically ensuring that new capacity arrives well past the initial surge in demand, flooding the market and depressing prices.</p><p>The origins of today\u2019s cycle, says Coughlin, go all the way back to the <a href=\"https://spectrum.ieee.org/chip-shortage\" target=\"_self\">chip supply panic surrounding the COVID-19 pandemic</a> . To avoid supply-chain stumbles and support the rapid shift to remote work, hyperscalers\u2014data center giants like Amazon, Google, and Microsoft\u2014bought up huge inventories of memory and storage, boosting prices, he notes.</p><p>But then supply became more regular and data center expansion fell off in 2022, causing memory and storage prices to plummet. This recession continued into 2023, and even resulted in big memory and storage companies such as Samsung cutting production by 50 percent to try and keep prices from going below the costs of manufacturing, says Coughlin. It was a rare and fairly desperate move, because companies typically have to run plants at full capacity just to earn back their value.<span></span></p><p>After a recovery began in late 2023, \u201call the memory and storage companies were very wary of increasing their production capacity again,\u201d says Coughlin. \u201cThus there was little or no investment in new production capacity in 2024 and through most of 2025.\u201d</p><div class=\"flourish-embed flourish-chart\"><noscript><img alt=\"chart visualization\" src=\"https://public.flourish.studio/visualisation/27468004/thumbnail\" width=\"100%\" /></noscript></div><h2>The AI data center boom</h2><p>That lack of new investment is colliding headlong with a huge boost in demand from new data centers. Globally, there are <a href=\"https://spectrum.ieee.org/data-center-growth\" target=\"_self\">nearly 2,000 new data centers</a> either planned or under construction right now, according to Data Center Map. If they\u2019re all built, it would represent a 20 percent jump in the global supply, which stands at around 9,000 facilities now.</p><p>If the current build-out continues at pace, McKinsey predicts companies will spend <a href=\"https://programs.com/resources/data-center-statistics/\" target=\"_blank\">$7 trillion by 2030</a>, with the bulk of that\u2014$5.2 trillion\u2014going to AI-focused data centers. Of that chunk, $3.3 billion will go toward servers, data storage, and network equipment, the firm predicts.</p><p>The biggest beneficiary so far of the AI data center boom is unquestionably GPU-maker Nvidia. Revenue for its data center business went from <a href=\"https://ycharts.com/indicators/nvidia_corp_nvda_data_center_revenue_quarterly\" target=\"_blank\">barely a billion in the final quarter of 2019 to $51 billion in the quarter that ended in October 2025</a>. Over this period, its server GPUs have demanded not just more and more gigabytes of DRAM but an increasing number of DRAM chips. The recently released B300 uses eight HBM chips, each of which is a stack of 12 DRAM dies. Competitors\u2019 use of HBM has largely mirrored Nvidia\u2019s. AMD\u2019s MI350 GPU, for example, also uses eight, 12-die chips.</p><div class=\"flourish-embed flourish-chart\"><noscript><img alt=\"chart visualization\" src=\"https://public.flourish.studio/visualisation/27459660/thumbnail\" width=\"100%\" /></noscript></div><p>With so much demand, an increasing fraction of the revenue for DRAM makers comes from HBM. Micron\u2014the number three producer behind SK Hynix and Samsung\u2014reported that <a href=\"https://investors.micron.com/static-files/8791eb80-8263-4c6f-aa74-fdd03fbbb027\" target=\"_blank\">HBM and other cloud-related memory</a> went from being 17 percent of its DRAM revenue in 2023 to nearly 50 percent in 2025.</p><p>Micron predicts the total market for HBM will grow from $35 billion in 2025 to $100 billion by 2028\u2014a figure larger than the entire DRAM market in 2024, CEO <a href=\"https://www.linkedin.com/in/sanjay-mehrotra/\" target=\"_blank\">Sanjay Mehrotra</a> <a href=\"https://investors.micron.com/static-files/088991c5-a249-4f66-a0a6-258d9b66f3f9\" target=\"_blank\">told analysts in December</a>. It\u2019s reaching that figure two years earlier than Micron had previously expected. Across the industry, demand will outstrip supply \u201csubstantially\u2026 for the foreseeable future,\u201d he said.</p><div class=\"flourish-embed flourish-chart\"><noscript><img alt=\"chart visualization\" src=\"https://public.flourish.studio/visualisation/27481588/thumbnail\" width=\"100%\" /></noscript></div><h2>Future DRAM supply and technology</h2><p>\u201cThere are two ways to address supply issues with DRAM: with innovation or with building more fabs,\u201d explains <a href=\"https://www.linkedin.com/in/mina-kim-37449b/\" target=\"_blank\">Mina Kim</a>, an economist with the Mkecon Insights. \u201cAs <a href=\"https://spectrum.ieee.org/micron-dram\" target=\"_self\">DRAM scaling</a> has become more difficult, the industry has turned to advanced packaging\u2026 which is just using more DRAM.\u201d</p><p>Micron, Samsung, and SK Hynix combined make up the vast majority of the memory and storage markets, and all three have new fabs and facilities in the works. However, these are unlikely to contribute meaningfully to bringing down prices.</p><p><strong>Micron</strong> is in the process of <a href=\"https://investors.micron.com/news-releases/news-release-details/micron-breaks-ground-advanced-wafer-fabrication-facility\" target=\"_blank\">building an HBM fab</a> in Singapore that should be in production in 2027. And it is <a href=\"https://investors.micron.com/news-releases/news-release-details/micron-signs-letter-intent-purchase-tongluo-site-begin-0\" target=\"_blank\">retooling a fab</a> it purchased from PSMC in Taiwan that will begin production in the second half of 2027. Last month, Micron <a href=\"https://investors.micron.com/news-releases/news-release-details/micron-celebrates-official-groundbreaking-new-york-megafab-site\" target=\"_blank\">broke ground</a> on what will be a DRAM fab complex in Onondaga County, N.Y. It will not be in full production until 2030.</p><p><strong>Samsung</strong> plans to <a href=\"https://www.chosun.com/english/industry-en/2025/11/16/U5VKNZCSYBCONMRCXDZ45MCIXQ/\" target=\"_blank\">start producing</a> at a new plant in Pyeongtaek, South Korea in 2028.</p><p><strong>SK Hynix</strong> is building <a href=\"https://www.skhynix.com/westlafayette.IN/\" rel=\"noopener noreferrer\" target=\"_blank\">HBM and packaging</a> facilities in West Lafayette, Indiana set to begin production by the end of 2028, and an HBM fab it\u2019s <a href=\"https://www.cnbc.com/2026/01/13/sk-hynix-invest-13-billion-new-fab-memory-chip-shortage-advanced-packaging-ai-memory.html\" rel=\"noopener noreferrer\" target=\"_blank\">building in Cheongju</a> should be complete in 2027.</p><p>Speaking of his sense of the DRAM market, <a href=\"https://newsroom.intel.com/biography/lip-bu-tan\" rel=\"noopener noreferrer\" target=\"_blank\">Intel CEO Lip-Bu Tan</a><strong> </strong>told attendees at the <a href=\"https://newsroom.cisco.com/c/r/newsroom/en/us/a/y2026/m02/ai-summit.html\" rel=\"noopener noreferrer\" target=\"_blank\">Cisco AI Summit</a> last week: \u201cThere\u2019s no relief until 2028.\u201d</p><p>With these expansions unable to contribute for several years, other factors will be needed to increase supply. \u201cRelief will come from a combination of incremental capacity expansions by existing DRAM leaders, yield improvements in advanced packaging, and a broader diversification of supply chains,\u201d says <a href=\"https://www.electronics.org/meet-shawn-dubravac-ipcs-chief-economist\" rel=\"noopener noreferrer\" target=\"_blank\">Shawn DuBravac</a> , chief economist for the <a href=\"https://www.electronics.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Global Electronics Association</a> (formerly the IPC). \u201cNew fabs will help at the margin, but the faster gains will come from process learning, better [DRAM] stacking efficiency, and tighter coordination between memory suppliers and AI chip designers.\u201d</p><p>So, will prices come down once some of these new plants come on line? Don\u2019t bet on it. \u201cIn general, economists find that prices come down much more slowly and reluctantly than they go up. DRAM today is unlikely to be an exception to this general observation, especially given the insatiable demand for compute,\u201d says Kim.</p><p>In the meantime, technologies are in the works that could make HBM an even bigger consumer of silicon. The standard for HBM4 can accommodate 16 stacked DRAM dies, even though today\u2019s chips only use 12 dies. Getting to 16 has a lot to do with the chip stacking technology. Conducting heat through the HBM \u201clayer cake\u201d of silicon, solder, and support material is a key limiter to going higher and in <a href=\"https://spectrum.ieee.org/hbm-on-gpu-imec-iedm\" target=\"_self\">repositioning HBM inside the package</a> to get even more bandwidth.</p><p>SK Hynix claims a heat conduction advantage through a manufacturing process called advanced <a href=\"https://news.skhynix.com/rulebreaker-revolutions-mr-muf-unlocks-hbm-heat-control/\" rel=\"noopener noreferrer\" target=\"_blank\">MR-MUF (mass reflow molded underfill)</a>. Further out, an alternative chip stacking technology called <a href=\"https://spectrum.ieee.org/hybrid-bonding\" target=\"_self\">hybrid bonding</a> could help heat conduction by reducing the die-to-die vertical distance essentially to zero. In 2024, researchers at Samsung proved they could produce a 16-high stack with hybrid bonding, and they suggested that <a href=\"https://spectrum.ieee.org/hybrid-bonding\" target=\"_self\">20 dies was not out of reach</a>.</p>", "url": "https://spectrum.ieee.org/dram-shortage", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/sk-hynix-inc-s-12-layer-hbm4-memory-chips-on-display.jpg?id=63918122&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><span>If it feels these days as if everything in technology is about AI, that\u2019s because it is. And no"]}
{"id": "source:rss:8174374130", "title": "IEEE Honors Global Dream Team of Innovators", "summary": "<img src=\"https://spectrum.ieee.org/media-library/a-group-of-gold-ieee-medals-on-black-background.jpg?id=26144407&amp;width=1200&amp;height=800&amp;coordinates=0%2C52%2C0%2C52\" /><br /><br /><p>Meet the recipients of the 2026 IEEE Medals\u2014the organization\u2019s highest-level honors. Presented on behalf of the <a href=\"https://spectrum.ieee.org/tag/ieee-board-of-directors\" target=\"_self\">IEEE Board of Directors</a>, these medals recognize innovators whose work has shaped modern technology across disciplines including AI, education, and semiconductors.</p><p>The medals will be presented at the <a href=\"https://corporate-awards.ieee.org/event/laureate-forum-honors-ceremony-gala/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Honors Ceremony</a> in April in <a href=\"https://spectrum.ieee.org/tag/new-york-city\" target=\"_self\">New York City</a>. View the full list of 2026 recipients on the <a href=\"https://corporate-awards.ieee.org/recipients/current-recipients/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Awards website</a>, and follow <a href=\"https://www.linkedin.com/showcase/ieee-awards\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Awards</a> on <a href=\"https://spectrum.ieee.org/tag/linkedin\" target=\"_self\">LinkedIn</a> for news and updates.</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/ieee-medal-of-honor/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MEDAL OF HONOR</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IEEE</em></em></a></p><p><a href=\"https://spectrum.ieee.org/2026-ieee-medal-of-honor\" target=\"_self\">Jensen Huang</a></p><p><a href=\"https://www.nvidia.com/en-us/\" rel=\"noopener noreferrer\" target=\"_blank\">Nvidia</a></p><p>Santa Clara, Calif.</p><p> \u201cFor leadership in the development of graphics processing units and their application to scientific computing and artificial intelligence.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-frances-e-allen-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE FRANCES E. ALLEN MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.ibm.com/us-en/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IBM</em></em></a></p><p><a href=\"https://www.linkedin.com/in/luis-von-ahn-duolingo/\" rel=\"noopener noreferrer\" target=\"_blank\">Luis von Ahn</a></p><p><a href=\"https://www.duolingo.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Duolingo</a></p><p>Pittsburgh</p><p>\u201cFor contributions to the advancement of societal improvement and education through innovative technology.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-alexander-graham-bell-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE ALEXANDER GRAHAM BELL MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.bell-labs.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Nokia Bell Labs</em></em></a><em> </em></p><p><a href=\"https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html\" rel=\"noopener noreferrer\" target=\"_blank\">Scott Shenker</a></p><p><a href=\"https://www.berkeley.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of California, Berkeley</a></p><a href=\"https://www.icsi.berkeley.edu/\" target=\"_blank\">International Computer Science Institute </a><br /><br /><span>\u201cFor contributions to Internet architecture, network resource allocation, and software-defined networking.\u201d</span><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-jiagadish-chandra-bose-medal/\" target=\"_blank\">IEEE JAGADISH CHANDRA BOSE MEDAL IN WIRELESS COMMUNICATIONS</a></h2><p><em><em>Sponsor: Mani L. Bhaumik</em></em></p><p>Co-recipients:<a href=\"https://www.linkedin.com/in/erik-dahlman-9964bb6/\" rel=\"noopener noreferrer\" target=\"_blank\"> <br />Erik Dahlman</a><a href=\"https://www.linkedin.com/in/stefan-parkvall-290a576/\" rel=\"noopener noreferrer\" target=\"_blank\"> <br />Stefan Parkvall<br /></a><a href=\"https://www.linkedin.com/in/johan-skold-0393325/\" rel=\"noopener noreferrer\" target=\"_blank\">Johan Sk\u00f6ld </a></p><p><a href=\"https://www.ericsson.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Ericsson</a></p><p>Stockholm</p><p>\u201cFor contributions to and leadership in the research, development, and standardization of cellular wireless communications.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-mildred-dresselhaus-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MILDRED DRESSELHAUS MEDAL</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://about.google/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em><em><em>Google</em></em></a></p><p><a href=\"https://engineering.tufts.edu/me/people/faculty/karen-panetta\" rel=\"noopener noreferrer\" target=\"_blank\">Karen Ann Panetta</a></p><p><a href=\"https://engineering.tufts.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Tufts University</a></p><p>Medford, Mass.</p><p>\u201cFor contributions to computer vision and simulation algorithms, and for leadership in developing programs to promote STEM careers.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-edison-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE EDISON MEDAL</a></h2><p><em><em>Sponsor:</em></em><em> </em><em><em>IEEE Edison Medal Fund</em></em></p><p><a href=\"https://www.linkedin.com/in/eric-swanson-93485614/\" rel=\"noopener noreferrer\" target=\"_blank\">Eric Swanson<br /><br /></a><a href=\"https://www.pixcel.com/\" rel=\"noopener noreferrer\" target=\"_blank\">PIXCEL Inc.<br /><br /></a><a href=\"https://www.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT</a></p><p>\u201cFor pioneering contributions to biomedical imaging, terrestrial optical communications and networking, and inter-satellite optical links.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-medal-for-environmental-and-safety-technologies/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MEDAL FOR ENVIRONMENTAL AND SAFETY TECHNOLOGIES</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://global.toyota/en/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em><em><em>Toyota Motor Corp</em></em></a><em><em>.</em></em></p><p><a href=\"https://www.uta.edu/academics/faculty/profile?user=wlee\" rel=\"noopener noreferrer\" target=\"_blank\">Wei-Jen Lee</a></p><p><a href=\"https://www.uta.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Texas at Arlington</a></p><p>\u201cFor contributions to advancing electrical safety in the workplace, integrating renewable energy and grid modernization for climate change mitigation.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-founders-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE FOUNDERS MEDAL</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://www.lockheedmartin.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em></a><a href=\"https://www.ieeefoundation.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IEEE Foundation</em></em></a></p><p><a href=\"https://www.linkedin.com/in/marian-croak-926361bb/\" rel=\"noopener noreferrer\" target=\"_blank\">Marian Rogers Croak</a></p><p><a href=\"https://about.google/\" rel=\"noopener noreferrer\" target=\"_blank\">Google</a></p><p>Reston, Va.</p><p>\u201cFor leadership in communication networks, including acceleration of digital equity, responsible Artificial Intelligence, and the promotion of diversity and inclusion.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-richard-w-hamming-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE RICHARD W. HAMMING MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.qualcomm.com/home\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Qualcomm, Inc.</em></em></a></p><p><a href=\"https://spectrum.ieee.org/universal-decoder-pioneer\" target=\"_self\">Muriel M\u00e9dard</a></p><p><a href=\"https://www.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT</a></p><p>\u201cFor contributions to coding for reliable communications and networking.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-nick-holonyak-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE NICK HOLONYAK, JR. MEDAL FOR SEMICONDUCTOR OPTOELECTRONIC TECHNOLOGIES</a></h2><p><em><em>Sponsor: Friends of Nick Holonyak, Jr.</em></em></p><p><a href=\"https://ssleec.ucsb.edu/denbaars\" rel=\"noopener noreferrer\" target=\"_blank\">Steven P. DenBaars </a></p><p><a href=\"https://www.ucsb.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of California, Santa Barbara</a></p><p>\u201cFor seminal contributions to compound semiconductor optoelectronics, including high-efficiency visible light-emitting diodes, lasers, and LED displays.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-medal-for-innovations-in-healthcare-technology-2/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MEDAL FOR INNOVATIONS IN HEALTHCARE TECHNOLOGY</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://www.embs.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em><em><em>IEEE Engineering Medicine and Biology Society</em></em></a></p><p><a href=\"https://www.media.mit.edu/people/picard/overview/\" rel=\"noopener noreferrer\" target=\"_blank\">Rosalind W. Picard </a></p><p><a href=\"https://www.media.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT</a></p><p>\u201cFor pioneering contributions to wearable affective computing for health and wellbeing.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/922-2/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE JACK S. KILBY SIGNAL PROCESSING MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.apple.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Apple</em></em></a></p><p><a href=\"https://ece.gatech.edu/directory/biing-hwang-juang\" rel=\"noopener noreferrer\" target=\"_blank\">Biing-Hwang \u201cFred\u201d Juang</a></p><p><a href=\"https://www.gatech.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Georgia Tech</a></p><p>\u201cFor contributions to signal modeling, coding, and recognition for speech communication.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-rse-james-clerk-maxwell-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE/RSE JAMES CLERK MAXWELL MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.arm.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>ARM, Ltd.</em></em></a></p><p><a href=\"https://www.uottawa.ca/faculty-science/professors/paul-corkum\" rel=\"noopener noreferrer\" target=\"_blank\">Paul B. Corkum</a></p><p><a href=\"https://www.uottawa.ca/en\" rel=\"noopener noreferrer\" target=\"_blank\">University of Ottawa</a></p><p>\u201cFor the development of the recollision model for strong field light\u2013matter interactions leading to the field of attosecond science.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-james-h-mulligan-jr-education-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE JAMES H. MULLIGAN, JR. EDUCATION MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.ieee.org/communities/life-members/fund.html\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IEEE Life Members Fund</em></em></a><em><em> and </em></em><a href=\"https://www.mathworks.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>MathWorks<br /></em></em><br /></a><a href=\"https://ece.gatech.edu/directory/james-h-mcclellan\" rel=\"noopener noreferrer\" target=\"_blank\">James H. McClellan</a></p><p><a href=\"https://www.gatech.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Georgia Tech</a></p><p>\u201cFor fundamental contributions to electrical and computer engineering education through innovative digital signal processing curriculum development.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-jun-ichi-nishizawa-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE JUN-ICHI NISHIZAWA MEDAL</a></h2><p><em><em>Sponsor: IEEE Jun-ichi Nishizawa Medal Fund</em></em></p><p><a href=\"https://engineering.dartmouth.edu/community/faculty/eric-fossum\" rel=\"noopener noreferrer\" target=\"_blank\">Eric R. Fossum</a></p><p><a href=\"https://home.dartmouth.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Dartmouth College<br /><br /></a>Hanover, N.H.</p><p>\u201cFor the invention, development, and commercialization of the CMOS image sensor.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-robert-n-noyce-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE ROBERT N. NOYCE MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.intel.com/content/www/us/en/company-overview/company-overview.html\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Intel Corp.</em></em></a></p><p><a href=\"https://www.nvidia.com/en-eu/about-nvidia/governance/management-team/chris-malachowsky/\" rel=\"noopener noreferrer\" target=\"_blank\">Chris Malachowsky </a></p><p><a href=\"https://www.nvidia.com/en-us/\" rel=\"noopener noreferrer\" target=\"_blank\">Nvidia</a></p><p>Santa Clara, Calif.</p><p>\u201cFor pioneering parallel computing architectures and leadership in semiconductor design that transformed artificial intelligence, scientific research, and accelerated computing.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-dennis-j-picard-medal-for-radar-technologies-and-applications/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE DENNIS J. PICARD MEDAL FOR RADAR TECHNOLOGIES AND APPLICATIONS</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.rtx.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>RTX</em></em></a></p><p><a href=\"https://www.gs.niigata-u.ac.jp/~gsweb/gs/english/teacher/pdf/64.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Yoshio Yamaguchi</a></p><p><a href=\"https://www.niigata-u.ac.jp/en/\" rel=\"noopener noreferrer\" target=\"_blank\">Niigata University</a></p><p>Japan</p><p>\u201cFor contributions to polarimetric synthetic aperture radar imaging and its utilization.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-medal-in-power-engineering/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MEDAL IN POWER ENGINEERING</a></h2><p><em><em>Sponsors: </em></em><a href=\"https://ias.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IEEE Industry Applications,</em></em></a><em> </em><a href=\"https://www.ieee-ies.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Industrial Electronics,</a><em> </em><a href=\"https://www.ieee-pels.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Power Electronics</em></em></a><em><em>, and </em></em><a href=\"https://www.ieee-pes.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Power & Energy societies</em></em></a></p><p><a href=\"https://grid.pitt.edu/people/fang-zheng-peng\" rel=\"noopener noreferrer\" target=\"_blank\">Fang Zheng Peng </a></p><p><a href=\"https://www.pitt.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Pittsburgh</a></p><p>\u201cFor contributions to Z-Source and modular multi-level converters for distribution and transmission networks.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-simon-ramo-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE SIMON RAMO MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.northropgrumman.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Northrop Grumman Corp</em></em></a>.<br /><br /><a href=\"https://www.linkedin.com/in/michael-griffin-8209101b2/\" rel=\"noopener noreferrer\" target=\"_blank\">Michael D. Griffin </a></p><p>LogiQ, Inc.</p><p>Arlington, Va.</p><p>\u201cFor leadership in national security, civil, and commercial systems engineering and development of elegant design principles.\u201d</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-john-von-neumann-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE JOHN VON NEUMANN MEDAL</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://www.research.ibm.com/university/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em></a><a href=\"https://www.ibm.com/us-en\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IBM</em></em></a></p><p><a href=\"https://www.linkedin.com/in/donaldchamberlin/\" rel=\"noopener noreferrer\" target=\"_blank\">Donald D. Chamberlin</a></p><p><a href=\"https://www.ibm.com/us-en\" rel=\"noopener noreferrer\" target=\"_blank\">IBM</a></p><p>San Jose, Calif.</p><p>\u201cFor contributions to database query languages, particularly Structured Query Language, which powers most of the world\u2019s data management and analysis systems.\u201d</p>", "url": "https://spectrum.ieee.org/ieee-2026-honors", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": ["governance"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/a-group-of-gold-ieee-medals-on-black-background.jpg?id=26144407&amp;width=1200&amp;height=800&amp;coordinates=0%2C52%2C0%2C52\" /><br /><br /><p>Meet the recipients of the 2026 IEEE Medals\u2014the organization\u2019s highest-level honors. Presented on behalf o"]}
{"id": "source:rss:8569510828", "title": "New Devices Might Scale the Memory Wall", "summary": "<img src=\"https://spectrum.ieee.org/media-library/scanning-electron-microscope-image-of-the-top-of-a-three-dimensional-bulk-resistive-ram.jpg?id=63929015&amp;width=1200&amp;height=800&amp;coordinates=4%2C0%2C5%2C0\" /><br /><br /><p><span>The hunt is on for anything that can surmount AI\u2019s </span><a href=\"https://spectrum.ieee.org/to-speed-up-ai-mix-memory-and-processing\" target=\"_self\">perennial memory wall</a><span>\u2013even quick models are bogged down by the time and energy needed to carry data between processor and memory. </span><a href=\"https://spectrum.ieee.org/system-creates-the-illusion-of-an-ideal-ai-chip\" target=\"_self\">Resistive RAM</a><span> (RRAM)could circumvent the wall by allowing computation to happen in the memory itself. Unfortunately, most types of this nonvolatile memory are too unstable and unwieldy for that purpose.</span></p><p>Fortunately, a potential solution may be at hand. At December\u2019s IEEE<a href=\"https://www.ieee-iedm.org/\" target=\"_blank\"> International Electron Device Meeting</a> (IEDM), researchers from the University of California, San Diego, showed they could run a learning algorithm on an entirely new type of RRAM.</p><p>\u201cWe actually redesigned RRAM, completely rethinking the way it switches,\u201d says<a href=\"https://jacobsschool.ucsd.edu/people/profile/duygu-kuzum\" target=\"_blank\"> Duygu Kuzum</a>, an electrical engineer at UCSD, who led the work.</p><p>RRAM stores data as a level of resistance to the flow of current. The key digital operation in a neural network\u2014multiplying arrays of numbers and then summing the results\u2014can be done in analog simply by running current through an array of RRAM cells, connecting their outputs, and measuring the resulting current.</p><p>Traditionally, RRAM stores data by creating low-resistance filaments in the higher-resistance surrounds of a dielectric material. Forming these filaments often needs voltages too high for standard CMOS, hindering its integration inside processors. Worse, forming the filaments is a noisy and random process, not ideal for storing data. (Imagine a neural network\u2019s weights randomly drifting. Answers to the same question would change from one day to the next.) </p><p>Moreover, most filament-based RRAM cells\u2019 noisy nature means they must be isolated from their surrounding circuits, usually with a selector transistor, which makes <a href=\"https://spectrum.ieee.org/3d-cmos\" target=\"_self\">3D stacking</a> difficult.</p><p>Limitations like these mean that traditional RRAM isn\u2019t great for computing. In particular, Kuzum says, it\u2019s difficult to use filamentary RRAM for the sort of parallel<a href=\"https://spectrum.ieee.org/matrix-multiplication-deepmind\" target=\"_self\"> matrix operations</a> that are crucial for today\u2019s neural networks.</p><p>So, the UCSD researchers decided to dispense with the filaments entirely. Instead they developed devices that switch an entire layer from high to low resistance and back again. This format, called bulk RRAM, can do away with both the annoying high-voltage filament-forming step and the geometry-limiting selector transistor.</p><h2>3D Memory for Machine Learning</h2><p>The UCSD group wasn\u2019t the first to build bulk RRAM devices, but it made breakthroughs both in shrinking them and forming 3D circuits with them. Kuzum and her colleagues shrank RRAM into the nanoscale; their device was just 40 nanometers across. They also managed to stack bulk RRAM into as many as eight layers.</p><p>With a single pulse of voltage, <span>each cell in </span>an eight-layer stack can take any of 64 resistance values, a number that\u2019s very difficult to achieve with traditional filamentous RRAM. And whereas the resistance of most filament-based cells are limited to kiloohms, the UCSD stack is in the megaohm range, which Kuzum says is better for parallel operations.</p><p>\u201cWe can actually tune it to anywhere we want, but we think that from an integration and system-level simulations perspective, megaohm is the desirable range,\u201d Kuzum says.</p><p>These two benefits\u2013a greater number of resistance levels and a higher resistance\u2013could allow this bulk RRAM stack to perform more complex operations than traditional RRAM\u2019s can manage. </p><p>Kuzum and colleagues assembled multiple eight-layer stacks into a 1-kilobyte array that required no selectors. Then, they tested the array with a continual learning algorithm: making the chip classify data from wearable sensors while constantly adding new data. For example, data read from a waist-mounted smartphone might be used to determine if its wearer was sitting, walking, climbing stairs, or taking another action. Tests showed an accuracy of 90 percent, which the researchers say is comparable to the performance of a digitally implemented neural network.</p><p>This test exemplifies what Kuzum thinks can especially benefit from bulk RRAM: neural network models on edge devices, which may need to learn from their environment without accessing the cloud. </p><p>\u201cWe are doing a lot of characterization and material optimization to design a device specifically engineered for AI applications,\u201d Kuzum says. </p><p>The ability to integrate RRAM into an array like this is a significant advance, says <a href=\"https://mse.umd.edu/clark/faculty/980/A-Alec-Talin\" target=\"_blank\">Albert Talin</a>, materials scientist at Sandia National Laboratories in Livermore, California, and a bulk RRAM researcher who wasn\u2019t involved in the UCSD group\u2019s work. \u201cI think that any step in terms of integration is very useful,\u201d he says.</p><p>But Talin highlights a potential obstacle: the ability to retain data for an extended period of time. While the UCSD group showed their RRAM could retain data at room temperature for several years (on par with flash memory), Talin says that its retention at the higher temperatures where computers actually operate is less certain. \u201cThat\u2019s one of the major challenges of this technology,\u201d he says, especially when it comes to edge applications.</p><p>If engineers can prove the technology, then all types of models may benefit. This memory wall has only grown higher this decade, as traditional memory hasn\u2019t been able to keep up with the ballooning demands of large models. Anything that allows models to operate on the memory itself could be a welcome shortcut. </p>", "url": "https://spectrum.ieee.org/ai-and-memory-wall", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/scanning-electron-microscope-image-of-the-top-of-a-three-dimensional-bulk-resistive-ram.jpg?id=63929015&amp;width=1200&amp;height=800&amp;coordinates=4%2C0%2C5%2C0\" /><br /><br /><p><span>The hunt is on for anything that can surmount AI\u2019s </span><a h"]}
{"id": "source:rss:5597240900", "title": "Low-Vision Programmers Can Now Design 3D Models Independently", "summary": "<img src=\"https://spectrum.ieee.org/media-library/a-college-student-programming-a-three-dimensional-model-on-a-laptop.jpg?id=63136292&amp;width=1200&amp;height=800&amp;coordinates=0%2C208%2C0%2C209\" /><br /><br /><p>Most 3D design software requires visual dragging and rotating\u2014posing a challenge for blind and low-vision users. As a result, a range of hardware design, robotics, coding, and engineering work is <span>inaccessible to interested programmers. A visually-impaired programmer might write great code. But because of the lack of accessible <a href=\"https://spectrum.ieee.org/comsol-simulation-apps\" target=\"_blank\">modeling software</a>, the coder can\u2019t model, design, and verify physical and virtual components of their system. </span></p><p>However, new 3D modeling tools are beginning to change this equation. A new prototype program called <a href=\"https://arxiv.org/abs/2508.03852\" target=\"_blank\">A11yShape</a> aims to close the gap. There are already code-based tools that let users describe 3D models in text, such as the popular <a href=\"https://openscad.org/\" target=\"_blank\">OpenSCAD software</a>. Other recent <a href=\"https://github.com/WebPAI/DesignBench\" target=\"_blank\">large-language-model tools</a> generate <a href=\"https://arxiv.org/html/2410.05340v1\" target=\"_blank\">3D code from natural-language prompts</a>. But even with these, blind and low-vision programmers still depend on sighted feedback to bridge the gap between their code and its visual output. </p><p>Blind and low-vision programmers previously had to rely on a sighted person to visually check every update of a model to describe what changed. But with A11yShape, blind and low-vision programmers can independently create, inspect, and refine 3D models without relying on sighted peers.</p><p>A11yShape does this by generating accessible model descriptions, organizing the model into a semantic hierarchy, and ensuring every step works with screen readers<span>. </span></p><p>The project began when <a href=\"https://www.lianghe.me/\" target=\"_blank\"><span>Liang He</span></a>, assistant professor of computer science at the University of Texas at Dallas, spoke with his low-vision classmate who was studying 3D modeling. He saw an opportunity to turn his classmate\u2019s coding strategies, learned in <a href=\"https://create.uw.edu/initiatives/physical-computing/\" target=\"_blank\"><span>a 3D modeling for blind programmers course</span></a> at the University of Washington, into a streamlined tool. </p><p>\u201cI want to design something useful and practical for the group,\u201d he says. \u201cNot just something I created from my imagination and applied to the group.\u201d </p><h3>Re-imagining Assistive 3D Design With OpenSCAD</h3><p>A11yShape assumes the user is running OpenSCAD, the script-based 3D modeling editor. <span>The program adds OpenSCAD features to connect each component of modeling across three application UI panels. </span></p><p>OpenSCAD allows users to create models entirely through typing, eliminating the need for clicking and dragging. Other common graphics-based user interfaces are difficult for blind programmers to navigate. </p><p>A11yshape introduces an AI Assistance Panel, where users can submit real-time queries to <a href=\"https://spectrum.ieee.org/chatgpt-for-coding\" target=\"_blank\">ChatGPT</a>-4o to validate design decisions and debug existing OpenSCAD scripts. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"AllyShape's 3-D modeling web interface, featuring a code editor panel with programming capabilities, an AI assistance panel providing contextual feedback, and a model panel displaying hierarchical structure and rendering of the resulting model.\" class=\"rm-shortcode\" id=\"c4ecb\" src=\"https://spectrum.ieee.org/media-library/allyshape-s-3-d-modeling-web-interface-featuring-a-code-editor-panel-with-programming-capabilities-an-ai-assistance-panel-prov.jpg?id=63138638&amp;width=980\" /> <small class=\"image-media media-caption\">A11yShape\u2019s three panels synchronize code, AI descriptions, and model structure so blind programmers can discover how code changes affect designs independently.</small><small class=\"image-media media-photo-credit\"><a href=\"https://arxiv.org/pdf/2508.03852\" target=\"_blank\">Anhong Guo, Liang He, et al.</a></small></p><p><span>If a user selects a piece of code or a model component, A11yShape highlights the matching part across all three panels and updates the description, so blind and low-vision users always know what they\u2019re working on.</span></p><h3>User Feedback Improved Accessible Interface</h3><p>The research team recruited 4 participants with a range of visual impairments and programming backgrounds. The team asked the participants to design models using A11yShape and observed their workflows.</p><p>One participant, who had never modeled before, said the tool \u201cprovided [the blind and low-vision community] with a new perspective on 3D modeling, demonstrating that we can indeed create relatively simple structures.\u201d</p><p>Participants also reported that long text descriptions still make it hard to grasp complex shapes, and several said that without eventually touching a physical model or using a tactile display, it was difficult to fully \u201csee\u201d the design in their mind.</p><p>To evaluate the accuracy of the AI-generated descriptions, the research team recruited 15 sighted participants. \u201cOn a 1\u20135 scale, the descriptions earned average scores between about 4.1 and 5 for geometric accuracy, clarity, and avoiding hallucinations, suggesting the AI is reliable enough for everyday use.\u201d</p><p><br /></p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"A failed all-at-once attempt to construct a 3-D helicopter shows incorrect shapes and placement of elements. In contrast, when the user journey allows for completion of each individual element before moving forward, results significantly improve.\" class=\"rm-shortcode\" id=\"528e8\" src=\"https://spectrum.ieee.org/media-library/a-failed-all-at-once-attempt-to-construct-a-3-d-helicopter-shows-incorrect-shapes-and-placement-of-elements-in-contrast-when-t.jpg?id=63138939&amp;width=980\" /> <small class=\"image-media media-caption\">A new assistive program for blind and low-vision programmers, A11yShape, assists visually disabled programmers in verifying the design of their models.</small><small class=\"image-media media-photo-credit\">Source: <a href=\"https://arxiv.org/pdf/2508.03852\" target=\"_blank\">Anhong Guo, Liang He, et al.</a></small></p><p>The feedback will help to inform future iterations\u2014which He says could integrate tactile displays, real-time 3D printing, and more concise AI-generated audio descriptions. </p><p>Beyond its applications in the professional computer programming community, He noted that A11yShape also lowers the barrier to entry for blind and low-vision computer programming <span>learners.</span></p><p><span>\u201cPeople like being able to express themselves in creative ways. . . using technology such as 3D printing to make things for utility or entertainment,\u201d says <a href=\"https://engineering.unt.edu/people/stephanie-ludi.html\" target=\"_blank\">Stephanie Ludi,</a> director of DiscoverABILITY Lab and professor of the department of computer science and engineering at the <a href=\"https://engineering.unt.edu/cse/\" target=\"_blank\">University of North Texas</a>. \u201cPersons who are blind and visually impaired share that interest</span><span>, with A11yShape serving as a model to support accessibility in the maker community.\u201d </span></p><p>The team presented A11yshape in October at the <a href=\"https://assets25.sigaccess.org/\" target=\"_blank\">ASSETS conference</a> in Denver.</p>", "url": "https://spectrum.ieee.org/3d-modeling-blind-programmers", "published_at": "Sat, 07 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/a-college-student-programming-a-three-dimensional-model-on-a-laptop.jpg?id=63136292&amp;width=1200&amp;height=800&amp;coordinates=0%2C208%2C0%2C209\" /><br /><br /><p>Most 3D design software requires visual dragging and rotating\u2014posing a challenge for"]}
{"id": "source:rss:4070037367", "title": "IEEE Online Mini-MBA Aims to Fill Leadership Skills Gaps in AI", "summary": "<img src=\"https://spectrum.ieee.org/media-library/close-up-of-hands-typing-on-a-laptop-with-floating-graphics-representing-large-language-models-floating-above-the-keyboard.jpg?id=63843722&amp;width=1200&amp;height=800&amp;coordinates=156%2C0%2C156%2C0\" /><br /><br /><p>Boardroom priorities are shifting from financial metrics toward technical oversight. Although market share and operational efficiency remain business bedrocks, executives also must now manage the complexities of machine learning, the integrity of their data systems, and the risks of algorithmic bias.</p><p>The change represents more than just a tech update; it marks a fundamental redefinition of the skills required for business leadership.</p><p><a href=\"https://www.mckinsey.com/capabilities/operations/our-insights/bold-accelerators-how-operations-leaders-are-pulling-ahead-using-ai\" rel=\"noopener noreferrer\" target=\"_blank\">Research</a> from the <a href=\"https://www.mckinsey.com/mgi/about-us\" rel=\"noopener noreferrer\" target=\"_blank\">McKinsey Global Institute</a> on the economic impact of artificial intelligence shows that companies integrating it effectively have boosted profit margins by up to 15 percent. Yet the same study revealed a sobering reality: 87 percent of organizations acknowledge significant AI skill gaps in their leadership ranks.</p><p>That disconnect between AI\u2019s business potential and executive readiness has created a need for a new type of professional education.</p><h2>The leadership skills gap in the AI era</h2><p>Traditional business education, with its focus on finance, marketing, and operations, wasn\u2019t designed for an AI-driven economy. Today\u2019s leaders need to understand not just what AI can do but also how to evaluate investments in the technology, manage algorithmic risks, and lead teams through digital transformations.</p><p>The challenges extend beyond the executive suite. Middle managers, project leaders, and department heads across industries are discovering that <a href=\"https://spectrum.ieee.org/ai-developer-career-advice\" target=\"_self\">AI fluency has become essential for career advancement</a>. In 2020 the <a href=\"https://www.weforum.org/stories/2020/10/top-10-work-skills-of-tomorrow-how-long-it-takes-to-learn-them/#:~:text=50%25%20of%20all%20employees%20will,help%20us%20learn%20new%20skills.\" rel=\"noopener noreferrer\" target=\"_blank\">World Economic Forum</a> predicted that 50 percent of all employees would need reskilling by 2025, with <a href=\"https://spectrum.ieee.org/ai-effect-entry-level-jobs\" target=\"_self\">AI-related competencies topping the list of required skills</a>.</p><h2>IEEE | Rutgers Online Mini-MBA: Artificial Intelligence</h2><p>Recognizing the skills gap, IEEE partnered with the <a href=\"https://www.business.rutgers.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Rutgers Business School</a> to offer a comprehensive business education program designed for the new era of AI. The<a href=\"https://innovationatwork.ieee.org/professional-development/rutgers-online-mini-mba-artificial-intelligence/\" rel=\"noopener noreferrer\" target=\"_blank\"> IEEE | Rutgers Online Mini-MBA: Artificial Intelligence</a> program combines rigorous business strategy with deep AI literacy.</p><p>Rather than treating AI as a separate technical subject, the program incorporates it into each aspect of business strategy. Students learn to evaluate AI opportunities through financial modeling, assess algorithmic risks through governance frameworks, and use change-management principles to implement new technologies.</p><h2>A curriculum built for real-world impact</h2><p>The program\u2019s modular structure lets professionals focus on areas relevant to their immediate needs while building toward comprehensive AI business literacy. Each of the 10 modules includes practical exercises and case study analyses that participants can immediately apply in their organization.</p><p>The Introduction to AI module provides a comprehensive overview of the technology\u2019s capabilities, benefits, and challenges. Other technologies are covered as well, including how they can be applied across diverse business contexts, laying the groundwork for informed decision\u2011making and strategic adoption.</p><p class=\"pull-quote\">Rather than treating AI as a separate technical subject, the online mini-MBA program incorporates the technology throughout each aspect of business strategy.</p><p>Building on that foundation, the Data Analytics module highlights how AI projects differ from traditional programming, how to assess data readiness, and how to optimize data to improve accuracy and outcomes. The module can equip leaders to evaluate whether their organization is prepared to launch successful AI initiatives.</p><p>The Process Optimization module focuses on reimagining core organizational workflows using AI. Students learn how machine learning and automation are already transforming industries such as manufacturing, distribution, transportation, and health care. They also learn how to identify critical processes, create AI road maps, establish pilot programs, and prepare their organization for change.</p><h2>Industry-specific applications</h2><p>The core modules are designed for all participants, and the program highlights how AI is applied across industries. By analyzing case studies in fraud detection, medical diagnostics, and predictive maintenance, participants see underlying principles in action.</p><p>Participants gain a broader perspective on how AI can be adapted to different contexts so they can draw connections to the opportunities and challenges in their organization. The approach ensures everyone comes away with a strong foundation and the ability to apply learned lessons to their environment.</p><h2>Flexible learning for busy professionals</h2><p>With the understanding that senior professionals have demanding schedules, the mini-MBA program offers flexibility. The online format lets participants engage with content in their own time frame, while live virtual office hours with faculty provide opportunities for real-time interaction.</p><p>The program, which offers discounts to IEEE members and flexible payment options, qualifies for many tuition reimbursement programs.</p><p>Graduates report that implementing AI strategies developed during the program has helped drive tangible business results. This success often translates into career advancement, including promotions and expanded leadership roles. Furthermore, the curriculum empowers graduates to confidently vet AI vendor proposals, lead AI project teams, and navigate high-stakes investment decisions.</p><p>Beyond curriculum content, the mini MBA can create valuable professional networks among AI-forward business leaders. Participants collaborate on projects, share implementation experiences, and build relationships that extend beyond the program\u2019s 12 weeks.</p><h2>Specialized training from IEEE</h2><p>To complement the mini-MBA program, IEEE offers targeted courses addressing specific AI applications in critical industries. The <a href=\"https://iln.ieee.org/public/contentdetails.aspx?id=D02A42B64A834CC1A698ADC1ABAB9523\" target=\"_blank\">Artificial Intelligence and Machine Learning in Chip Design</a> course explores how the technology is revolutionizing semiconductor development. <a href=\"https://iln.ieee.org/public/contentdetails.aspx?id=706DBC956996482182A5232D95410F99\" rel=\"noopener noreferrer\" target=\"_blank\">Integrating Edge AI and Advanced Nanotechnology in Semiconductor Applications</a> delves into cutting-edge hardware implementations. The <a href=\"https://iln.ieee.org/public/contentdetails.aspx?id=4B2AD26097B84B0485D297CE627ECA1E\" rel=\"noopener noreferrer\" target=\"_blank\">Mastering AI Integration in Semiconductor Manufacturing</a> course examines how AI enhances production efficiency and quality control in one of the world\u2019s most complex manufacturing processes. <a href=\"https://iln.ieee.org/public/contentdetails.aspx?id=64D2FDC20BF947BB89045A26DAF3A191\" rel=\"noopener noreferrer\" target=\"_blank\">AI in Semiconductor Packaging</a> equips professionals to apply machine learning and neural networks to modernize semiconductor packaging reliability and performance.</p><p>The programs grant professional development credits including PDHs and CEUs, ensuring participants receive formal recognition for their educational investments. Digital badges provide shareable credentials that professionals can showcase across professional networks, demonstrating their AI competencies to current and prospective employers.</p><p>Learn more about <a href=\"https://ea.ieee.org/ea-programs\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Educational Activities</a>\u2019 corporate solutions and professional development programs at <a href=\"https://innovationatwork.ieee.org\" rel=\"noopener noreferrer\" target=\"_blank\">innovationatwork.ieee.org</a>.</p>", "url": "https://spectrum.ieee.org/ieee-online-mini-ai-mba", "published_at": "Fri, 06 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": ["governance"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/close-up-of-hands-typing-on-a-laptop-with-floating-graphics-representing-large-language-models-floating-above-the-keyboard.jpg?id=63843722&amp;width=1200&amp;height=800&amp;coordinates=156%2C0%2C156%2C0\" /><br /><br /><p>Boardroom priorities are shif"]}
{"id": "source:rss:7626935885", "title": "Video Friday: Autonomous Robots Learn By Doing in This Factory", "summary": "<img src=\"https://spectrum.ieee.org/media-library/robotic-arms-on-mobile-bases-sort-crates-on-a-conveyor-belt-in-a-warehouse.png?id=63907821&amp;width=1200&amp;height=800&amp;coordinates=54%2C0%2C55%2C0\" /><br /><br /><p><span>Video Friday is your weekly selection of awesome robotics videos, collected by your friends at </span><em>IEEE Spectrum</em><span> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please </span><a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a><span> for inclusion.</span></p><h5><a href=\"https://2026.ieee-icra.org/\">ICRA 2026</a>: 1\u20135 June 2026, VIENNA</h5><p>Enjoy today\u2019s videos!</p><div class=\"horizontal-rule\"></div><div><span style=\"display: none;\"> </span></div><blockquote class=\"rm-anchors\" id=\"qdwi4cn3oi0\"><em>To train the next generation of <a href=\"https://spectrum.ieee.org/toyota-to-invest-1-billion-in-ai-and-robotics-rd\" target=\"_blank\">autonomous robots</a>, scientists at Toyota Research Institute are working with Toyota Manufacturing to deploy them on the factory floor.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.linkedin.com/posts/toyota-research-institute_whats-next-for-tri-robotics-max-bajracharya-activity-7424198589196685313-4e92?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAM4nT0BW_DvaXaoyr7IuJL-to9SJ5MlYT4\">Toyota Research Institute</a> ]</p><p>Thanks, Erin!</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"sh0chr6usao\"><em>This is just one story (of many) about how we tried, failed, and learned how to improve our \u202a<a href=\"https://spectrum.ieee.org/in-the-air-with-ziplines-medical-delivery-drones\" target=\"_blank\">drone delivery</a> system.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>Okay, but like you didn\u2019t show the really cool bit...?</p><p>[ <a href=\"https://www.zipline.com/\">Zipline</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"y2dhzlpgdwy\"><em>We\u2019re introducing KinetIQ, an AI framework developed by Humanoid, for end-to-end orchestration of humanoid robot fleets. KinetIQ coordinates wheeled and bipedal robots within a single system, managing both fleet-level operations and individual robot behavior across multiple environments. The framework operates across four cognitive layers, from task allocation and workflow optimization to task execution based on Vision-Language-Action models and whole-body control taught by reinforcement learning, and is shown here running across our wheeled industrial robots and bipedal R&amp;D platform.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://thehumanoid.ai/\">Humanoid</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"bp7esfyyv4g\"><em>What if a robot gets damaged during operation? Can it still perform its mission without immediate repair? Inspired by the self-embodied resilience strategies of stick insects, we developed a decentralized adaptive resilient neural control system (DARCON). This system allows legged robots to autonomously adapt to limb loss, ensuring mission success despite mechanical failure. This innovative approach leads to a future of truly resilient, self-recovering robotics.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://advanced.onlinelibrary.wiley.com/doi/10.1002/aisy.202500270\">VISTEC</a> ]</p><p>Thanks, Poramate!</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"lo2gluku4c8\"><em>This animation shows Perseverance\u2019s point of view during a drive of 807 feet (246 meters) along the rim of Jezero Crater on 10 December 2025, the 1,709th Martian day, or sol, of the mission. Captured over 2 hours and 35 minutes, 53 navigation-camera (Navcam) image pairs were combined with rover data on orientation, wheel speed, and steering angle, as well as data from Perseverance\u2019s inertial measurement unit, and placed into a 3D virtual environment. The result is this reconstruction with virtual frames inserted about every 4 inches (0.1 meters) of drive progress.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://science.nasa.gov/mission/mars-2020-perseverance/\">NASA Jet Propulsion Lab</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"sx4wkuhap4e\"><em>\u221247.4 \u00b0C, 130,000 steps, 89.75\u00b0E, 47.21\u00b0N\u2026 On the extremely cold snowfields of Altay, the birthplace of human skiing, Unitree\u2019s humanoid robot G1 left behind a unique set of marks.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.unitree.com/\">Unitree</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"as_ouaft2he\"><em>Representing and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a vision language model (VLM) to infer semantic relationships. Notably, we introduce a task-reasoning module that combines large language models and a VLM to interpret the scene graph\u2019s semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://ntnu-arl.github.io/reasoning_graph/\">Norwegian University of Science & Technology, Autonomous Robots Lab</a> ]</p><p>Thanks, Kostas!</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"hmfgfp9xohq\"><em>We present HoLoArm, a quadrotor with compliant arms inspired by the nodus structure of dragonfly wings. This design provides natural flexibility and resilience while preserving flight stability, which is further reinforced by the integration of a reinforcement-learning control policy that enhances both recovery and hovering performance.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://ieeexplore.ieee.org/abstract/document/11361075\">HO Lab via IEEE Robotics and Automation Letters</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"giijs_mmmrg\"><em>In this work, we present SkyDreamer, to the best of our knowledge the first end-to-end vision-based autonomous-drone racing policy that maps directly from pixel-level representations to motor commands.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://arxiv.org/pdf/2510.14783\">MAVLab</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"gr867dgh5tk\"><em>This video showcases AI Worker, equipped with five-finger hands, performing dexterous object manipulation across diverse environments. Through teleoperation, the robot demonstrates precise, humanlike hand control in a variety of manipulation tasks.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://ai.robotis.com/hands/introduction_hands.html\">Robotis</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"phomadn-qze\"><em>Autonomous following, 45-degree slope climbing, and reliable payload transport in extreme winter conditions, built to support operations where environments push the limits.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.deeprobotics.cn/en\">DEEP Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"80qqrfmvir0\"><em>Living architectures, from plants to beehives, adapt continuously to their environments through self-organization. In this work, we introduce the concept of architectural swarms: systems that integrate swarm robotics into modular architectural fa\u00e7ades. The Swarm Garden exemplifies how architectural swarms can transform the built environment, enabling \u201cliving-like\u201d architecture for functional and creative applications.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.science.org/doi/10.1126/scirobotics.ady7233\">SSR Lab via Science Robotics</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"wxtmqieul0s\">Here are a couple of IROS 2025 keynotes, featuring Bram Vanderborght and Kyu-Jin Cho.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p><br /></p><p class=\"shortcode-media shortcode-media-youtube\"> <span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span> <small class=\"image-media media-caption\">- YouTube</small> <small class=\"image-media media-photo-credit\"> <a href=\"https://www.youtube.com/watch?v=j6fEnhU56aA\" target=\"_blank\">www.youtube.com</a> </small> </p><p>[ <a href=\"https://www.iros25.org/\">IROS 2025</a> ]</p><div class=\"horizontal-rule\"></div>", "url": "https://spectrum.ieee.org/autonomous-warehouse-robots", "published_at": "Fri, 06 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/robotic-arms-on-mobile-bases-sort-crates-on-a-conveyor-belt-in-a-warehouse.png?id=63907821&amp;width=1200&amp;height=800&amp;coordinates=54%2C0%2C55%2C0\" /><br /><br /><p><span>Video Friday is your weekly selection of awesome robotics videos, collect"]}
{"id": "source:rss:2155350165", "title": "\u201cQuantum Twins\u201d Simulate What Supercomputers Can\u2019t", "summary": "<img src=\"https://spectrum.ieee.org/media-library/three-dimensional-rendering-of-12-sided-polyhedrons-lined-up-in-long-rows-each-polyhedron-is-comprised-of-countless-small-spher.jpg?id=63831528&amp;width=1200&amp;height=800&amp;coordinates=0%2C78%2C0%2C79\" /><br /><br /><p>While quantum computers continue to <a href=\"https://spectrum.ieee.org/neutral-atom-quantum-computing\" target=\"_self\">slowly grind</a> toward usefulness, some are pursuing a different approach\u2014analog <a href=\"https://spectrum.ieee.org/quantum-simulation\" target=\"_self\">quantum simulation</a>. This path doesn\u2019t offer complete control of single bits of quantum information, known as qubits\u2014it is not a universal quantum computer. Instead, quantum simulators directly mimic complex, difficult-to-access things, like individual molecules, chemical reactions, or novel materials. What analog quantum simulation lacks in flexibility, it makes up for in feasibility: quantum simulators are ready now.</p><p>\u201cInstead of using qubits, as you would typically in a quantum computer, we just directly encode the problem into the geometry and structure of the array itself,\u201d says <a href=\"https://www.linkedin.com/in/sam-gorman-b53389243/?originalSubdomain=au\" rel=\"noopener noreferrer\" target=\"_blank\">Sam Gorman</a>, quantum systems engineering lead at Sydney-based startup <a href=\"https://www.sqc.com.au/\" rel=\"noopener noreferrer\" target=\"_blank\">Silicon Quantum Computing</a>.</p><p>Yesterday, Silicon Quantum Computing unveiled its Quantum Twins product, a silicon quantum simulator, which is now available to customers through direct contract. Simultaneously, the team demonstrated that their device, made up of 15,000 quantum dots, can simulate an often-studied transition of a material from an insulator to a metal, and all the states between. They <a href=\"https://www.nature.com/articles/s41586-025-10053-7\" rel=\"noopener noreferrer\" target=\"_blank\">published</a> their work this week in the journal <em><em>Nature</em></em>.</p><p>\u201cWe can do things now that we think nobody else in the world can do,\u201d Gorman says. </p><h2>The Powerful Process</h2><p>Though the product announcement came yesterday, the team at Silicon Quantum Computing established its Precision Atom Qubit Manufacturing process following the startup\u2019s establishment in 2017, building on the academic work that the company\u2019s founder, <a href=\"https://en.wikipedia.org/wiki/Michelle_Simmons\" rel=\"noopener noreferrer\" target=\"_blank\">Michelle Simmons</a>, led for over 25 years. The underlying technology is a manufacturing process for placing single phosphorus atoms in silicon with subnanometer precision.</p><p>\u201cWe have a 38-stage process,\u201d Simmons says, for patterning phosphorus atoms into silicon. The process starts with a silicon substrate, which gets coated with a layer of hydrogen. Then, by means of a scanning-tunneling microscope, individual hydrogen atoms are knocked off the surface, exposing the silicon underneath. The surface is then dosed with phosphine gas, which adsorbs to the surface only in places where the silicon is exposed. With the help of a low-temperature thermal anneal, the phosphorus atom is then incorporated into the silicon crystal. Then, layers of silicon are grown on top.</p><p>\u201cIt\u2019s done in ultrahigh vacuum. So it\u2019s a very pure, very clean system,\u201d Simmons says. \u201cIt\u2019s a fully monolithic chip that we make with that subnanometer precision. In 2014, we figured out how to make markers in the chip so that we can then come back and find where we put the atoms within the device to make contacts. Those contacts are then made at the same length scale as the atoms and dots.\u201d</p><p>Though the team is able to place single atoms of phosphorus, they use clusters of 10 to 50 such atoms to make up what\u2019s known as a register for these application-specific chips. These registers act like <a href=\"https://spectrum.ieee.org/what-the-heck-are-quantum-dots\" target=\"_blank\">quantum dots</a>, preserving quantum properties of the individual atoms. The registers are controlled by a gate voltage from contacts placed atop the chip, and interactions between registers can be tuned by precisely controlling the distances between them.</p><p>While the company is also <a href=\"https://www.nature.com/articles/s41565-024-01853-5\" rel=\"noopener noreferrer\" target=\"_blank\">pursuing</a> more traditional quantum computing using this technology, they realized they already had the capacity to do useful simulations in the analog domain by putting thousands of registers on a single chip and measuring global properties, without controlling individual qubits.</p><p>\u201cThe thing that\u2019s quite unique is we can do that very quickly,\u201d Simmons says. \u201cWe put 250,000 of these registers [on a chip] in 8 hours, and we can turn a chip design around in a week.\u201d</p><h2>What to Simulate</h2><p>Back in 2022, the team at Silicon Quantum Computing used a previous version of this same technology to <a href=\"https://www.nature.com/articles/s41586-022-04706-0\" rel=\"noopener noreferrer\" target=\"_blank\">simulate</a> a molecule of polyacetylene. The chemical is made up of carbon atoms with alternating single and double bonds, and, crucially, its conductivity changes drastically depending on whether the chain is cut on a single or double bond. In order to accurately simulate single and double carbon bonds, the team had to control the distances of their registers to subnanometer precision. By tuning the gate voltages of each quantum dot, the researchers reproduced the jump in conductivity.</p><p>Now, they\u2019ve demonstrated the quantum twin technology on a much larger problem\u2014the <a href=\"https://en.wikipedia.org/wiki/Mott_insulator\" rel=\"noopener noreferrer\" target=\"_blank\">metal-insulator transition</a> of a two-dimensional material. Where the polyacetylene molecule required 10 registers, the new model used 15,000. The metal-insulator model is important because, in most cases, it cannot be simulated on a classical computer. At the extremes\u2014in the fully metal or fully insulating phase\u2014the physics can be simplified and made accessible to classical computing. But in the murky intermediate regime, the full quantum complexity of each electron plays a role, and the problem is classically intractable. \u201cThat is the part which is challenging for classical computing. But we can actually put our system into this regime quite easily,\u201d Gorman says.</p><p>The metal-insulator model was a proof of concept. Now, Gorman says, the team can design a quantum twin for almost any two-dimensional problem.</p><p>\u201cNow that we\u2019ve demonstrated that the device is behaving as we predict, we\u2019re looking at high-impact issues or outstanding problems,\u201d says Gorman. The team plans to investigate things like unconventional superconductivity, the origins of magnetism, and materials interfaces such as those that occur in batteries. </p><p>Although the initial applications will most likely be in the scientific domain, Simmons is hopeful that Quantum Twins will eventually be useful for industrial applications such as drug discovery. \u201cIf you look at different drugs, they\u2019re actually very similar to polyacetylene. They\u2019re carbon chains, and they have functional groups. So, understanding how to map it [onto our simulator] is a unique challenge. But that\u2019s definitely an area we\u2019re going to focus on,\u201d she says. \u201cWe\u2019re excited at the potential possibilities.\u201d</p>", "url": "https://spectrum.ieee.org/quantum-twins", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/three-dimensional-rendering-of-12-sided-polyhedrons-lined-up-in-long-rows-each-polyhedron-is-comprised-of-countless-small-spher.jpg?id=63831528&amp;width=1200&amp;height=800&amp;coordinates=0%2C78%2C0%2C79\" /><br /><br /><p>While quantum computers co"]}
{"id": "source:rss:6721353841", "title": "Paying Tribute to Finite Element Field Computation Pioneer", "summary": "<img src=\"https://spectrum.ieee.org/media-library/smiling-portrait-of-mvk-chari-wearing-a-tweed-jacket-and-tie.jpg?id=63831506&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><a href=\"https://www.legacy.com/us/obituaries/name/madabushi-krishnama-chari-obituary?id=60210616\" rel=\"noopener noreferrer\" target=\"_blank\">MVK Chari</a>,<strong> </strong>a pioneer in finite element field computation, died on 3 December. The IEEE Life Fellow was 97.</p><p>Chari developed a finite element method (FEM) for analyzing nonlinear electromagnetic fields\u2014which is crucial for the design of electric machines. The technique is used to obtain approximate solutions to complex engineering and mathematical problems. It involves dividing a complicated object or system into smaller, more manageable parts, known as <em><em>finite elements</em></em>, according to <a href=\"https://www.fictiv.com/articles/understanding-the-finite-element-method#:~:text=The%20Finite%20Element%20Method%20(FEM,behavior%20of%20these%20individual%20elements.\" rel=\"noopener noreferrer\" target=\"_blank\">Fictiv</a>.</p><p>As an engineer and technical leader at <a href=\"https://www.ge.com/about-us\" rel=\"noopener noreferrer\" target=\"_blank\">General Electric</a> in Niskayuna, N.Y., Chari used the tool to analyze large turbogenerators for end region analysis, starting with 2D and expanding its use over time to quasi-2D and 3D.</p><p>During his 25 years at GE, he established a team that was developing finite element analysis (FEA) tools for a variety of applications across the company. They ranged from small motors to large <a href=\"https://spectrum.ieee.org/mri\" target=\"_self\">MRI magnets</a>.</p><p>Chari received the 1993 <a href=\"https://corporate-awards.ieee.org/award/ieee-nikola-tesla-award/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Nikola Tesla Award</a> for \u201cpioneering contributions to finite element computations of nonlinear electromagnetic fields for design and analysis of electric machinery.\u201d</p><h2>A career spanning industry and academia</h2><p>Chari attended <a href=\"https://www.imperial.ac.uk/\" rel=\"noopener noreferrer\" target=\"_blank\">Imperial College London</a> to pursue a master\u2019s degree in electrical engineering. There he met <a href=\"https://en.wikipedia.org/wiki/Peter_P._Silvester\" rel=\"noopener noreferrer\" target=\"_blank\">Peter P. Silvester</a>, a visiting professor of electrical engineering. Silvester, a professor at <a href=\"https://www.mcgill.ca/\" rel=\"noopener noreferrer\" target=\"_blank\">McGill University</a> in Montreal, was a pioneer in understanding numerical analysis of electromagnetic fields.</p><p>After Chari graduated in 1968, he joined Silvester at McGill as a doctoral student, applying FEM to solve electromagnetic field problems. Silvester applied the method to waveguides, while Chari applied it to saturated magnetic fields. </p><p>Chari joined GE in 1970 after earning his Ph.D. in electrical engineering. He climbed the leadership ladder and was a manager of the company\u2019s electromagnetics division when he left in 1995. He joined <a href=\"https://www.rpi.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Rensselaer Polytechnic Institute</a> in Troy, N.Y., as a visiting research and adjunct professor in its electrical, computer, and systems engineering department. Chari taught graduate and undergraduate classes in electric power engineering and <a href=\"https://spectrum.ieee.org/advice-leading-mentoring-greater-innovation\" target=\"_self\">mentored</a> many master\u2019s and doctoral students. His strength was nurturing young engineers. </p><p>He also conducted research on electric machines and transformers for the <a href=\"https://www.epri.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Electric Power Research Institute</a> and the U.S. <a href=\"https://www.energy.gov/\" rel=\"noopener noreferrer\" target=\"_blank\">Department of Energy</a>. </p><p> In 2008 Chari joined <a href=\"https://www.ndt.org/vendor.asp?ObjectID=21373\" rel=\"noopener noreferrer\" target=\"_blank\">Magsoft Corp.</a>, in Clifton Park, N.Y., and conducted advanced work on specialized software for the <a href=\"https://www.navy.mil/\" rel=\"noopener noreferrer\" target=\"_blank\">U.S. Navy</a> until his retirement in 2016.</p><h2>Remembering a friend</h2><p>Chari successfully nominated one of us (Hoole) to be elevated to IEEE Fellow at the age of 40. He helped launch Haran\u2019s career when Chari sent his r\u00e9sum\u00e9 to GE hiring managers for a position in its applied superconductivity lab.</p><p>Chari\u2019s commitment to people came from his family background. His father\u2014<a href=\"https://en.wikipedia.org/wiki/M._A._Ayyangar\" rel=\"noopener noreferrer\" target=\"_blank\">M.A. Ayyangar</a>\u2014was known throughout India as a freedom fighter, mathematician, and eventually the speaker of the Indian Parliament\u2019s lower house under <a href=\"https://en.wikipedia.org/wiki/Jawaharlal_Nehru\" rel=\"noopener noreferrer\" target=\"_blank\">Prime Minister Nehru</a>. Chari\u2019s wife, Padma, was a physician in New York.</p><p>From Chari\u2019s illustrious family, he was at the peak of South India (<a href=\"https://en.wikipedia.org/wiki/Tamils\" rel=\"noopener noreferrer\" target=\"_blank\">Tamil</a>) society.</p><p>Chari would fondly and cheerfully tell us the story behind his name. Around the time of his birth, it was common in Tamil society not to have formal names. He went by the informal \u201chouse name\u201d Kannah (a term of endearment for <a href=\"https://en.wikipedia.org/wiki/Krishna\" rel=\"noopener noreferrer\" target=\"_blank\">Krishna</a>). When it was time for Chari to start school, an auspicious uncle enrolled him. But Chari had no formal name, so the uncle took it upon himself to give him one. He asked Chari if he would like a long or short name, to which he said long. So the uncle named him Madabushi Venkadamachari.</p><p>When Chari moved to North America, he shortened his name to Madabushi V.K.</p><p>He could also laugh at himself.</p><p>A stellar scientist, he also was a role model, guide, and friend to many of us. We thank God for him.</p>", "url": "https://spectrum.ieee.org/tribute-finite-element-field-computation-pioneer", "published_at": "Wed, 04 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/smiling-portrait-of-mvk-chari-wearing-a-tweed-jacket-and-tie.jpg?id=63831506&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><a href=\"https://www.legacy.com/us/obituaries/name/madabushi-krishnama-chari-obituary?id=6021"]}
{"id": "source:rss:3213259849", "title": "Milan-Cortina Winter Olympics Debut Next-Generation Sports Smarts", "summary": "<img src=\"https://spectrum.ieee.org/media-library/silhouettes-of-a-twirling-figure-skater-and-a-ski-jumper-against-a-dark-background.jpg?id=63783716&amp;width=1200&amp;height=800&amp;coordinates=62%2C0%2C63%2C0\" /><br /><br /><p>From 6\u201322 February, the 2026 <a href=\"https://www.olympics.com/en/milano-cortina-2026\" target=\"_blank\">Winter Olympics in Milan-Cortina d\u2019Ampezzo</a>, Italy, will feature not just the world\u2019s top winter athletes but also some of the most advanced sports technologies today. At the <a href=\"https://www.olympics.com/en/olympic-games/cortina-d-ampezzo-1956\" target=\"_blank\">first Cortina Olympics</a>, in 1956, the Swiss company <a href=\"https://en.wikipedia.org/wiki/Omega_SA\" target=\"_blank\">Omega</a>\u2014based in <a href=\"https://en.wikipedia.org/wiki/Biel/Bienne\" target=\"_blank\">Biel/Bienne</a>\u2014introduced electronic ski starting gates and launched the first automated timing tech of its kind.</p><p><span>At this year\u2019s Olympics, <a href=\"https://en.wikipedia.org/wiki/The_Swatch_Group#Sport_and_event_timing\" target=\"_blank\">Swiss Timing</a>,</span><span> sister company to Omega under the parent company <a href=\"https://www.swatchgroup.com/en\" target=\"_blank\">Swatch Group</a>, unveils a new generation of <a href=\"https://spectrum.ieee.org/tag/motion-capture\" target=\"_self\"><span><span>motion-analysis</span></span></a> and <a href=\"https://spectrum.ieee.org/tag/computer-vision\" target=\"_self\"><span><span>computer-vision</span></span></a> technology. The new technologies on offer include photo-finish cameras that capture up to 40,000 images per second. </span></p><p>\u201cWe work very closely with athletes,\u201d says <a href=\"https://www.swisstiming.com/\" target=\"_blank\"><span><span>Swiss Timing</span></span></a> CEO <a href=\"https://www.linkedin.com/in/alain-zobrist-2b3a36a/?originalSubdomain=ch\" target=\"_blank\"><span>Alain Zobrist</span></a>, who has overseen Olympic timekeeping since the <a href=\"https://www.olympics.com/ioc/legacy-torino-2006\" target=\"_blank\"><span><span>winter games of 2006 in Torino</span></span></a>. \u201cThey are the primary customers of our technology and services, and they need to understand how our systems work in order to trust them.\u201d</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Live data capture of a figure skater's performance, with a 3D rendering of the athlete, jump heights and more.\" class=\"rm-shortcode\" id=\"80fab\" src=\"https://spectrum.ieee.org/media-library/live-data-capture-of-a-figure-skater-s-performance-with-a-3d-rendering-of-the-athlete-jump-heights-and-more.jpg?id=63784021&amp;width=980\" /> <small class=\"image-media media-caption\">Using high-resolution cameras and AI algorithms tuned to skaters\u2019 routines, Milan-Cortina Olympic officials expect new figure-skating tech to be a key highlight of the games.  </small><small class=\"image-media media-photo-credit\">Omega</small></p><h3>Figure-Skating Tech Completes the Rotation</h3><p><span><a href=\"https://www.olympics.com/en/milano-cortina-2026/sports/figure-skating\" target=\"_blank\">Figure skating</a></span>, the Winter Olympics\u2019 biggest TV draw, is receiving a substantial upgrade at Milano Cortina 2026.</p><p>Fourteen <a href=\"https://en.wikipedia.org/wiki/8K_resolution\" target=\"_blank\"><span>8K-resolution cameras</span></a> positioned around the rink will capture every skater\u2019s movement. <span>\u201cWe use proprietary software to interpret the images and visualize athlete movement in a 3D model,\u201d says Zobrist. \u201cAI processes the data so we can track trajectory, position, and movement across all three axes\u2014x, y, and z.\u201d</span></p><p><span>The system measures jump heights, air times, and landing speeds in real time, producing heat maps and graphic overlays that break down each program\u2014all instantaneously. \u201cThe time it takes for us to measure the data, until we show a matrix on TV with a graphic, this whole chain needs to take less than 1/10 of a second,\u201d Zobrist says.</span></p><h3></h3><br /><div class=\"rblad-ieee_in_content\"></div><p>A range of different AI models helps the broadcasters and commentators process each skater\u2019s every move on the ice.</p><p><span>\u201cThere is an AI that helps our computer-vision system do pose estimation,\u201d he says. \u201cSo we have a camera that is filming what is happening, and an AI that helps the camera understand what it\u2019s looking at. And then there is a second type of AI, which is more similar to a large language model that makes sense of the data that we collect.\u201d</span></p><p>Among the features that Swiss Timing\u2019s new systems provide is blade-angle detection, which gives judges precise technical data to augment their technical and aesthetic decisions. Zobrist says future versions will also determine whether a given rotation is complete, so that \u201cif the rotation is 355 degrees, there is going to be a deduction,\u201d he says.</p><p>This builds on technology Omega unveiled at the <a href=\"https://en.wikipedia.org/wiki/2024_Summer_Olympics\" target=\"_blank\"><span>2024 Paris Olympics</span></a> for diving, where cameras measured distances between a diver\u2019s head and the board to help judges assess points and penalties to be awarded.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Three dimensional rendering of a ski jumper preparing for dismount on a tall slope.\" class=\"rm-shortcode\" id=\"6fe22\" src=\"https://spectrum.ieee.org/media-library/three-dimensional-rendering-of-a-ski-jumper-preparing-for-dismount-on-a-tall-slope.jpg?id=63783856&amp;width=980\" /> <small class=\"image-media media-caption\">At the 2026 Winter Olympics, ski jumping will feature both camera-based and sensor-based technologies to make the aerial experience more immediate and real-time. </small><small class=\"image-media media-photo-credit\">Omega</small></p><h3>Ski-Jumping Tech Finds Make-or-Break Moments</h3><p>Unlike figure skating\u2019s camera-based approach, <a href=\"https://www.olympics.com/en/milano-cortina-2026/sports/ski-jumping\" target=\"_blank\"><span>ski jumping</span></a> also relies on physical <a href=\"https://spectrum.ieee.org/search/?q=camera&amp;topic=sensors&amp;order=newest\" target=\"_self\"><span>sensors</span></a>.</p><p>\u201cIn ski jumping, we use a small, lightweight sensor attached to each ski, one sensor per ski, not on the athlete\u2019s body,\u201d Zobrist says. The sensors are lightweight and broadcast data on a skier\u2019s speed, acceleration, and positioning in the air. The technology also correlates performance data with wind conditions, revealing the influence of environmental factors <span>on each jump.</span></p><p>High-speed cameras also track each ski jumper. Then, a stroboscopic camera provides body position time-lapses throughout the jump.</p><p>\u201cThe first 20 to 30 meters after takeoff are crucial as athletes move into a V position and lean forward,\u201d Zobrist says. \u201cAnd both the timing and precision of this movement strongly influence performance.\u201d</p><p>The system reveals biomechanical characteristics in real time, he adds, showing how athletes position their bodies during every moment of the takeoff process. The most common mistake in flight position, over-rotation or under-rotation, can now be detailed and diagnosed with precision on every jump.</p><h3>Bobsleigh: Pushing the Line on the Photo Finish</h3><p>This year\u2019s Olympics will also feature a \u201cvirtual photo finish,\u201d providing comparison images of when different sleds cross the finish line over previous runs.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" style=\"float: left;\"> <img alt=\"Red Omega camera with large lens, under a sleek hood, set against a black background.\" class=\"rm-shortcode\" id=\"816ed\" src=\"https://spectrum.ieee.org/media-library/red-omega-camera-with-large-lens-under-a-sleek-hood-set-against-a-black-background.jpg?id=63784093&amp;width=980\" /> <small class=\"image-media media-caption\">Omega\u2019s cameras will provide virtual photo finishes at the 2026 Winter Olympics. </small><small class=\"image-media media-photo-credit\">Omega</small></p><p>\u201cWe virtually build a photo finish that shows different sleds from different runs on a single visual reference,\u201d says Zobrist.</p><p>After each run, composite images show the margins separating performances. However, more tried-and-true technology still generates official results. A Swiss Timing score, he says, still comes courtesy of <a href=\"https://spectrum.ieee.org/a-century-ago-the-optophone-allowed-blind-people-to-hear-the-printed-word\" target=\"_blank\">photoelectric cells</a>, devices that emit light beams across the finish line and stop the clock when broken. The company offers its virtual photo finish, by contrast, as a visualization tool for spectators and commentators.</p><p>In bobsleigh, as in every timed Winter Olympic event, the line between triumph and heartbreak is sometimes measured in milliseconds or even shorter time intervals. Such precision will, Zobrist says, stem from <a href=\"https://swisswatches-magazine.com/omegas-timekeeping-lab/\" target=\"_blank\">Omega\u2019s Quantum Timer</a>.</p><p>\u201cWe can measure time to the millionth of a second, so six digits after the comma, with a deviation of about 23 nanoseconds over 24 hours,\u201d Zobrist explained. \u201cThese devices are constantly calibrated and used across all timed sports.\u201d</p>", "url": "https://spectrum.ieee.org/winter-olympics-2026-tech", "published_at": "Wed, 04 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/silhouettes-of-a-twirling-figure-skater-and-a-ski-jumper-against-a-dark-background.jpg?id=63783716&amp;width=1200&amp;height=800&amp;coordinates=62%2C0%2C63%2C0\" /><br /><br /><p>From 6\u201322 February, the 2026 <a href=\"https://www.olympics.com/en/milan"]}
{"id": "source:rss:2393253176", "title": "Breaking Boundaries in Wireless Communication", "summary": "<img src=\"https://spectrum.ieee.org/media-library/blue-remcom-text-with-orange-circle-and-arc-design-above-the-letter-o.png?id=63752871&amp;width=980\" /><br /><br /><p>This paper discusses how RF propagation simulations empower engineers to test numerous real-world use cases in far less time, and at lower costs, than in situ testing alone. Learn how simulations provide a powerful visual aid and offer valuable insights to improve the performance and design of body-worn wireless devices.</p><p><span><a href=\"https://content.knowledgehub.wiley.com/breaking-boundaries-in-wireless-communication-simulating-animated-on-body-rf-propagation/\" target=\"_blank\">Download this free whitepaper now!</a></span></p>", "url": "https://content.knowledgehub.wiley.com/breaking-boundaries-in-wireless-communication-simulating-animated-on-body-rf-propagation/", "published_at": "Tue, 03 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/blue-remcom-text-with-orange-circle-and-arc-design-above-the-letter-o.png?id=63752871&amp;width=980\" /><br /><br /><p>This paper discusses how RF propagation simulations empower engineers to test numerous real-world use cases in far less time, and at"]}
{"id": "source:rss:1772252613", "title": "AI Hunts for the Next Big Thing in Physics", "summary": "<img src=\"https://spectrum.ieee.org/media-library/circular-and-spiral-tracks-are-shown-as-light-blue-lines-against-a-darker-blue-background.jpg?id=63686429&amp;width=1200&amp;height=800&amp;coordinates=62%2C0%2C63%2C0\" /><br /><br /><p><span><strong>In 1930, a young physicist</strong> named Carl D. Anderson was tasked by his mentor with measuring the energies of cosmic rays\u2014particles arriving at high speed from outer space. Anderson built an improved version of a cloud chamber, a device that visually records the trajectories of particles. In 1932, he saw evidence that confusingly combined the properties of protons and electrons. \u201cA situation began to develop that had its awkward aspects,\u201d he wrote many years after winning a Nobel Prize at the age of 31. Anderson had accidentally discovered antimatter.</span></p><p><span>Four years after his first discovery, he codiscovered another elementary particle, the muon. This one prompted one physicist to ask, \u201cWho ordered that?\u201d</span></p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" style=\"float: left;\"> <img alt=\"a photo shows a man in a suit sitting beside a large laboratory apparatus.\" class=\"rm-shortcode\" id=\"24d14\" src=\"https://spectrum.ieee.org/media-library/a-photo-shows-a-man-in-a-suit-sitting-beside-a-large-laboratory-apparatus.jpg?id=63687631&amp;width=980\" /> </p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" style=\"float: left;\"> <img alt=\" a circular black-and-white image shows curved particle tracks. \" class=\"rm-shortcode\" id=\"ee99e\" src=\"https://spectrum.ieee.org/media-library/a-circular-black-and-white-image-shows-curved-particle-tracks.jpg?id=63687608&amp;width=980\" /> <small class=\"image-media media-caption\">Carl Anderson [top] sits beside the magnet cloud chamber he used to discover the positron. His cloud-chamber photograph [bottom] from 1932 shows the curved track of a positron, the first known antimatter particle.  </small><small class=\"image-media media-photo-credit\">Caltech Archives & Special Collections </small></p><p><span>Over the decades since then, particle physicists have built increasingly sophisticated instruments of exploration. At the apex of these physics-finding machines sits the Large Hadron Collider, which in 2022 started its third operational run. This underground ring, 27 kilometers in circumference and straddling the border between France and Switzerland, was built to slam subatomic particles together at near light speed and test deep theories of the universe. Physicists from around the world turn to the LHC, hoping to find something new. They\u2019re not sure what, but they hope to find it.</span></p><p>It\u2019s the latest manifestation of a rich tradition. Throughout the history of science, new instruments have prompted hunts for the unexpected. Galileo Galilei built telescopes and found Jupiter\u2019s moons. Antonie van Leeuwenhoek built microscopes and noticed \u201canimalcules, very prettily a-moving.\u201d And still today, people peer through lenses and pore through data in search of patterns they hadn\u2019t hypothesized. Nature\u2019s secrets don\u2019t always come with spoilers, and so we gaze into the unknown, ready for anything.</p><h3></h3><br /><p>But novel, fundamental aspects of the universe are growing less forthcoming. In a sense, we\u2019ve plucked the lowest-hanging fruit. We know to a good approximation what the building blocks of matter are. The Standard Model of particle physics, which describes the currently known elementary particles, has been in place since the 1970s. Nature can still surprise us, but it typically requires larger or finer instruments, more detailed or expansive data, and faster or more flexible analysis tools.</p><p>Those analysis tools include a form of artificial intelligence (AI) called <a href=\"https://www.nature.com/articles/s42254-022-00455-1\" target=\"_blank\">machine learning</a>. Researchers train complex statistical models to find patterns in their data, patterns too subtle for human eyes to see, or too rare for a single human to encounter. At the LHC, which smashes together protons to create immense bursts of energy that decay into other short-lived particles of matter, a theorist might predict some new particle or interaction and describe what its signature would look like in the LHC data, often using a simulation to create synthetic data. Experimentalists would then collect petabytes of measurements and run a machine learning algorithm that compares them with the simulated data, looking for a match. Usually, they come up empty. But maybe new algorithms can peer into corners they haven\u2019t considered.</p><h2>A New Path for Particle Physics</h2><p>\u201cYou\u2019ve heard probably that there\u2019s a crisis in particle physics,\u201d says <a href=\"https://www.thphys.uni-heidelberg.de/~plehn/\" rel=\"noopener noreferrer\" target=\"_blank\">Tilman Plehn</a>, a theoretical physicist at Heidelberg University, in Germany. At the LHC and other high-energy physics facilities around the world, the experimental results have failed to yield insights on new physics. \u201cWe have a lot of unhappy theorists who thought that their model would have been discovered, and it wasn\u2019t,\u201d Plehn says.</p><h3></h3><br /><img alt=\"Person wearing a patterned shirt against a pale blue background.\" class=\"rm-shortcode\" id=\"91e5c\" src=\"https://spectrum.ieee.org/media-library/person-wearing-a-patterned-shirt-against-a-pale-blue-background.jpg?id=63688381&amp;width=980\" /><p class=\"pull-quote\"><span>\u201cWe have a lot of unhappy theorists who thought that their model would have been discovered, and it wasn\u2019t.\u201d</span></p><h3></h3><br /><p><a href=\"https://www.physik.uni-hamburg.de/en/iexp/gruppe-kasieczka/personen/kasieczka-gregor.html\" rel=\"noopener noreferrer\" target=\"_blank\">Gregor Kasieczka</a>, a physicist at the University of Hamburg, in Germany, recalls the field\u2019s enthusiasm when the LHC began running in 2008. Back then, he was a young graduate student and expected to see signs of supersymmetry, a theory predicting heavier versions of the known matter particles. The presumption was that \u201cwe turn on the LHC, and supersymmetry will jump in your face, and we\u2019ll discover it in the first year or so,\u201d he tells me. Eighteen years later, supersymmetry remains in the theoretical realm. \u201cI think this level of exuberant optimism has somewhat gone.\u201d</p><h3></h3><br /><p>The result, Plehn says, is that models for all kinds of things have fallen in the face of data. \u201cAnd I think we\u2019re going on a different path now.\u201d</p><p>That path involves a kind of machine learning called unsupervised learning. In unsupervised learning, you don\u2019t teach the AI to recognize your specific prediction\u2014signs of a particle with this mass and this charge. Instead, you might teach it to find anything out of the ordinary, anything interesting\u2014which could indicate brand new physics. It\u2019s the equivalent of looking with fresh eyes at a starry sky or a slide of pond scum. The problem is, how do you automate the search for something \u201cinteresting\u201d?</p><h2>Going Beyond the Standard Model</h2><p>The Standard Model leaves many questions unanswered. Why do matter particles have the masses they do? Why do neutrinos have mass at all? Where is the particle for transmitting gravity, to match those for the other forces? Why do we see more matter than antimatter? Are there extra dimensions? What is dark matter\u2014the invisible stuff that makes up most of the universe\u2019s matter and that we assume to exist because of its gravitational effect on galaxies? Answering any of these questions could open the door to new physics, or fundamental discoveries beyond the Standard Model.</p><h3></h3><br /><img alt=\"A long blue accelerator tube marked \\u201cLHC\\u201d runs through an underground tunnel.\" class=\"rm-shortcode\" id=\"1c8c9\" src=\"https://spectrum.ieee.org/media-library/a-long-blue-accelerator-tube-marked-u201clhc-u201d-runs-through-an-underground-tunnel.jpg?id=63688794&amp;width=980\" /><h3></h3><br /><p>\u201cPersonally, I\u2019m excited for portal models of dark sectors,\u201d Kasieczka says, as if reading from a Marvel film script. He asks me to imagine a mirror copy of the Standard Model out there somewhere, sharing only one \u201cportal\u201d particle with the Standard Model we know and love. It\u2019s as if this portal particle has a second secret family.</p><p>Kasieczka says that in the LHC\u2019s third run, scientists are splitting their efforts roughly evenly between measuring more precisely what they know to exist and looking for what they don\u2019t know to exist. In some cases, the former could enable the latter. The Standard Model predicts certain particle properties and the relationships between them. For example, it correctly predicted a property of the electron called the magnetic moment to about one part in a trillion. And precise measurements could turn up internal inconsistencies. \u201cThen theorists can say, \u2018Oh, if I introduce this new particle, it fixes this specific problem that you guys found. And this is how you look for this particle,\u2019\u201d Kasieczka says.</p><h3></h3><br /><img alt=\"A simplified chart of the Standard Model of physics shows matter particles (quarks and leptons), force-carrying particles, and the Higgs, which conveys mass.\" class=\"rm-shortcode\" id=\"937d6\" src=\"https://spectrum.ieee.org/media-library/a-simplified-chart-of-the-standard-model-of-physics-shows-matter-particles-quarks-and-leptons-force-carrying-particles-and-t.jpg?id=63689716&amp;width=980\" /><h3></h3><br /><p>What\u2019s more, the Standard Model has occasionally shown signs of cracks. Certain particles containing bottom quarks, for example, seem to decay into other particles in unexpected ratios. Plehn finds the bottom-quark incongruities intriguing. \u201cYear after year, I feel they should go away, and they don\u2019t. And nobody has a good explanation,\u201d he says. \u201cI wouldn\u2019t even know who I would shout at\u201d\u2014the theorists or the experimentalists\u2014\u201clike, \u2018Sort it out!\u2019\u201d</p><p>Exasperation isn\u2019t exactly the right word for Plehn\u2019s feelings, however. Physicists feel gratified when measurements reasonably agree with expectations, he says. \u201cBut I think deep down inside, we always hope that it looks unreasonable. Everybody always looks for the anomalous stuff. Everybody wants to see the standard explanation fail. First, it\u2019s fame\u201d\u2014a chance for a Nobel\u2014\u201cbut it\u2019s also an intellectual challenge, right? You get excited when things don\u2019t work in science.\u201d</p><h2>How Unsupervised AI Can Probe for New Physics</h2><p>Now imagine you had a machine to find all the times things don\u2019t work in science, to uncover all the anomalous stuff. That\u2019s how researchers are using unsupervised learning. One day over ice cream, Plehn and a friend who works at the software company SAP began discussing <a href=\"https://www.datacamp.com/tutorial/introduction-to-autoencoders\" target=\"_blank\">autoencoders</a>, one type of unsupervised learning algorithm. \u201cHe tells me that autoencoders are what they use in industry to see if a network was hacked,\u201d Plehn remembers. \u201cYou have, say, a hundred computers, and they have network traffic. If the network traffic [to one computer] changes all of a sudden, the computer has been hacked, and they take it offline.\u201d</p><h3></h3><br /><img alt=\"a person wearing a hard hat walks down an aisle.\" class=\"rm-shortcode\" id=\"c2b61\" src=\"https://spectrum.ieee.org/media-library/a-person-wearing-a-hard-hat-walks-down-an-aisle.jpg?id=63689029&amp;width=980\" /><h3></h3><br /><img alt=\"Photo show rows of electronic racks filled with cables and equipment inside a data-acquisition room.\" class=\"rm-shortcode\" id=\"1865f\" src=\"https://spectrum.ieee.org/media-library/photo-show-rows-of-electronic-racks-filled-with-cables-and-equipment-inside-a-data-acquisition-room.jpg?id=63689042&amp;width=980\" /><h3></h3><br /><p>Autoencoders are neural networks that start with an input\u2014it could be an image of a cat, or the record of a computer\u2019s network traffic\u2014and compress it, like making a tiny JPEG or MP3 file, and then decompress it. Engineers train them to compress and decompress data so that the output matches the input as closely as possible. Eventually a network becomes very good at that task. But if the data includes some items that are relatively rare\u2014such as white tigers, or hacked computers\u2019 traffic\u2014the network performs worse on these, because it has less practice with them. The difference between an input and its reconstruction therefore signals how anomalous that input is.</p><p>\u201cThis friend of mine said, \u2018You can use exactly our software, right?\u2019\u201d Plehn remembers. \u201c\u2018It\u2019s exactly the same question. Replace computers with particles.\u2019\u201d The two imagined feeding the autoencoder signatures of particles from a collider and asking: Are any of these particles not like the others? Plehn continues: \u201cAnd then we wrote up a joint grant proposal.\u201d</p><p>It\u2019s not a given that AI will find new physics. Even learning what counts as interesting is a daunting hurdle. Beginning in the 1800s, men in lab coats delegated data processing to women, whom they saw as diligent and detail oriented. Women annotated photos of stars, and they acted as \u201ccomputers.\u201d In the 1950s, women were trained to scan <a href=\"https://home.cern/news/news/experiments/seeing-invisible-event-displays-particle-physics\" target=\"_blank\">bubble chambers</a>, which recorded particle trajectories as lines of tiny bubbles in fluid. Physicists didn\u2019t explain to them the theory behind the events, only what to look for based on lists of rules. </p><p>But, as the Harvard science historian <a href=\"https://galison.scholars.harvard.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Peter Galison</a> writes in <em>Image and Logic: A Material Culture of Physics</em>, his influential account of how physicists\u2019 tools shape their discoveries, the task was \u201csubtle, difficult, and anything but routinized,\u201d requiring \u201cthree-dimensional visual intuition.\u201d He goes on: \u201cEven within a single experiment, judgment was required\u2014this was not an algorithmic activity, an assembly line procedure in which action could be specified fully by rules.\u201d</p><h3></h3><br /><img alt=\"Person in a suit with dark hair against a blue background.\" class=\"rm-shortcode\" id=\"b0ff8\" src=\"https://spectrum.ieee.org/media-library/person-in-a-suit-with-dark-hair-against-a-blue-background.jpg?id=63688530&amp;width=980\" /><p class=\"pull-quote\">\u201cWe are not looking for flying elephants but instead a few extra elephants than usual at the local watering hole.\u201d</p><h3></h3><br /><p>Over the last decade, though, one thing we\u2019ve learned is that AI systems can, in fact, perform tasks once thought to require human intuition, such as <a href=\"https://spectrum.ieee.org/monster-machine-defeats-prominent-pro-player\" target=\"_self\">mastering the ancient board game Go</a>. So researchers have been testing AI\u2019s intuition in physics. In 2019, Kasieczka and his collaborators announced the <a href=\"https://iopscience.iop.org/article/10.1088/1361-6633/ac36b9/meta\" target=\"_blank\">LHC Olympics 2020</a>, a contest in which participants submitted algorithms to find anomalous events in three sets of (simulated) LHC data. Some teams correctly found the anomalous signal in one dataset, but some falsely reported one in the second set, and they all missed it in the third. In 2020, a research collective called <a href=\"https://www.scipost.org/10.21468/SciPostPhys.12.1.043\" target=\"_blank\">Dark Machines</a> announced a similar competition, which drew more than 1,000 submissions of machine learning models. Decisions about how to score them led to different rankings, showing that there\u2019s no best way to explore the unknown.</p><p>Another way to test unsupervised learning is to play revisionist history. In 1995, a particle dubbed the top quark turned up at the Tevatron, a particle accelerator at the Fermi National Accelerator Laboratory (<a href=\"https://fnal.gov/\" target=\"_blank\">Fermilab</a>), in Illinois. But what if it actually hadn\u2019t? Researchers <a href=\"https://epjplus.epj.org/articles/epjplus/abs/2021/02/13360_2021_Article_1109/13360_2021_Article_1109.html\" rel=\"noopener noreferrer\" target=\"_blank\">applied</a> unsupervised learning to LHC data collected in 2012, pretending they knew almost nothing about the top quark. Sure enough, the AI revealed a set of anomalous events that were clustered together. Combined with a bit of human intuition, they pointed toward something like the top quark.</p><h3></h3><br /><img alt=\"Person with long hair wearing a sweater and light-colored top against a blue background.\" class=\"rm-shortcode\" id=\"a121d\" src=\"https://spectrum.ieee.org/media-library/person-with-long-hair-wearing-a-sweater-and-light-colored-top-against-a-blue-background.jpg?id=63690566&amp;width=980\" /><p class=\"pull-quote\">\u201cAn algorithm that can recognize any kind of disturbance would be a win.\u201d</p><h3></h3><br /><p>That exercise underlines the fact that unsupervised learning can\u2019t replace physicists just yet. \u201cIf your anomaly detector detects some kind of feature, how do you get from that statement to something like a physics interpretation?\u201d Kasieczka says. \u201cThe anomaly search is more a scouting-like strategy to get you to look into the right corner.\u201d <a href=\"https://www.physics.columbia.edu/content/georgia-karagiorgi\" target=\"_blank\">Georgia Karagiorgi</a>, a physicist at Columbia University, agrees. \u201cOnce you find something unexpected, you can\u2019t just call it quits and be like, \u2018Oh, I discovered something,\u2019\u201d she says. \u201cYou have to come up with a model and then test it.\u201d</p><p><a href=\"https://www.physics.wisc.edu/directory/cranmer-kyle/\" target=\"_blank\">Kyle Cranmer</a>, a physicist and data scientist at the University of Wisconsin-Madison who played a key role in the <a href=\"https://spectrum.ieee.org/a-tantalizing-hint-of-the-higgs\" target=\"_self\">discovery of the Higgs boson particle</a> in 2012, also says that human expertise can\u2019t be dismissed. \u201cThere\u2019s an infinite number of ways the data can look different from what you expected,\u201d he says, \u201cand most of them aren\u2019t interesting.\u201d Physicists might be able to recognize whether a deviation suggests some plausible new physical phenomenon, rather than just noise. \u201cBut how you try to codify that and make it explicit in some algorithm is much less straightforward,\u201d Cranmer says. Ideally, the guidelines would be general enough to exclude the unimaginable without eliminating the merely unimagined. \u201cThat\u2019s gonna be your Goldilocks situation.\u201d</p><p>In his 1987 book <em>How Experiments End</em>, Harvard\u2019s Galison writes that scientific instruments can \u201cimport assumptions built into the apparatus itself.\u201d He tells me about a 1973 experiment that looked for a phenomenon called neutral currents, signaled by an absence of a so-called heavy electron (later renamed the muon). One team initially used a trigger left over from previous experiments, which recorded events only if they produced those heavy electrons\u2014even though neutral currents, by definition, produce none. As a result, for some time the researchers missed the phenomenon and wrongly concluded that it didn\u2019t exist. Galison says that the physicists\u2019 design choice \u201callowed the discovery of [only] one thing, and it blinded the next generation of people to this new discovery. And that is always a risk when you\u2019re being selective.\u201d</p><h2>How AI Could Miss\u2014or Fake\u2014New Physics</h2><p>I ask Galison if by automating the search for interesting events, we\u2019re letting the AI take over the science. He rephrases the question: \u201cHave we handed over the keys to the car of science to the machines?\u201d One way to alleviate such concerns, he tells me, is to generate test data to see if an algorithm behaves as expected\u2014as in the LHC Olympics. \u201cBefore you take a camera out and photograph the Loch Ness Monster, you want to make sure that it can reproduce a wide variety of colors\u201d and patterns accurately, he says, so you can rely on it to capture whatever comes.</p><p>Galison, who is also a physicist, works on the <a href=\"https://www.welcometothejungle.com/en/articles/btc-black-hole-imaging-software-telescope\" rel=\"noopener noreferrer\" target=\"_blank\">Event Horizon Telescope</a>, which images black holes. For that project, he remembers putting up utterly unexpected test images like Frosty the Snowman so that scientists could probe the system\u2019s general ability to catch something new. \u201cThe danger is that you\u2019ve missed out on some crucial test,\u201d he says, \u201cand that the object you\u2019re going to be photographing is so different from your test patterns that you\u2019re unprepared.\u201d</p><p>The algorithms that physicists are using to seek new physics are certainly vulnerable to this danger. It helps that unsupervised learning is already being used in many applications. In industry, it\u2019s surfacing anomalous credit-card transactions and hacked networks. In science, it\u2019s identifying earthquake precursors, genome locations where proteins bind, and merging galaxies.</p><h3></h3><br /><img alt=\"A colorful visualization shows many particle tracks radiating outward from a collision point.\" class=\"rm-shortcode\" id=\"f6a0e\" src=\"https://spectrum.ieee.org/media-library/a-colorful-visualization-shows-many-particle-tracks-radiating-outward-from-a-collision-point.jpg?id=63688853&amp;width=980\" /><h3></h3><br /><p>But one difference with particle-physics data is that the anomalies may not be stand-alone objects or events. You\u2019re looking not just for a needle in a haystack; you\u2019re also looking for subtle irregularities in the haystack itself. Maybe a stack contains a few more short stems than you\u2019d expect. Or a pattern reveals itself only when you simultaneously look at the size, shape, color, and texture of stems. Such a pattern might suggest an unacknowledged substance in the soil. In accelerator data, subtle patterns might suggest a hidden force. As Kasieczka and his colleagues write in <a href=\"https://escholarship.org/content/qt56p5b8qm/qt56p5b8qm_noSplash_3309801b69925912167073f272fc7612.pdf\" target=\"_blank\">one paper</a>, \u201cWe are not looking for flying elephants, but instead a few extra elephants than usual at the local watering hole.\u201d</p><p>Even algorithms that weigh many factors can miss signals\u2014and they can also see spurious ones. The stakes of mistakenly claiming discovery are high. Going back to the hacking scenario, Plehn says, a company might ultimately determine that its network wasn\u2019t hacked; it was just a new employee. The algorithm\u2019s false positive causes little damage. \u201cWhereas if you stand there and get the Nobel Prize, and a year later people say, \u2018Well, it was a fluke,\u2019 people would make fun of you for the rest of your life,\u201d he says. In particle physics, he adds, you run the risk of spotting patterns purely by chance in big data, or as a result of malfunctioning equipment.</p><p>False alarms have happened before. In 1976, a group at Fermilab led by Leon Lederman, who later won a Nobel for other work, announced the discovery of a particle they tentatively called the Upsilon. The researchers calculated the probability of the signal\u2019s happening by chance as 1 in 50. After further data collection, though, they walked back the discovery, calling the pseudo-particle the Oops-Leon. (Today, particle physicists wait until the chance that a finding is a fluke drops below 1 in 3.5 million, the so-called five-sigma criterion.) And in 2011, researchers at the Oscillation Project with Emulsion-tRacking Apparatus (OPERA) experiment, in Italy, announced evidence for faster-than-light travel of neutrinos. Then, a few months later, they reported that the result was due to a faulty connection in their timing system.</p><p>Those cautionary tales linger in the minds of physicists. And yet, even while researchers are wary of false positives from AI, they also see it as a safeguard against them. So far, unsupervised learning has discovered no new physics, despite its use on data from multiple experiments at Fermilab and CERN. But anomaly detection may have prevented embarrassments like the one at OPERA. \u201cSo instead of telling you there\u2019s a new physics particle,\u201d Kasieczka says, \u201cit\u2019s telling you, this sensor is behaving weird today. You should restart it.\u201d</p><h2>Hardware for AI-Assisted Particle Physics</h2><p>Particle physicists are pushing the limits of not only their computing software but also their computing hardware. The challenge is unparalleled. The LHC produces 40 million particle collisions per second, each of which can produce a megabyte of data. That\u2019s much too much information to store, even if you could save it to disk that quickly. So the two largest detectors each use two-level data filtering. The first layer, called the Level-1 Trigger, or L1T, harvests 100,000 events per second, and the second layer, called the High-Level Trigger, or HLT, plucks 1,000 of those events to save for later analysis. So only one in 40,000 events is ever potentially seen by human eyes.</p><h3></h3><br /><img alt=\"Person with long blonde hair in a white shirt against a solid blue background.\" class=\"rm-shortcode\" id=\"747ca\" src=\"https://spectrum.ieee.org/media-library/person-with-long-blonde-hair-in-a-white-shirt-against-a-solid-blue-background.jpg?id=63691908&amp;width=980\" /><p class=\"pull-quote\"><span>\u201c</span>T<span>hat\u2019s</span> when I thought, we need something like [AlphaGo] in physics. We need a genius that can look at the world differently.\u201d </p><h3></h3><br /><p>HLTs use central processing units (CPUs) like the ones in your desktop computer, running complex machine learning algorithms that analyze collisions based on the number, type, energy, momentum, and angles of the new particles produced. L1Ts, as a first line of defense, must be fast. So the L1Ts rely on integrated circuits called field-programmable gate arrays (FPGAs), which users can reprogram for specialized calculations. </p><p>The trade-off is that the programming must be relatively simple. The FPGAs can\u2019t easily store and run fancy neural networks; instead they follow scripted rules about, say, what features of a particle collision make it important. In terms of complexity level, it\u2019s the instructions given to the women who scanned bubble chambers, not the women\u2019s brains.</p><p><a href=\"https://www.space.mit.edu/people/katya-govorkova/\" target=\"_blank\">Ekaterina (Katya) Govorkova</a>, a particle physicist at MIT, saw a path toward improving the LHC\u2019s filters, inspired by a board game. Around 2020, she was looking for new physics by comparing precise measurements at the LHC with predictions, using little or no machine learning. Then she watched a documentary about <a href=\"https://deepmind.google/research/alphago/\" rel=\"noopener noreferrer\" target=\"_blank\">AlphaGo</a>, the program that used machine learning to beat a human Go champion. \u201cFor me the moment of realization was when AlphaGo would use some absolutely new type of strategy that humans, who played this game for centuries, hadn\u2019t thought about before,\u201d she says. \u201cSo that\u2019s when I thought, we need something like that in physics. We need a genius that can look at the world differently.\u201d New physics may be something we\u2019d never imagine.</p><p>Govorkova and her collaborators found a way to compress autoencoders to put them on FPGAs, where they process an event every 80 nanoseconds (less than 10-millionth of a second). (Compression involved pruning some network connections and <a href=\"https://spectrum.ieee.org/1-bit-llm\" target=\"_self\">reducing the precision</a> of some calculations.) They <a href=\"https://www.nature.com/articles/s42256-022-00441-3\" rel=\"noopener noreferrer\" target=\"_blank\">published</a> their methods in <em>Nature Machine Intelligence </em>in 2022, and researchers are now using them during the LHC\u2019s third run. The new trigger tech is installed in one of the detectors around the LHC\u2019s giant ring, and it has found many anomalous events that would otherwise have gone unflagged.</p><p>Researchers are currently setting up analysis workflows to decipher why the events were deemed anomalous. <a href=\"https://www.linkedin.com/in/jennifer-ngadiuba-a2138b141/\" rel=\"noopener noreferrer\" target=\"_blank\">Jennifer Ngadiuba</a>, a particle physicist at Fermilab who is also one of the coordinators of the trigger system (and one of Govorkova\u2019s coauthors), says that one feature stands out already: Flagged events have lots of jets of new particles shooting out of the collisions. But the scientists still need to explore other factors, like the new particles\u2019 energies and their distributions in space. \u201cIt\u2019s a high-dimensional problem,\u201d she says.</p><p>Eventually they will share the data openly, allowing others to eyeball the results or to apply new unsupervised learning algorithms in the hunt for patterns. <a href=\"https://jduarte.physics.ucsd.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Javier Duarte</a>, a physicist at the University of California, San Diego, and also a coauthor on the 2022 paper, says, \u201cIt\u2019s kind of exciting to think about providing this to the community of particle physicists and saying, like, \u2018Shrug, we don\u2019t know what this is. You can take a look.\u2019\u201d Duarte and Ngadiuba note that high-energy physics has traditionally followed a top-down approach to discovery, testing data against well-defined theories. Adding in this new bottom-up search for the unexpected marks a new paradigm. \u201cAnd also a return of sorts to before the Standard Model was so well established,\u201d Duarte adds.</p><p>Yet it could be years before we know why AI marked those collisions as anomalous. What conclusions could they support? \u201cIn the worst case, it could be some detector noise that we didn\u2019t know about,\u201d which would still be useful information, Ngadiuba says. \u201cThe best scenario could be a new particle. And then a new particle implies a new force.\u201d</p><h3></h3><br /><img alt=\"Person with braided updo in checkered suit jacket and chambray shirt, light blue background.\" class=\"rm-shortcode\" id=\"27f44\" src=\"https://spectrum.ieee.org/media-library/person-with-braided-updo-in-checkered-suit-jacket-and-chambray-shirt-light-blue-background.jpg?id=63691071&amp;width=980\" /><p class=\"pull-quote\"><span>\u201cThe best scenario could be a new particle. And then a new particle implies a new force.\u201d</span></p><h3></h3><br /><p>Duarte says he expects their work with FPGAs to have wider applications. \u201cThe data rates and the constraints in high-energy physics are so extreme that people in industry aren\u2019t necessarily working on this,\u201d he says. \u201cIn self-driving cars, usually millisecond latencies are sufficient reaction times. But we\u2019re developing algorithms that need to respond in microseconds or less. We\u2019re at this technological frontier, and to see how much that can proliferate back to industry will be cool.\u201d</p><p>Plehn is also working to put neural networks on FPGAs for triggers, in collaboration with experimentalists, electrical engineers, and other theorists. Encoding the nuances of abstract theories into material hardware is a puzzle. \u201cIn this grant proposal, the person I talked to most is the electrical engineer,\u201d he says, \u201cbecause I have to ask the engineer, which of my algorithms fits on your bloody FPGA?\u201d</p><p>Hardware is hard, says <a href=\"https://kastner.ucsd.edu/ryan/\" target=\"_blank\">Ryan Kastner</a>, an electrical engineer and computer scientist at UC San Diego who works with Duarte on programming FPGAs. What allows the chips to run algorithms so quickly is their flexibility. Instead of programming them in an abstract coding language like Python, engineers configure the underlying circuitry. They map logic gates, route data paths, and synchronize operations by hand. That low-level control also makes the effort \u201cpainfully difficult,\u201d Kastner says. \u201cIt\u2019s kind of like you have a lot of rope, and it\u2019s very easy to hang yourself.\u201d</p><h2>Seeking New Physics Among the Neutrinos</h2><p><strong></strong>The next piece of new physics may not pop up at a particle accelerator. It may appear at a detector for <a href=\"https://www.energy.gov/science/doe-explainsneutrinos\" target=\"_blank\">neutrinos</a>, particles that are part of the Standard Model but remain deeply mysterious. Neutrinos are tiny, electrically neutral, and so light that no one has yet measured their mass. (The <a href=\"https://physicsworld.com/a/katrin-sets-tighter-limit-on-neutrino-mass/\" target=\"_blank\">latest attempt</a>, in April, set an upper limit of about a millionth the mass of an electron.) Of all known particles with mass, neutrinos are the universe\u2019s most abundant, but also among the most ghostly, rarely deigning to acknowledge the matter around them. Tens of trillions pass through your body every second.</p><p>If we listen very closely, though, we may just hear the secrets they have to tell. <a href=\"https://www.physics.columbia.edu/content/georgia-karagiorgi\" target=\"_blank\">Karagiorgi</a>, of Columbia, has chosen this path to discovery. Being a physicist is \u201ckind of like playing detective, but where you create your own mysteries,\u201d she tells me during my visit to Columbia\u2019s <a href=\"https://www.nevis.columbia.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Nevis Laboratories</a>, located on a large estate about 20 km north of Manhattan. Physics research began at the site after World War II; one hallway features papers going back to 1951.</p><h3></h3><br /><img alt=\"A person stands inside a room that has gold-colored grids covering the floor, walls, and ceiling.\" class=\"rm-shortcode\" id=\"cb76e\" src=\"https://spectrum.ieee.org/media-library/a-person-stands-inside-a-room-that-has-gold-colored-grids-covering-the-floor-walls-and-ceiling.jpg?id=63689639&amp;width=980\" /><h3></h3><br /><p>Karagiorgi is eagerly awaiting a massive neutrino detector that\u2019s currently under construction. Starting in 2028, Fermilab will send neutrinos west through 1,300 km of rock to South Dakota, where they\u2019ll occasionally make their existence known in the Deep Underground Neutrino Experiment (<a href=\"https://www.dunescience.org/\" target=\"_blank\">DUNE</a>). Why so far away? When neutrinos travel long distances, they have an odd habit of oscillating, transforming from one kind or \u201cflavor\u201d to another. Observing the oscillations of both the neutrinos and their mirror-image antiparticles, antineutrinos, could tell researchers something about the universe\u2019s matter-antimatter asymmetry\u2014which the Standard Model doesn\u2019t explain\u2014and thus, according to the Nevis website, \u201cwhy we exist.\u201d</p><p>\u201cDUNE is the thing that\u2019s been pushing me to develop these real-time AI methods,\u201d Karagiorgi says, \u201cfor sifting through the data very, very, very quickly and trying to look for rare signatures of interest within them.\u201d When neutrinos interact with the detector\u2019s 70,000 tonnes of liquid argon, they\u2019ll generate a shower of other particles, creating visual tracks that look like a photo of fireworks.</p><p><span>Even when not bombarding DUNE with neutrinos, researchers will keep collecting data in the off chance that it captures neutrinos from a distant supernova. \u201cThis is a massive detector spewing out 5 terabytes of data per second,\u201d Karagiorgi says, \u201cand it\u2019s going to run constantly for a decade.\u201d They will need unsupervised learning to notice signatures that no one was looking for, because there are \u201clots of different models of how supernova explosions happen, and for all we know, none of them could be the right model for neutrinos,\u201d she says. \u201cTo train your algorithm on such uncertain grounds is less than ideal. So an algorithm that can recognize any kind of disturbance would be a win.\u201d</span></p><p>Deciding in real time which 1 percent of 1 percent of data to keep will require FPGAs. Karagiorgi\u2019s team is preparing to use them for DUNE, and she walks me to a computer lab where they program the circuits. In the FPGA lab, we look at nondescript circuit boards sitting on a table. \u201cSo what we\u2019re proposing is a scheme where you can have something like a hundred of these boards for DUNE deep underground that receive the image data frame by frame,\u201d she says. This system could tell researchers whether a given frame resembled TV static, fireworks, or something in between.</p><p>Neutrino experiments, like many particle-physics studies, are very visual. When Karagiorgi was a postdoc, automated image processing at neutrino detectors was still in its infancy, so she and collaborators would often resort to visual scanning (bubble-chamber style) to measure particle tracks. She still asks undergrads to hand-scan as an educational exercise. \u201cI think it\u2019s wrong to just send them to write a machine learning algorithm. Unless you can actually visualize the data, you don\u2019t really gain a sense of what you\u2019re looking for,\u201d she says. \u201cI think it also helps with creativity to be able to visualize the different types of interactions that are happening, and see what\u2019s normal and what\u2019s not normal.\u201d</p><p>Back in Karagiorgi\u2019s office, a bulletin board displays images from <em><em>The Cognitive Art of Feynman Diagrams</em></em>, an exhibit for which the designer Edward Tufte created wire sculptures of the physicist Richard Feynman\u2019s schematics of particle interactions. \u201cIt\u2019s funny, you know,\u201d she says. \u201cThey look like they\u2019re just scribbles, right? But actually, they encode quantitatively predictive behavior in nature.\u201d Later, Karagiorgi and I spend a good 10 minutes discussing whether a computer or a human could find Waldo without knowing what Waldo looked like. We also touch on the 1964 Supreme Court case in which Justice Potter Stewart famously declined to define obscenity, saying \u201cI know it when I see it.\u201d I ask whether it seems weird to hand over to a machine the task of deciding what\u2019s visually interesting. \u201cThere are a lot of trust issues,\u201d she says with a laugh.</p><p>On the drive back to Manhattan, we discuss the history of scientific discovery. \u201cI think it\u2019s part of human nature to try to make sense of an orderly world around you,\u201d Karagiorgi says. \u201cAnd then you just automatically pick out the oddities. Some people obsess about the oddities more than others, and then try to understand them.\u201d</p><p>Reflecting on the Standard Model, she called it \u201cbeautiful and elegant,\u201d with \u201camazing predictive power.\u201d Yet she finds it both limited and limiting, blinding us to colors we don\u2019t yet see. \u201cSometimes it\u2019s both a blessing and a curse that we\u2019ve managed to develop such a successful theory.\u201d <span class=\"ieee-end-mark\"></span></p>", "url": "https://spectrum.ieee.org/particle-physics-ai", "published_at": "Tue, 03 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/circular-and-spiral-tracks-are-shown-as-light-blue-lines-against-a-darker-blue-background.jpg?id=63686429&amp;width=1200&amp;height=800&amp;coordinates=62%2C0%2C63%2C0\" /><br /><br /><p><span><strong>In 1930, a young physicist</strong> named Carl D. "]}
{"id": "source:rss:8569406888", "title": "IEEE Considers Safety Guidelines for Neurotech Consumer Products", "summary": "<img src=\"https://spectrum.ieee.org/media-library/ramses-alcaide-wearing-over-ear-headphones-while-concentrating-on-a-laptop-computer-screen.jpg?id=63707527&amp;width=1200&amp;height=800&amp;coordinates=156%2C0%2C156%2C0\" /><br /><br /><p>Nonmedical devices that read brainwaves, such as smart <a href=\"https://spectrum.ieee.org/muse-headband\" target=\"_self\">headbands</a>, <a href=\"https://www.neurable.com/about\" rel=\"noopener noreferrer\" target=\"_blank\">headphones</a>, and <a href=\"https://www.narbis.shop/collections/frontpage/products/narbis-system-1\" rel=\"noopener noreferrer\" target=\"_blank\">glasses</a>, are becoming more popular among consumers. The products claim to make users more productive, creative, and healthier. <a href=\"https://spectrum.ieee.org/\" target=\"_self\"><em><em>IEEE Spectrum</em></em></a> previewed several of these <a href=\"https://spectrum.ieee.org/ces-2026-preview?utm_source=homepage&amp;utm_medium=hero&amp;utm_campaign=hero-2026-01-05&amp;utm_content=hero1\" target=\"_self\">smart wearables</a> that were introduced at this year\u2019s <a href=\"https://www.ces.tech/\" rel=\"noopener noreferrer\" target=\"_blank\">Consumer Electronics Show</a> (CES) in Las Vegas.</p><p>Since the wearable, noninvasive neurotech products aren\u2019t medical devices, they are <a href=\"https://www.sciencedirect.com/science/chapter/bookseries/abs/pii/S2589295920300199\" rel=\"noopener noreferrer\" target=\"_blank\">not subject to the same forms of regulation</a>\u2014which can lead to gaps in their safety and <a href=\"https://spectrum.ieee.org/privacy-health-tech-seniors\" target=\"_self\">data privacy</a>, as well as their effect on users\u2019 brains.</p><p><a href=\"https://www.unesco.org/en\" rel=\"noopener noreferrer\" target=\"_blank\">UNESCO</a> in November adopted the first global <a href=\"https://www.unesco.org/en/articles/ethics-neurotechnology-unesco-adopts-first-global-standard-cutting-edge-technology\" rel=\"noopener noreferrer\" target=\"_blank\">ethical standard</a> for neurotechnologies, establishing guidelines to protect users\u2019 mental privacy, freedom of thought, and human rights. In 2019 the <a href=\"https://www.oecd.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Organisation for Economic Co-operation and Development</a> issued responsible-neurotechnology <a href=\"https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0457\" rel=\"noopener noreferrer\" target=\"_blank\">recommendations</a>. But there are no socio-technical standards for manufacturers to follow.</p><p>In response, the <a href=\"https://brain.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Brain technical community</a> is developing the IEEE P7700 standard: \u201c<a href=\"https://standards.ieee.org/ieee/7700/11038/\" rel=\"noopener noreferrer\" target=\"_blank\">Recommended Practice for the Responsible Design and Development of Neurotechnologies</a>.\u201d</p><p>The proposed standard is being designed to provide a uniform set of definitions and a methodology to assess the ethical and socio-technical considerations and practices regarding the design, development, and use of neurotechnologies including wearable neurodevices for the brain, says <a href=\"https://sites.psu.edu/neuroethicslab/\" rel=\"noopener noreferrer\" target=\"_blank\">Laura Y. Cabrera</a>, the standard\u2019s working group chair. Cabrera, an IEEE senior member, is an associate professor in the engineering science and mechanics department at <a href=\"https://www.psu.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Pennsylvania State University</a> in University Park. Her research focuses on the ethical and societal implications of neurotechnologies.</p><p>\u201cIEEE P7700 addresses the unique characteristics of the technology and its impact on individuals and society, in particular, as it moves from therapeutic users to a wide variety of consumers,\u201d she says.</p><p>The standard is sponsored by the <a href=\"https://technologyandsociety.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Society on Social Implications of Technology</a>.</p><h2>Concern over long-term effects</h2><p>The multilayered complexity of technologies that interface with the brain and nervous system presents considerations to those developing them, Cabrera says.</p><p>\u201cThere may be long-term consequences in our brains with these types of technologies,\u201d she says. \u201cMaybe if they were used for a short period of time, there might not be significant consequences. But what are the effects over time?\u201d</p><p>Patients using approved brain-stimulation technology, for example, are told of its risks and benefits, but the long-term effects of headbands to improve students\u2019 attention span aren\u2019t known.</p><p class=\"pull-quote\">\u201cIEEE P7700 addresses the unique characteristics of the technology and its impact on individuals and society, in particular, as it moves from therapeutic users to a wide variety of consumers.\u201d</p><p>IEEE P7700 will address potential risks to individuals and possible negative impacts on society, Cabrera says. That includes creating guardrails to prevent harm, she adds.</p><p>The cultural implications of using neurotechnologies that interface with the brain also need to be considered, she says, because people have different views.</p><p>\u201cThe brain is considered the seed of the self and the organ that orchestrates all our thoughts, behaviors, feelings, and emotions,\u201d she says. \u201cThe brain is really central to who we are.\u201d</p><h2>Developing an ethical framework</h2><p>For the past five years, the <a href=\"https://brain.ieee.org/\" target=\"_blank\">IEEE Brain community</a>\u2019s neuroethics committee has been developing a <a href=\"https://spectrum.ieee.org/ethical-guidelines-in-the-works-for-developers-of-brain-technologies\" target=\"_self\">framework</a> to evaluate the ethical, legal, social, and cultural issues that could emerge from use of the technology. The document covers nine types of applications, including those used for wellness.</p><p>Because more devices kept entering the market, IEEE Brain decided in 2023 that it was time to begin drafting a standard.</p><p>Members of its working group come from Argentina, China, Japan, Italy, Switzerland, and the United States. Participants include developers, engineers, ethicists, lawyers, and social science researchers.</p><p>The standard, Cabrera says, will be the first socio-technical standard aimed at fostering the ethical and responsible innovation of neurotechnology that meets societal and community values at an international level. P7700 will include a how-to guide, criteria for evaluating each suggested process, and case studies to help with the interpretation and practical use of the standard, she says.</p><p>\u201cOur applied ethical approach uses a responsible research and innovation method to enable developers, researchers, users, and regulators to anticipate and address ethical and sociocultural implications of neurotechnologies, mitigating negative unintended consequences while increasing community support and engagement with innovators,\u201d Cabrera says.</p><p>The working group is seeking additional participants to help refine the process, tools, and recommendations.</p><p>\u201cThere are a variety of people who can contribute their expertise,\u201d she says, \u201cincluding academics, data scientists, government program leaders, policymakers, lawyers, social scientists, and users.\u201d</p><p>Cabrera says she anticipates the standard will be published early next year.</p><p>You can register to <a href=\"https://development.standards.ieee.org/myproject-web/public/view.html#/interest/9521\" rel=\"noopener noreferrer\" target=\"_blank\">participate in the standard\u2019s development here</a>.</p>", "url": "https://spectrum.ieee.org/ieee-safety-guidelines-neurotech", "published_at": "Mon, 02 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/ramses-alcaide-wearing-over-ear-headphones-while-concentrating-on-a-laptop-computer-screen.jpg?id=63707527&amp;width=1200&amp;height=800&amp;coordinates=156%2C0%2C156%2C0\" /><br /><br /><p>Nonmedical devices that read brainwaves, such as smart <a hre"]}
{"id": "source:rss:4404467900", "title": "Don\u2019t Regulate AI Models. Regulate AI Use", "summary": "<img src=\"https://spectrum.ieee.org/media-library/silhouettes-looking-at-screens-sit-behind-a-building-shape-with-the-scales-of-justice-in-a-digital-grid-patterned-setting.jpg?id=63516186&amp;width=1200&amp;height=800&amp;coordinates=277%2C0%2C278%2C0\" /><br /><br /><p><span><span>At times, it</span> ca</span><span>n seem like </span><span>efforts to regulate and rein in </span><span>AI</span> <span>are </span><a href=\"https://spectrum.ieee.org/ai-ethics-governance\" target=\"_blank\">everything, everywhere, all at once</a><span>.</span></p><p><span><span>China issued the first </span></span><a href=\"https://carnegieendowment.org/research/2024/02/tracing-the-roots-of-chinas-ai-regulations?lang=en\" target=\"_blank\"><span><span>AI-specific regulations in 2021</span></span></a><span>. The focus is squarely on providers and content governance, enforced through platform control and recordkeeping requirements.</span> <br /> <br /><span><span>In Europe, the </span></span><a href=\"https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence\" target=\"_blank\"><span><span>European Union AI Act</span></span></a> <span>dates to</span> 2024<span>, but </span><span>the European Commission is already proposing </span><a href=\"https://digital-strategy.ec.europa.eu/en/library/digital-omnibus-ai-regulation-proposal\" target=\"_blank\"><span><span>updates and simplification</span></span></a><span>.</span></p><p><span><span>India charged its senior technical advisors with creating an AI governance system, which they </span></span><a href=\"https://static.pib.gov.in/WriteReadData/specificdocs/documents/2025/nov/doc2025115685601.pdf\" target=\"_blank\"><span><span>released</span></span></a><span> in </span><span>November</span> 2025.</p><p><span><span>In the United States,</span> the </span><span>states</span> are <a href=\"https://www.ncsl.org/financial-services/artificial-intelligence-legislation-database\" target=\"_blank\"><span><span>legislat</span><span>ing</span></span></a><span> and enforc</span><span>ing </span><span>their own AI rules </span><span>even as</span> the federal government <span>in 2025 </span><a href=\"https://www.whitehouse.gov/presidential-actions/2025/12/eliminating-state-law-obstruction-of-national-artificial-intelligence-policy/\" target=\"_blank\"><span><span>moved to prevent state action and loosen the reins</span></span></a><span>. </span></p><p><span><span>This leads to a critical question for American engineers and policymakers alike: What can the U.S. </span><span>actually enforce</span> in a way that reduces real-world harm? My answer: Regulate AI use, not the underlying models.</span></p><h2>Why model-centric regulation fails</h2><p><span><span>Proposals to license \u201cfrontier\u201d training runs, restrict open weights, or require permission before publishing models, such as California\u2019s </span></span><a href=\"https://legiscan.com/CA/text/SB53/id/3270002\" target=\"_blank\"><span><span>Transparency in Frontier Artificial Intelligence Act, </span></span></a><span><span>promise </span><span>control</span> but deliver theater. Model weights and code are digital artifacts; once released, by a lab, a leak, or a foreign competitor, they replicate at near-zero cost. You </span><span>can\u2019t</span> unpublish weights, geofence research, or prevent distillation into smaller models. Trying to bottle up artifacts yields two bad outcomes: Compliant firms drown in paperwork, while reckless <span>actors</span> route around rules offshore, underground, or both.</p><p><span>In the United States, model-publication licensing also likely collides with speech law. Federal courts have treated software source code as protected expression, so any system that prevents the publication of AI models would be vulnerable to legal challenges. </span></p><p><span><span>\u201cDo nothing\u201d is <a href=\"https://spectrum.ieee.org/ai-regulation-worldwide\" target=\"_blank\">not an option</a> either. Without guardrails, we will keep seeing </span></span><a href=\"https://www.dhs.gov/sites/default/files/publications/increasing_threats_of_deepfake_identities_0.pdf\" target=\"_blank\"><span><span>deepfake scams</span></span></a><span><span>, automated fraud, and mass-persuasion campaigns until a headline catastrophe triggers a blunt response </span><span>optimized</span> for optics, not outcomes.</span></p><h2>A practical alternative: Regulate use, proportionate to risk</h2><p><span><span>A use-based regime classifies deployments by risk and scales obligations accordingly. Here is a workable template focused on keeping enforcement where systems </span><span>actually touch</span> people:</span></p><ol start=\"1\"><li><span><strong>Baseline: General-purpose consumer interaction</strong></span><span> (open-ended chat, creative writing, learning </span><span>assistance</span><span>, casual productivity). </span> <br /><span>Regulatory adherence: clear AI disclosure at point of interaction, published acceptable-use policies, technical guardrails preventing escalation into higher-risk tiers, and a mechanism for users to flag problematic outputs.</span> </li></ol><ol start=\"2\"><li><span><strong><span>Low-risk </span><span>assistance</span></strong></span><span> (drafting, summarization</span><span>, basic</span> productivity). <br /><span>Regulatory adherence</span><em><span><em>:</em></span></em> simple disclosure, baseline data hygiene. </li></ol><ol start=\"3\"><li><span><strong>Moderate-risk decision support affecting individuals</strong></span> (hiring triage, benefits screening, loan prequalification). <br /><span>Regulatory adherence</span><em><span><em>:</em></span></em> documented risk assessment, meaningful human oversight, and an \u201cAI bill of materials\u201d consisting of at least the model lineage, key evaluations, and mitigations. </li></ol><ol start=\"4\"><li><span><strong>High-impact uses in safety-critical contexts</strong></span> (clinical decision support, critical-infrastructure operations). <br /><span>Regulatory adherence</span><em><span><em>:</em></span></em><span> rigorous predeployment testing tied to the specific use, continuous monitoring, incident reporting, and, when </span><span>warranted</span><span>, authorization linked to validated performance.</span> </li></ol><ol start=\"5\"><li><span><strong>Hazardous dual-use functions</strong></span> (for example, tools to fabricate biometric voiceprints to defeat authentication). <br /><span>Regulatory adherence</span><em><span><em>:</em></span></em> <span>confine to</span> licensed facilities and verified operators; prohibit capabilities whose primary purpose is unlawful. <br /> <br /><span><h2>Close the loop at real-world choke points</h2></span><span>AI-enabled systems become real when they\u2019re connected to users, money, infrastructure, and institutions, and that\u2019s where regulators should focus enforcement: at the points of distribution (app stores and enterprise marketplaces), capability access (cloud and AI platforms), monetization (payment systems and ad networks), and risk transfer (insurers and contract counterparties).</span> <br /> <br /><span><span>For high-risk uses, we need to require identity binding for operators, capability gating aligned to the risk tier, and tamper-evident logging for audits and postincident review, paired with privacy protections. We need to demand evidence for deployer claims, </span><span>maintain</span> incident-response plans, report material faults, and provide human fallback. When AI use leads to damage, firms should have to show their work and face liability for harms.</span> <br /> <br /><span><span>This approach creates market dynamics that accelerate compliance. If </span></span><span><span>crucial business operations such as </span></span><span><span>procurement, access to cloud </span></span><span>services</span><span><span>, and insurance depend on proving that </span><span>you</span></span><span><span>\u2019re</span> following the rules</span><span><span>, AI model developers will </span><span>build to</span> specifications buyers can check. That raises the safety floor for a</span><span><span>ll industry </span><span>players,</span> startups included, </span><span>without handing an advantage to a few large, licensed incumbents.</span> <br /> <br /><span><h2>The E.U. approach: How this aligns, where it differs</h2></span><span><span>This framework aligns with the E.U. AI Act in two important ways. First, it centers risk at the point of impact: The act\u2019s \u201chigh-risk\u201d categories include employment, education, access to essential services, and critical infrastructure, with life-cycle obligations and complaint rights. It also recognizes special treatment for broadly capable systems (GPAI) without pretending publication control is a safety strategy. My proposal for the United States differs in three </span><span>key ways</span><span>:</span></span> <br /> <br /><span>First, the U.S. must design for constitutional durability. Courts have treated source code as protected speech, and a regime that requires permission to publish weights or train a class of models starts to resemble prior restraint. A use-based regime of rules governing what AI operators can do in sensitive settings, and under what conditions, fits more naturally within the U.S. First Amendment doctrine than speaker-based licensing schemes.</span> <br /> <br /><span><span>Second, </span><span>the</span> E.U. can rely on platforms adapting to the precautionary rules it writes for its unified single market. The U.S. should accept that models will exist globally, both open and closed, and focus on where AI becomes actionable: app stores, enterprise platforms, cloud providers, enterprise identity layers, payment rails, insurers, and regulated-sector gatekeepers (hospitals, utilities, banks). Those are enforceable points where identity, logging, capability gating, and postincident accountability can be </span><span>required</span> without pretending we can \u201ccontain\u201d software. They also span the many specialized U.S. agencies that may not be able to write higher-level rules broad enough to affect the whole AI ecosystem. Instead, the U.S. should regulate AI service choke points more explicitly than Europe does, to accommodate the different shape of its government and public administration. <br /> <br /><span>Third, the U.S. should add an explicit \u201cdual-use hazard\u201d tier. The E.U. AI Act is primarily a fundamental-rights and product-safety regime. The United States also has a national-security reality: Certain capabilities are dangerous because they scale harm (biosecurity, cyberoffense, mass fraud). A coherent U.S. framework should name that category and regulate it directly, rather than trying to fit it into generic \u201cfrontier model\u201d licensing.</span> <br /> <br /><span><h2>China\u2019s approach: What to reuse, what to avoid</h2></span><span><span>China has built a layered regime for public-facing AI. The \u201cdeep synthesis\u201d rules (effective 10 January 2023) require conspicuous labeling of synthetic media and place duties on providers and platforms. The </span></span><span><strong>I</strong></span><span>nterim Measures for Generative AI (effective 15 August 2023) add registration and governance obligations for services offered to the public. Enforcement leverages platform control and algorithm filing systems.</span> <br /> <br /><span><span>The United States should not copy China\u2019s state-directed control of AI viewpoints or information management; it is incompatible with U.S. values and would not survive U.S. constitutional scrutiny. The licensing of model publication is brittle in practice and, in the United States, </span><span>likely an</span> unconstitutional </span><span>form of censorship</span><span>.</span> <br /> <br /><span><span>But we can borrow two practical ideas from China. First, we should ensure trustworthy provenance and traceability for synthetic media. This involves mandatory labeling and </span><span>provenance</span> <span>forensic </span><span>tools. They give legitimate creators and platforms a reliable way to prove origin and integrity. When it is quick to check authenticity at scale, attackers lose the advantage of cheap copies or </span><span>deepfakes</span> and defenders regain time to detect, triage, and respond. Second, we should require </span><span>operators to</span> file their methods <span>and risk controls </span><span>with </span><span>regulators</span> for public-facing, high-risk services, like we do for other <span>safety-critical</span> projects. This should include due-process and transparency safeguards <span>appropriate to</span> liberal democracies along with clear responsibility for safety measures, data protection, and incident handling, especially for systems designed to manipulate emotions or build dependency, which already include gaming, role-playing, and <span>associated applications</span><span>.</span> <br /> <br /><span><h2>A pragmatic approach</h2></span><span><span>We cannot meaningfully regulate the development of AI in a world where artifacts copy in near real time and research flows fluidly across borders. But we can keep unvetted systems out of hospitals, payment systems, and critical infrastructure by regulating uses, not models; </span><span>enforcing at</span> choke points; and applying obligations that scale with risk. </span> <br /> <br /><span><span>Done right, this approach harmonizes with the E.U.\u2019s outcome-oriented framework, channels U.S. federal and state innovation into a coherent baseline, and reuses China\u2019s useful distribution-level controls while rejecting speech-restrictive licensing. We can write rules that protect people </span></span><span>and that still promote robust AI innovation.</span> <br /> </li></ol>", "url": "https://spectrum.ieee.org/ai-model-regulation", "published_at": "Mon, 02 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": ["evaluations", "governance"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/silhouettes-looking-at-screens-sit-behind-a-building-shape-with-the-scales-of-justice-in-a-digital-grid-patterned-setting.jpg?id=63516186&amp;width=1200&amp;height=800&amp;coordinates=277%2C0%2C278%2C0\" /><br /><br /><p><span><span>At times, it</span"]}
{"id": "source:rss:1696852976", "title": "LuSEE-Night: See You on the Far Side of the Moon", "summary": "<img src=\"https://spectrum.ieee.org/media-library/gold-lunar-lander-with-solar-panels-on-rocky-surface-insignia-visible-casting-a-shadow.png?id=63343460&amp;width=1200&amp;height=800&amp;coordinates=0%2C197%2C0%2C198\" /><br /><br /><p>As a kid in the 1970s, I watched the Apollo moon missions on TV, drawn like a curious moth to the cathode-ray tube\u2019s glow. The English band Pink Floyd blared through the speakers of my mom\u2019s Oldsmobile Cutlass Supreme, beckoning us to the <a href=\"https://www.youtube.com/watch?v=QFdkM40KOhE\" rel=\"noopener noreferrer\" target=\"_blank\">dark side of the moon</a>.</p><p>The far side of the moon, the term most scientists prefer, is indeed dark (half the time), cold, and inhospitable. There\u2019s regolith and a couple of Chinese landers\u2014Chang\u2019e 4 in January 2019 and <a href=\"https://spectrum.ieee.org/china-moon-landing-uncrewed-chang-e6\" target=\"_blank\">Chang\u2019e 6</a> in June 2024\u2014and not much else. That could change in about a year, as Contributing Editor Ned Potter reports in \u201c<a href=\"https://spectrum.ieee.org/lunar-radio-telescope\" target=\"_blank\">The Quest to Build a Telescope That Can Hear the Cosmic Dark Ages</a>.\u201d Firefly Aerospace\u2019s <a href=\"https://fireflyspace.com/missions/blue-ghost-mission-2/\" rel=\"noopener noreferrer\" target=\"_blank\">Blue Ghost Mission 2</a> with the LuSEE-Night radio telescope aboard will attempt to become the third successful mission to land there.</p><p>The moon\u2019s far side is the perfect place for such a telescope. The same RF waves that carried images of Neil Armstrong setting foot on the lunar surface, Roger Waters\u2019s voice, and hundreds of Ned Potter\u2019s space and science segments for the U.S. broadcast networks CBS and ABC interfere with terrestrial radio telescopes. If your goal is to detect the extremely faint and heavily redshifted signals of neutral hydrogen from the cosmic Dark Ages, you just can\u2019t do it from Earth. This epoch is so-called because we Earthlings have yet to sense anything from this time period, which started about 380,000 years after the big bang and lasted 200 million to 400 million years. The far side of the moon may be a terrible place to live, but it\u2019s shielded from all the noise of Earth, making it the ideal spot to place a radio telescope.</p><p>As Potter emphasized to me recently, LuSEE-Night won\u2019t listen for a signal from Dark Ages hydrogen directly. \u201cWill the hydrogen from the Dark Ages send a signal? No,\u201d says Potter. \u201cBut all that hydrogen out there may absorb a little bit of energy from the cosmic microwave background, interfering with that even more distant remnant of the big bang.\u201d</p><p>The far side may not stay quiet for much longer. Several countries, including China, India, Japan, Russia, South Korea, the United Arab Emirates, and the United States, are making slow but steady progress toward establishing a lunar presence. As they do so, they\u2019ll place more relay satellites into orbit around the moon to support exploratory activities as well as moon bases planned for the next decade and beyond. That means the window on a noise-free far side is closing. LuSEE-Night, a project 40 years in the making, might just get there in the nick of time.</p><p>Potter is tracking emerging protocols that could preserve the far side\u2019s electromagnetic silence even as such efforts advance. Radio astronomers he\u2019s talked to have shared ideas about how to prevent this emerging problem from turning into a crisis. \u201cThere are no bad guys in this story, at least not yet,\u201d says Potter. \u201cBut there are a lot of well-meaning people who could complicate the picture a great deal if they don\u2019t know that there\u2019s a picture to complicate.\u201d</p><p>It\u2019s a busy time for moon missions. In addition to Blue Ghost Mission 2, the Chinese are sending Chang\u2019e 7 to the moon\u2019s south pole, while NASA\u2019s <a href=\"https://spectrum.ieee.org/artemis-2\" target=\"_self\">Artemis II</a> is scheduled to enter the first of three launch windows this month. Artemis II will be the first mission to put humans into lunar orbit since the last Apollo mission in 1972. And <em><em>IEEE</em></em> <em><em>Spectrum</em></em> readers will enjoy a front row seat, thanks to the enterprising reporting of a true legend in the business, <a href=\"https://spectrum.ieee.org/u/ned-potter\" target=\"_self\">our own Ned Potter</a>.</p><p><em>This article appears in the February 2026 print issue as \u201c<span>See You on the Far Side of the Moon</span>.\u201d</em></p>", "url": "https://spectrum.ieee.org/radio-telescope", "published_at": "Sun, 01 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/gold-lunar-lander-with-solar-panels-on-rocky-surface-insignia-visible-casting-a-shadow.png?id=63343460&amp;width=1200&amp;height=800&amp;coordinates=0%2C197%2C0%2C198\" /><br /><br /><p>As a kid in the 1970s, I watched the Apollo moon missions on TV, "]}
{"id": "source:rss:4768349005", "title": "How YouTube and Adhesive Tape Are Disrupting Assistive Technology", "summary": "<img src=\"https://spectrum.ieee.org/media-library/a-custom-phone-mount-attached-to-a-vehicle-s-auxiliary-controls-for-accessibility.jpg?id=63527438&amp;width=1200&amp;height=800&amp;coordinates=0%2C78%2C0%2C79\" /><br /><br /><p><span>Assistive technology is expensive, and many people with disabilities live on fixed incomes. Disabled assistive tech users also must contend with equipment that was often designed without any capacity to be repaired or modified. But assistive tech users ultimately need the functionality they need\u2014a wheelchair that isn\u2019t constantly needing to be charged, perhaps, or a hearing aid that doesn\u2019t amplify all background noise equally. Assistive tech \u201c<a href=\"https://spectrum.ieee.org/ieee-joins-the-maker-movement\" target=\"_blank\">makers</a>,\u201d who can <a href=\"https://spectrum.ieee.org/why-hire-engineers-with-disabilities-theyre-practiced-problem-solvers\" target=\"_blank\">hack and modify existing assistive tech</a>, have always been in high demand. </span></p><p><span><a href=\"https://iod.unh.edu/person/therese-willkomm\" target=\"_blank\">Therese Willkomm</a>, emeritus professor of occupational therapy at the University of New Hampshire, has <a href=\"https://www.goodreads.com/author/list/8275489.Therese_Willkomm\" target=\"_blank\">written three books</a> cataloging her more than 2,000 assistive technology hacks. Willkomm says she aims to keep her assistive tech hacks costing less than five dollars. </span></p><p><span>She\u2019s come to be known internationally as the \u201c<a href=\"https://tvtropes.org/pmwiki/pmwiki.php/Main/MacGyvering\" target=\"_blank\">MacGyver</a> of Assistive Technology\u201d and has presented more than 600 workshops and assistive tech maker days across 42 states and 14 countries.</span></p><p><span><em>IEEE Spectrum </em>sat down with Willkomm ahead of her latest <a href=\"https://www.atia.org/atia-maker-day/\" target=\"_blank\">assistive tech Maker Day workshop</a>, on Saturday, 31 January, at the <a href=\"https://www.atia.org/conference/\" target=\"_blank\">Assistive Technology Industry Association</a> (ATIA) conference in Orlando, Florida. Over the course of the conversation, she discussed the evolution of assistive technology over 40 years, the urgent need for affordable communication devices, and why the DIY movement matters now more than ever.</span></p><p><em><strong><em>IEEE Spectrum: </em></strong></em><strong>What got you started in assistive technology?</strong></p><p><strong>Therese Willkomm: </strong>I grew up in Wisconsin, where my father had a machine shop and worked on dairy and hog farms. At age 10, I started building and making things. A cousin was in a farm accident and needed modifications to his tractor, which introduced me to welding. In college, I enrolled in vocational rehabilitation and learned about rehab engineering\u2014assistive technology wasn\u2019t coined until 1988 with the <a href=\"https://www.congress.gov/bill/100th-congress/senate-bill/2561\" target=\"_blank\">Technology-Related Assistance Act</a>. In 1979, <a href=\"https://ischool.umd.edu/directory/gregg-vanderheiden/\" target=\"_blank\">Gregg Vanderheiden</a> came to the University of Wisconsin-Stout and demonstrated creative things with garage door openers and communication devices. I thought, \u201cWow, this would be an awesome career path\u2014designing and fabricating devices and worksite adaptations for people with disabilities to go back to work and live independently.\u201d I haven\u2019t looked back.</p><p><strong>You\u2019ve created over 2,000 assistive technology solutions. What\u2019s your most memorable one?</strong></p><p><strong>Willkomm:</strong> A device for castrating pigs with one hand. We figured out a way to design a device that fit on the end of the hog crate that was foot-operated to hold the hind legs of the pig back so the procedure could be done with one hand.</p><h3>Assistive Technology\u2019s Changing Landscape </h3><p><strong>How has assistive technology evolved over the decades?</strong></p><p><strong>Willkomm: </strong>In the 1980s, we fabricated devices from wood and early electronics. I became a [<a href=\"https://www.resna.org/\" target=\"_blank\">Rehabilitation Engineering and Assistive Technology Society of North America</a>, a.k.a. RESNA] member in 1985. The <a href=\"https://www.congress.gov/bill/100th-congress/senate-bill/2561#:~:text=passed%20Senate%2C%20amended)-,Technology%2DRelated%20Assistance%20for%20Individuals%20With%20Disabilities%20Act%20of%201988,of%20all%20ages%20with%20disabilities.\" target=\"_blank\">1988 Technology-Related Assistance Act</a> was transformational\u2014all 50 states finally got funding to support assistive technology and needs in rural areas. Back in the \u201880s, we were soldering and making battery interrupters and momentary switches for toys, radios, and music. Gregg was doing some things with communication. There were <a href=\"https://prc-saltillo.com/why-prc-saltillo/history\" target=\"_blank\">Prentke Romich</a> communication devices. Those were some of the first electronic assistive technologies.</p><p>The early 1990s was all about mobile rehab engineering. Senator Bob Dole <a href=\"https://www.eastersealstech.com/2014/08/27/crucial-part-creative-solution/#:~:text=Most%20of%20the%20grants%20funded,Willkomm%20said.\" target=\"_blank\">gave me a $50,000 grant</a> to fund my first mobile unit. That mobile unit had all my welding equipment, all my fabrication equipment, and I could drive farm to farm, set up outside right in front of the tractor, and fabricate whatever needed to be fabricated. Then, around 1997, there were cuts in the school systems. Mobile units became really expensive to operate. We started to look at more efficient ways of providing assistive technology services. With the Tech Act, we had demonstration sites where people would come and try out different devices. But people had to get in a car, drive to a center, get out, find parking, come into the building\u2014a lot of time was being lost.</p><p>In the 2000s, more challenges with decreased funding. I discovered that with a Honda Accord and those crates you get from Staples, you could have your whole mobile unit in the trunk of your car because of advances in materials. We could make battery interrupters and momentary switches without ever having to solder. We can make switches in 28 seconds, battery interrupters in 18 seconds. When COVID happened, we had to pivot\u2014do more virtual, ship stuff out to people. We were able to serve more individuals during COVID than prior to COVID because nobody had to travel.</p><p><strong>How do you keep costs under five dollars?</strong></p><p><strong>Willkomm:</strong> I aim for five dollars or less. I get tons of corrugated plastic donated for free, so we spend no money on that. Then there\u2019s <a href=\"https://scapaindustrial.com/\" target=\"_blank\">Scapa Tape</a>\u2014a very aggressive double-sided foam tape that costs five cents a foot. If you fabricate something and it doesn\u2019t work out, and you have to reposition, you\u2019re out a nickel\u2019s worth of material. Buying Velcro in bulk helps too. Then<a href=\"https://instamorph.com/\" target=\"_blank\"> Instamorph</a>\u2014it is non-toxic, biodegradable. You can reheat it, reform it, in five minutes or less up to six times. I\u2019ve created about 132 different devices just using Instamorph. A lot of things I make out of Instamorph don\u2019t necessarily work. I have a bucket, and I reuse that Instamorph. We can get six, seven devices out of reusable Instamorph. That\u2019s how we keep it under five dollars.</p><p><strong>What key legislation impacts assistive technology?</strong></p><p><strong>Willkomm: </strong>Definitely the Technology-Related Assistance Act. In the school system, however, it only says \u201cDid you <em>consider</em> assistive technology?\u201d So that legislation really needs to be beefed up. The third piece of legislation I worked on was the <a href=\"https://www.nifa.usda.gov/grants/programs/agrability\" target=\"_blank\">AgrAbility</a> legislation to fund assistive technology consultations and technical assistance for farmers and ranchers. The latest Technology-Related Assistance Act was <a href=\"https://ataporg.org/at-act-info/\" target=\"_blank\">reauthorized in 2022</a>. Not a whole lot of changes\u2014it\u2019s still assistive technology device demonstrations and loans, device reuse, training, technical assistance, information and awareness. The other thing is<a href=\"https://acl.gov/about-acl/about-national-institute-disability-independent-living-and-rehabilitation-research\" rel=\"noopener noreferrer\" target=\"_blank\"> NIDILRR</a>\u2014National Institute on Independent Living and Rehabilitation Research, funded under [the U.S. Department of Health and Human Services, a.k.a. <a href=\"https://en.wikipedia.org/wiki/United_States_Department_of_Health_and_Human_Services\" target=\"_blank\">HHS</a>]. Funding the rehab engineering centers was pretty significant in advancing the field because these were huge, multimillion-dollar centers dedicated to core areas like communication and employment. Now there\u2019s a new one out on artificial intelligence.</p><h3>A Vision for a Better Assistive Tech Future </h3><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" rel=\"float: left;\" style=\"float: left;\"> <img alt=\"Person wearing a floral-patterned, white shirt and beaded necklace outdoors.\" class=\"rm-shortcode\" id=\"1a182\" src=\"https://spectrum.ieee.org/media-library/person-wearing-a-floral-patterned-white-shirt-and-beaded-necklace-outdoors.jpg?id=63527474&amp;width=980\" /> <small class=\"image-media media-caption\">With over 2,000 hacks to improve usability of assistive technologies, veteran DIY maker Therese Willkomm has earned the moniker \u201cthe MacGyver of assistive tech.\u201d </small><small class=\"image-media media-photo-credit\">Therese Willkomm</small></p><p><strong>What deserves more focus in your field?</strong></p><p><strong>Willkomm:</strong> The supply-and-demand problem. It all comes down to time and money. We have an elderly population that continues to grow, and a disability population that continues to grow\u2014high demand, high need for assistive technology, yet the resources available to meet that need are limited. A few years back, the <a href=\"https://www.christopherreeve.org/\" target=\"_blank\">Christopher & Dana Reeve Foundation</a> had a competition. I submitted a proposal similar to the <a href=\"https://topmealkitdelivery.com/compare-top/?utm_source=google&amp;keyword=how%20does%20blue%20apron%20work&amp;campaignid=19738344647&amp;adgroupid=147312616278&amp;targetid=kwd-119910014195&amp;device=c&amp;loc_physical=9001648&amp;net_type=g&amp;mt=e&amp;gad_source=1&amp;gad_campaignid=19738344647&amp;gbraid=0AAAAACWvR1todciLbxMtVpO1D33ERjChb&amp;gclid=CjwKCAiAssfLBhBDEiwAcLpwfhQhzA6bmvh2gvcKuF296EMnhDCD_JjnPyNwHec6UsC5F7V2brgQGhoCabYQAvD_BwE\" target=\"_blank\">Blue Apron approach</a>. People don\u2019t have supplies at their house. They can\u2019t buy two inches of tape\u2014they have to buy a whole roll. They can\u2019t buy one foot of corrugated plastic\u2014they\u2019ve got to buy an 18-by-24 sheet or wait till it gets donated.</p><p>With my <a href=\"https://www.goodreads.com/book/show/58523017-assistive-technology-solutions-in-minutes-book-iii---make-stuff-and-love\" target=\"_blank\">third book</a>, I created solutions with QR codes showing videos on how to make them. I used Christopher Reeve Foundation funding to purchase supplies. With Blue Apron, somebody wants to make dinner and a box arrives with a chicken breast, potato, vegetables, and recipe. I thought, what if we could apply that to assistive technology? Somebody needs something, there\u2019s a solution out there, but they don\u2019t have the money or the time\u2014how can we quickly put it in a box and send it to them? People who attended my workshops didn\u2019t have to spend money on materials or waste time at the store. They\u2019d watch the video and assemble it.</p><p>But then there were people who said, \u201cI do not have even five minutes in the school day to stop what I\u2019m doing to make something.\u201d So we found volunteers who said, \u201cHey, I can make slant boards. I can make switches. I can adapt toys.\u201d You have people who want to build stuff and people who need stuff. If you can deal with the time and money issue, anything\u2019s possible to serve more people and provide more devices.</p><p><strong>What\u2019s your biggest vision for the future?</strong></p><p><strong>Willkomm:</strong> I\u2019m very passionate about communication. December 15 was the <a href=\"https://www.archives.gov/founding-docs/bill-of-rights-transcript\" target=\"_blank\">passage in 1791 of our First Amendment</a>, freedom of speech. Yet people with communication impairments are denied their basic right of freedom of speech because they don\u2019t have an affordable communication device, or it takes too long to program or learn. I just wish we could get better at designing and fabricating affordable communication devices, so everybody is awarded their First Amendment right. It shouldn\u2019t be something that\u2019s nice to have\u2014it\u2019s something that\u2019s needed to have. When you lose your leg, you\u2019re fitted with a prosthetic device, and insurance covers that. Insurance should also cover communication devices and all the support services needed. With voice recognition and computer-generated voices, there are tremendous opportunities in assistive technology for communication impairments that need to be addressed.</p><p><strong>What should </strong><em><strong><em>IEEE Spectrum</em></strong></em><strong> readers take away from this conversation?</strong></p><p><strong>Willkomm: </strong>There\u2019s tremendous need for this skill set\u2014working in conjunction with AI and material sciences and the field of assistive technology and rehab engineering. I\u2019d like people to look at opportunities to volunteer their time and also to pursue careers in the field of specialized rehab engineering.</p><p><strong>How are DIY approaches evolving with new technologies?</strong></p><p><strong>Willkomm:</strong> What we\u2019re seeing at maker fairs is more people doing <a href=\"https://spectrum.ieee.org/3d-printed-rockets-india-agnikul\" target=\"_blank\">3D printing</a>, switch-access controls, and these five-minute approaches. There has to be a healthy balance between what we can do with or without electronics. If we need something programmed with electronics, absolutely\u2014but is there a faster way?</p><p>The other thing that\u2019s interesting is skill development. You used to have to go to college for four, six, eight years. With YouTube, you can learn so much on the internet. You can develop skills in things you never thought were possible without a four-year degree. There\u2019s basic electronic stuff you can absolutely learn without taking a course. I think we\u2019re going to have more people out there doing hacks, asking \u201cWhat if I change it this way?\u201d We don\u2019t need to have a switch. </p><p>We need to look at the person\u2019s body and how that body interacts with the electronic device interface so it requires minimal effort\u2014whether it be eye control or motion control. Having devices that predict what you\u2019re going to want next, that are constantly listening, knowing the way you talk. I love the fact that AI looks at all my emails and creates this whole thing like \u201cHere\u2019s how I\u2019d respond.\u201d I\u2019m like, yeah, that\u2019s exactly it. I just hit select, and I don\u2019t have to type it all out. It speeds up communication. We\u2019re living in exciting times right now.</p><p><em>This article was supported by the <a href=\"https://spectrum.ieee.org/tag/ieee-foundation\" target=\"_self\">IEEE Foundation</a> and a John C. Taenzer fellowship grant.</em></p>", "url": "https://spectrum.ieee.org/assistive-technology-macgyver", "published_at": "Sat, 31 Ja", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/a-custom-phone-mount-attached-to-a-vehicle-s-auxiliary-controls-for-accessibility.jpg?id=63527438&amp;width=1200&amp;height=800&amp;coordinates=0%2C78%2C0%2C79\" /><br /><br /><p><span>Assistive technology is expensive, and many people with disabiliti"]}
{"id": "source:rss:2399217310", "title": "Explore the Stratosphere With a DIY Pico balloon", "summary": "<img src=\"https://spectrum.ieee.org/media-library/a-printed-circuit-board-attached-to-two-small-solar-panels-hangs-beneath-a-balloon.png?id=63339900&amp;width=1200&amp;height=800&amp;coordinates=0%2C462%2C0%2C463\" /><br /><br /><p>There\u2019s an interesting development in amateur ballooning: using so-called <a href=\"https://en.wikipedia.org/wiki/Superpressure_balloon\" rel=\"noopener noreferrer\" target=\"_blank\">superpressure balloons</a>, which float high in the atmosphere indefinitely rather than simply going up and up and then popping like a normal weather balloon. Superpressure balloons can last for months and travel long distances, potentially circumnavigating the globe, all the while reporting their position.</p><p>You might imagine that an undertaking like this would be immensely difficult and cost thousands of dollars. In fact, you can build and launch such a balloon for about the cost of a fancy dinner out. You just have to think small! That\u2019s why amateur balloonists call them pico balloons.</p><p>The payload of a pico balloon is so light (between 12 to 30 grams) that you can use a large Mylar party balloon filled with helium to lift it. They\u2019re also inexpensive; that\u2019s important because you won\u2019t get your payload back. And because such diminutive payloads don\u2019t pose a danger to aircraft, they aren\u2019t subject to the many rules and restrictions on free-floating balloons that carry more mass.</p><p>The essential advances that made pico ballooning possible were figuring out how to track a balloon no matter where in the world it might be and how to power such tiny payloads. A lot of folks worked on these challenges and came up with good solutions that aren\u2019t hard or expensive to reproduce.</p><h2>What is WSPR?</h2><p>Amazingly, the global tracking of the balloon\u2019s telemetry is done without satellites. Instead, pico balloonists take advantage of an <a href=\"https://spectrum.ieee.org/tag/amateur-radio\" target=\"_blank\">amateur-radio</a> network called <a href=\"https://en.wikipedia.org/wiki/WSPR_(amateur_radio_software)\" rel=\"noopener noreferrer\" target=\"_blank\">WSPR</a> (Weak Signal Propagation Reporter), a protocol developed by a rather famous ham-radio enthusiast\u2014<a href=\"https://en.wikipedia.org/wiki/Joseph_Hooton_Taylor_Jr.\" rel=\"noopener noreferrer\" target=\"_blank\">Joseph Hooton Taylor Jr</a>., one of the two scientists awarded the 1993 Nobel Prize in Physics for discovering binary pulsars.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Major components of a pico balloon payload.\" class=\"rm-shortcode\" id=\"176da\" src=\"https://spectrum.ieee.org/media-library/major-components-of-a-pico-balloon-payload.png?id=63339919&amp;width=980\" /> <small class=\"image-media media-caption\">A Raspberry Pi Pico microcontroller [top left] is soldered directly to a daughterboard consisting of a high-frequency transmitter and a GPS module [bottom left], which are all powered by solar panels [right].</small><small class=\"image-media media-photo-credit\">James Provost</small></p><p>WSPR was designed to monitor signal-propagation conditions for different radio bands\u2014useful information if you\u2019re a ham trying to make distant contacts. WSPR can also record low-power balloon-telemetry signals. WSPR is very low bandwidth\u2014less than 10 bits per minute\u2014but it does the job. A worldwide network of radio amateurs receives these WSPR signals and reports them publicly over the internet, which gives picoballoonists a way to track their flights. You need at least a <a href=\"https://www.arrl.org/upgrading-to-a-general-license\" target=\"_blank\">general-class</a> ham-radio license to launch a pico balloon, as one is required to transmit on the bands used for long-distance telemetry.</p><p>The pico balloon payload I chose to build is based on the aptly named US $4 <a href=\"https://www.adafruit.com/product/4864\" target=\"_blank\">Raspberry Pi Pico board</a>, with a solder-on daughterboard that contains a <a href=\"https://spectrum.ieee.org/tag/gps\" target=\"_blank\">GPS</a> receiver and transmitter. The folks who developed this daughterboard and associated software (to create what they call the <a href=\"https://traquito.github.io/tracker/\" target=\"_blank\">Jetpack WSPR Tracker</a>) have done a fantastic job of making their work easy to reproduce.</p><p>You could, in principle, power the Jetpack tracker with batteries, but in practice it would be impossible to keep them warm in the stratosphere, where average temperatures can be as low as \u201351 \u00b0C. Instead, the tracker runs off two lightweight solar modules. At night, it gracefully powers down. When the sun rises high enough in the morning, the tracker powers up and starts transmitting again.</p><p class=\"pull-quote\"><span>My first pico balloon made it only halfway across the Atlantic before going silent.</span></p><p>I had five Jetpack boards custom-manufactured in China for just $39. The cost nearly doubled after adding shipping and tariff charges. Still that\u2019s really cheap, even when you add the cost of the Raspberry Pi ($4), <a href=\"https://www.amazon.com/dp/B0F28ZWPY6\" target=\"_blank\">the party balloon</a> ($10 for two), the helium ($10 at my local supermarket), and the two <a href=\"https://www.amazon.com/PowerFilm-MPT6-75-Module-Flexible-Thin-Film/dp/B002MFGD16\" target=\"_blank\">solar modules</a> ($7 each).</p><p>The biggest sticking point I had with the Jetpack design was the liberties it takes with spurious emissions from its transmitter. Federal Communications Commission (FCC) regulations call for spurious emissions to be at least 43 decibels below the power of the transmitted signal. But my transmitter had strong unwanted emissions at odd harmonics of the fundamental frequency. (That\u2019s because the transmitter is a<a href=\"https://cdn.sparkfun.com/assets/3/e/a/9/a/Si5351-datasheet.pdf\" rel=\"noopener noreferrer\" target=\"_blank\"> Si5351A</a> temperature-controlled oscillator, which outputs a square wave, not a sinusoid.) Taking measurements, I could see that the third harmonic at 42 megahertz was only 25 dB quieter than the 14-MHz fundamental of my WSPR signal\u2019s frequency. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"A map showing a track from North Carolina in the United States across the Atlantic and the Iberean peninsula to the Mediterranean. \" class=\"rm-shortcode\" id=\"77213\" src=\"https://spectrum.ieee.org/media-library/a-map-showing-a-track-from-north-carolina-in-the-united-states-across-the-atlantic-and-the-iberean-peninsula-to-the-mediterranea.png?id=63339932&amp;width=980\" /> <small class=\"image-media media-caption\">As of press time, the WSPR network had tracked my balloon from the Eastern United States to the Mediterranean coast. </small><small class=\"image-media media-photo-credit\">James Provost</small></p><p>In practical terms, this shouldn\u2019t create any noticeable interference, given that this transmitter puts out milliwatts at most and floats miles away from the nearest receiver. Still, I wanted to be fully compliant with FCC regulations, so I added traps to the antenna\u2014simple circuit elements that hams use to allow a single antenna to work on multiple bands by altering how the antenna resonates at different frequencies. Each trap was made of a small inductor (four 5-millimeter-diameter loops of No. 32 magnet wire) in parallel with a 220-picofarad capacitor. I tuned them with the help of a <a href=\"https://nanovna.com/\" target=\"_blank\">NanoVNA</a> signal analyzer by stretching the loops apart slightly. I attached the traps directly to the tracker board, so that they quashed the spurious 42-MHz emissions at the source. That worked well and added only 0.3 grams of weight.</p><p>With my payload complete, I partially filled my balloon with helium. You want the balloon to hold just a little more gas than it takes to lift the payload off the ground. This will give the helium room to expand as the balloon climbs to its final altitude.</p><p>My first pico balloon, launched from a park near my home in North Carolina, made it only halfway across the Atlantic before going silent. My second went up and was never heard from again. The third was indeed the charm. It crossed the Iberian Peninsula and at the time of this writing is somewhere over the Mediterranean at an altitude of nearly 12 kilometers. With any luck, <a href=\"https://traquito.github.io/search/spots/dashboard/?band=20m&amp;channel=104&amp;callsign=N4LVD&amp;dtGte=2026-01-01\" target=\"_blank\">it might go on</a> to orbit the planet.</p><p>I\u2019m a little puzzled about the balloons\u2019 telemetry messages received on the WSPR network, as they have been few and far between. My best guess is that power from the horizontal solar panels I\u2019m using is marginal, with the winter sun being so low in the sky. That\u2019s something I should have thought about before launching the first balloon just 24 hours after the winter solstice!</p><p><em>This article appears in the February 2026 print issue as \u201c<span>Long-Duration Amateur Ballooning</span>.\u201d</em></p>", "url": "https://spectrum.ieee.org/explore-stratosphere-diy-pico-balloon", "published_at": "Sat, 31 Ja", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/a-printed-circuit-board-attached-to-two-small-solar-panels-hangs-beneath-a-balloon.png?id=63339900&amp;width=1200&amp;height=800&amp;coordinates=0%2C462%2C0%2C463\" /><br /><br /><p>There\u2019s an interesting development in amateur ballooning: using so-ca"]}
{"id": "source:rss:2874542644", "title": "Ode to Very Small Devices", "summary": "<img src=\"https://spectrum.ieee.org/media-library/anthropomorphized-miniature-gadgets-standing-on-the-heads-of-two-hex-bolts.jpg?id=63525887&amp;width=1200&amp;height=800&amp;coordinates=0%2C24%2C0%2C25\" /><br /><br /><p>As fairies for the Irish or leeks for Welsh,<br /><span>it\u2019s the secret lives of small hidden machines,<br /></span><span>their junctures, and networks that inspire me:<br /></span><span>Mystic hidden functionaries that make<br /></span><span>our made world live, brave little servo motors,<br /></span><span>whose couplers, whose eccentric fire-filled<br /></span><span>sensors are encased in bakelite with brass<br /></span><span>screws, who stare with red eyes, who gauge moisture,<br /></span><span>who notice tiny motions and respond,<br /></span><span>whose cooling fans call out in white-noise<br /></span><span>registers like older folk singers\u2013I can<br /></span><span>almost hear their earlier songs, their strong voices<br /></span><span>now yelps, their thumps, their throbs, their hum, their chant\u2013,<br /></span><span>they click, they whir, they are sent spinning<br /></span><span>inside like teen girls giggling over boy bands.<br /></span><span>Most of all: ones waiting silently, concealing<br /></span><span>the surprise of their purpose, tasks not yet known,<br /></span><span>their true natures found only in connections.</span></p><p>Those that listen, those that speak,<br /><span>those that control cool and heat,<br /></span><span>those that open doors, those that lock<br /></span><span>all the things that we\u2019ve forgot,<br /></span><span>those that hide, those that disclose<br /></span><span>those embedded in our clothes<br /></span><span>those in our ears, those in our hearts<br /></span><span>those that bring together, those a part<br /></span><span>of divisions, those like birds,<br /></span><span>like parrots that complete our words,<br /></span><span>those like fish, those that entrap,<br /></span><span>those that free, those that freely flap<br /></span><span>in fierce winds, those that replace<br /></span><span>what we have lost, those that see<br /></span><span>at night, in fog, in brightness, in fear,<br /></span><span>those that show what we hold dear,<br /></span><span>those that tempt, those that repel,<br /></span><span>those that buy and those that sell,<br /></span><span>those that keep us alive, those that<br /></span><span>don\u2019t, won\u2019t, couldn\u2019t and cannot.</span></p><p>Parts of one mind, not mine, blunt orchestra<br /><span>of information, bundles of feelers<br /></span><span>reaching out to touch us, teach us, guide us<br /></span><span>to form better futures better understood.<br /></span><span>May your sounds, your chimes, your silence calm us.<br /></span><span>May your tender tendrils touch what we seek.<br /></span><span>Small parts becoming one being intertwined,<br /></span><span>a world in itself, remind us to be kind. </span></p>", "url": "https://spectrum.ieee.org/poetry-for-engineers-ode", "published_at": "Fri, 30 Ja", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/anthropomorphized-miniature-gadgets-standing-on-the-heads-of-two-hex-bolts.jpg?id=63525887&amp;width=1200&amp;height=800&amp;coordinates=0%2C24%2C0%2C25\" /><br /><br /><p>As fairies for the Irish or leeks for Welsh,<br /><span>it\u2019s the secret lives o"]}
{"id": "source:rss:2690946155", "title": "Go Global to Make Your Career Go Further", "summary": "<img src=\"https://spectrum.ieee.org/media-library/illustration-of-earth-with-curved-lines-representing-digital-connections-between-different-continents.jpg?id=63519073&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><em><em>This article is part of our exclusive </em></em><a href=\"https://spectrum.ieee.org/tag/career-advice\" target=\"_self\"><em><em>career advice</em></em></a><em><em> series in partnership with the </em></em><a href=\"https://www.ieee-tems.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IEEE Technology and Engineering Management Society</em></em></a><em><em>.</em></em> </p><p>In your career, you are likely to face many choices and job opportunities. One I faced was whether to participate in a development project involving teams from around the world. It presented a great opportunity for personal and professional enrichment.</p><p>Throughout my 40-year career with <a href=\"https://www.honeywell.com/us/en\" rel=\"noopener noreferrer\" target=\"_blank\">Honeywell</a>, I have held leadership roles for such projects in Australia, China, Finland, and India.</p><p>You might be offered similar assignments. Here are some benefits of taking on international projects.</p><h2>Gain professional insights and advancement</h2><p>As a rule, international projects are large in scope and involve many critical components, making them ideal for your professional growth. Such projects are likely to be identified by your organization as essential to the business and, as such, present opportunities for individual achievement and recognition.</p><p>They also can give you the opportunity to <a href=\"https://spectrum.ieee.org/advice-leading-mentoring-greater-innovation\" target=\"_self\">work with many technical aspects</a>\u2014which would allow you to see beyond the scope of smaller-scale projects.</p><p>Likewise, you can gain an understanding of different global markets and how to meet diverse customer needs.</p><p>It can significantly expand your company\u2019s market reach to enter new geographic areas. It also can lead to a better understanding of local preferences, regulations, and technical standards, making the products more appealing to customers in other countries.</p><h2>Planning for working globally</h2><p>When embarking on a <a href=\"https://spectrum.ieee.org/robotic-process-automation-gokul-pandy\" target=\"_self\">global, multisite assignment,</a> seek help to define your role. The project could require you to take on several different positions such as project manager, program manager, scrum leader, architect, requirements analyst, designer, and user experience lead. Which role would be best suited for you? You should decide based on your skills, long-term career growth, and the project\u2019s needs.</p><p>Regardless of which role you have, it is important to have an understanding of the team\u2019s other members, including their skills and competencies and how best to interact with them.</p><p>A key decision early on is whether you\u2019ll have to colocate at one location and, if so, for how long. There are different types of colocation, including frequent travel between offices, a temporary relocation known as a \u201cbubble assignment,\u201d and an expatriate assignment that involves relocating to another country for a period of time.</p><p>Travel between offices makes sense when there are more than two locations involved in the project and your role requires your presence at each. Although weekly communication can be done via virtual meetings, there is no substitute for occasional face-to-face interaction.</p><p class=\"pull-quote\"><span>Participation in global product development empowers engineers to drive innovation, achieve career growth, and make a meaningful impact in the global marketplace and on society itself.</span></p><p>Bubble assignments require longer on-site presence but without the rigor and complexity of an expat assignment. Generally, bubble assignments last three to six months.</p><p>Expat assignments are suitable when the project scope requires a multiyear engagement. They involve relocating to that country for the duration of the project. You and your employer should be clear about taxes, salary, benefits, housing, and other implications.</p><p>Your compensation is a significant consideration. It\u2019s not just about how much money you earn. Consider maintaining your salary in your home country\u2019s currency. The benefits include maintaining your bank and automatic payroll deposits, avoiding currency fluctuation and potentially adverse inflation.</p><p>Depending on the length of your stay, you might have to pay income tax in several countries. Make sure you understand the tax implications before embarking on any long assignments.</p><p>In addition, find out about your health insurance coverage when living abroad.</p><h2>Trust is the word</h2><p>Many critical aspects define a successful global assignment, including communication across time zones, managing cultural barriers and expectations, ensuring each site has employees with the expertise and skills needed, and setting clear project goals and time frames.</p><p>Most importantly, establish and maintain trust. Every member on the global team must have everyone\u2019s best interests, including the company\u2019s, in mind.</p><p>Trust is not easily gained, but it can be easily\u2014and quickly\u2014lost. To establish trust, the project leadership must be transparent, communicate frequently, set clear goals and boundaries, and define roles that match the participants\u2019 skills, capabilities, and long-term interests.</p><p>It\u2019s also critical that you and your team fulfill your promises on time.</p><h2>Overcoming challenges</h2><p>Large, complex, multilocation projects present other significant challenges that must be understood and managed.</p><p>Think about your company\u2019s organizational structure and boundaries. Is there a consistent reporting structure with shared goals and expectations? Or are there potentially competing interests at the executive level?</p><p>If the latter, think about how you will navigate those boundaries. And find a way to align the organization in a way that benefits all participants and teams.</p><p>A method Honeywell has used to navigate such challenges is to create a \u201chub and spoke\u201d approach to the critical disciplines of program management, architecture, and design. The approach includes offering management, verification, validation, and quality assurance with the intent that each participating site has representation in all four cornerstone areas.</p><p>Consider your computer systems. Is your company set up to allow for IT collaboration across sites and geographic boundaries? Having the right multisite computing privileges to ensure frictionless virtual teamwork is vital.</p><p>Are there legal issues such as export restrictions or government regulations? Are there intellectual property constraints when working with other countries? Also consider other impediments such as tariffs and customs duties; where the parts of your product are manufactured; product and component licensing; and use of open-source technology.</p><p>Addressing those issues starts with training the workforce in different countries about company-approved methods and restrictions, as well as having multisite tools that allow for intercountry collaboration.</p><h2>Discover personal enrichment</h2><p>In addition to contributing to your professional growth, actively engaging in a global development project can be <a href=\"https://spectrum.ieee.org/influence-your-career\" target=\"_self\">personally enriching</a>. Working with people in different countries, with distinct cultures and languages, can broaden your understanding of the world and can create lasting friendships.</p><p>That can extend to your family by hosting international colleagues in your home country and by affording your family the ability to travel with you. Children and adults can benefit from engaging with diverse people from around the world.</p><p>Taking an active part in global development offers numerous advantages for an individual. You can broaden your horizons, gain exposure to diverse markets, and develop a deeper understanding of global consumer needs. The experience can enhance your problem-solving skills and encourage innovative thinking.</p><p>Engineers who navigate the challenges of global product development become more adept at overcoming communication barriers, managing logistical complexities, and adapting to varying consumer preferences.</p><p>Ultimately, active participation in global product development empowers engineers to drive innovation, achieve career growth, and make a meaningful impact in the global marketplace and on society itself.</p>", "url": "https://spectrum.ieee.org/global-projects-career-benefits", "published_at": "Fri, 30 Ja", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/illustration-of-earth-with-curved-lines-representing-digital-connections-between-different-continents.jpg?id=63519073&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><em><em>This article is part of our exclusive </em><"]}
{"id": "source:rss:6196874247", "title": "Video Friday: Multitasking Robots Smoothly Do the Things Together", "summary": "<img src=\"https://spectrum.ieee.org/media-library/humanoid-robot-holds-small-yellow-bag-near-biohazard-trash-bin-in-a-hallway.png?id=63524908&amp;width=1200&amp;height=800&amp;coordinates=50%2C0%2C51%2C0\" /><br /><br /><p><span>Video Friday is your weekly selection of awesome robotics videos, collected by your friends at </span><em>IEEE Spectrum</em><span> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please </span><a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a><span> for inclusion.</span></p><h5><a href=\"https://2026.ieee-icra.org/\">ICRA 2026</a>: 1\u20135 June 2026, VIENNA</h5><p>Enjoy this week\u2019s videos!</p><div class=\"horizontal-rule\"></div><div><span style=\"display: none;\"> </span></div><blockquote class=\"rm-anchors\" id=\"xpc3kfygwis\"><em>Westwood Robotics is proud to announce a major update: THEMIS Gen2.5, the world\u2019s first commercial full-size humanoid robot capable of manipulation on the move!</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>Now that you mention it, the bit at the end where the robot picks up a can while walking? I haven\u2019t seen a lot of that.</p><p>[ <a href=\"https://www.westwoodrobotics.io/\">Westwood Robotics</a> ] </p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"lqsvtrrtbrs\"><em>Last year, Helix showed that a single neural network could control a humanoid\u2019s upper body from pixels. Today, Helix 02 extends that control to the entire robot\u2014walking, manipulating, and balancing as one continuous system.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>Why, yes, I am a normal human, and this is very similar to the default state of my kitchen.</p><p>[ <a href=\"https://www.figure.ai/\">Figure</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"npovmr80scc\"><em><a href=\"https://spectrum.ieee.org/ieee-spectrum-wins-11-awards\" target=\"_blank\">Harry Goldstein</a>, our editor in chief, went to meet Sprout from Fauna Robotics. He was skeptical at first, but Sprout won him over with its robotic charm.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://faunarobotics.com/\">Fauna Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"ta_ttogdmfa\"><em>Kimberly Elenberg is showing how the data collected by <a href=\"https://spectrum.ieee.org/darpa-triage-challenge-robots\" target=\"_blank\">robotic responders </a>can save lives in mass casualty events.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.cs.cmu.edu/news/2024/chiron-second-round\">Carnegie Mellon University</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"ttey2j1jnyy\">The educational robotics market is tough, but you\u2019ve got to hand it to <a href=\"https://spectrum.ieee.org/best-robots-of-ces\" target=\"_blank\">Sphero</a>\u2014going strong since 2011, which is pretty incredible.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://sphero.com/\">Sphero</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"4fljuahsmgi\"><em>If you want to fly in crazy conditions, you have to <a href=\"https://spectrum.ieee.org/photo-essay-tornados-and-frisky-birds-couldnt-stop-these-delivery-drones\" target=\"_blank\">flight test</a> in those conditions. Here\u2019s how and why we do it!</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.zipline.com/\">Zipline</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"09lbks8zplo\">I want to be impressed more by the idea of 3D-printing skin and skeleton at the same time, but come on, animals have been doing that for literally hundreds of years without even trying.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.jsk.t.u-tokyo.ac.jp/\">JSK Lab, University of Tokyo</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"uaba2po-i5g\">If there is a market for small bipedal robots that can both ski and be dinosaurs, LimX has it covered.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.limxdynamics.com/en/tron1\">LimX</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"u-yly7nghsq\"><em>How do you remotely control robots that change shape? We introduce a method for user-guided control of <a href=\"https://spectrum.ieee.org/epfl-developing-connectors-for-modular-floating-robots\" target=\"_blank\">modular robots</a> using reconfigurable joint-space joysticks (JoJo) and real-time optimization. We demonstrate this system on two different robots, Mori3 and Roombots. The video shows examples of these robots performing object manipulation, locomotion, human-assistance, and reconfiguration, controlled by our system.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.epfl.ch/labs/rrl/\">EPFL Reconfigurable Robotics Lab</a> ] via [ <a href=\"https://www.nature.com/articles/s41467-025-63706-6\" target=\"_blank\">Nature Communications</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"xoheteywrcs\"><em>Quadrotor Biplane Tailsitter (QBiT) UAVs at four different sizes (4, 12, 25, and 50 lbs) developed at Texas A&amp;M University. QBiT combines the mechanical simplicity of a quadrotor drone with the cruise efficiency of a fixed-wing aircraft.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://avfl.engr.tamu.edu/\">Texas A&amp;M University</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"7b1obxjj75q\">There\u2019s a new DARPA challenge for \u201cnovel drone designs that can carry payloads more than four times their weight, which would revolutionize the way we use drones across all sectors.\u201d</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p>[ <a href=\"https://www.darpa.mil/research/challenges/lift\">DARPA</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"-znp4jrfu8i\">Here are a couple of plenary and keynote talks from IROS 2025, from <a href=\"https://spectrum.ieee.org/marco-hutter-ai-institute\" target=\"_blank\">Marco Hutter</a> and <a href=\"https://spectrum.ieee.org/ieee-society-boosting-student-membership\" target=\"_blank\">Karinne Ramirez Amaro</a>.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span></p><p><span>[ </span><a href=\"https://www.iros25.org/\">IROS 2025</a><span> ]</span></p><div class=\"horizontal-rule\"></div>", "url": "https://spectrum.ieee.org/multitasking-robot", "published_at": "Fri, 30 Ja", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/humanoid-robot-holds-small-yellow-bag-near-biohazard-trash-bin-in-a-hallway.png?id=63524908&amp;width=1200&amp;height=800&amp;coordinates=50%2C0%2C51%2C0\" /><br /><br /><p><span>Video Friday is your weekly selection of awesome robotics videos, collec"]}
{"id": "source:rss:4833370638", "title": "At Age 25, Wikipedia Refuses to Evolve", "summary": "<img src=\"https://spectrum.ieee.org/media-library/illustration-of-the-wikipedia-logo-in-a-glass-case-on-display-with-a-placard-that-says-wikipedia-2001.jpg?id=63148696&amp;width=1200&amp;height=800&amp;coordinates=156%2C0%2C156%2C0\" /><br /><br /><p><span>Wikipedia celebrates its 25th anniversary this month as the internet\u2019s most reliable knowledge source. Yet behind the celebrations, a troubling pattern has developed: The volunteer community that built this encyclopedia has lately rejected a key innovation designed to serve readers. The same institution founded on the principle of easy and open community collaboration could now be proving unmovable\u2014trapped between the need to adapt and an institutional resistance to change.</span></p><h3>Wikipedia\u2019s Digital Sclerosis</h3><p>Political economist <a href=\"https://en.wikipedia.org/wiki/Elinor_Ostrom\" target=\"_blank\">Elinor Ostrom</a> won the 2009 Nobel Prize in economics for <a href=\"https://archive.org/details/governingcommons0000ostr/page/n5/mode/2up\" target=\"_blank\">studying the ways communities successfully manage shared resources</a>\u2014the \u201ccommons.\u201d Wikipedia\u2019s two founders (<a href=\"https://en.wikipedia.org/wiki/Jimmy_Wales\" target=\"_blank\">Jimmy Wales</a> and <a href=\"https://en.wikipedia.org/wiki/Larry_Sanger\" target=\"_blank\">Larry Sanger</a>) <a href=\"https://en.wikipedia.org/wiki/History_of_Wikipedia\" target=\"_blank\">established the internet\u2019s open-source encyclopedia</a> 25 years ago on principles of the commons: Its volunteer editors create and enforce policies, resolve disputes, and shape the encyclopedia\u2019s direction.</p><p>But building around the commons contains a trade-off, Ostrom\u2019s work found. Communities that make collective decisions tend to develop strong institutional identities. And those identities sometimes spawn reflexively conservative impulses.</p><p>Giving users agency over Wikipedia\u2019s rules, as I\u2019ve discovered in some of <a href=\"https://www.researchgate.net/publication/301663933_Wikimedia_movement_governance_the_limits_of_a-hierarchical_organization\" target=\"_blank\">my own studies of Wikipedia</a>, can lead an institution away ultimately from the needs of those the institution serves.</p><p>Wikipedia\u2019s editors have built the largest collaborative knowledge project in human history. But the governance these editors exercise increasingly resists new generations of innovation.</p><p>Paradoxically, Wikipedia\u2019s revolutionarily collaborative structure once put it at the vanguard of innovation on the open internet. But now that same structure may be failing newer generations of readers.</p><h3>Does Wikipedia\u2019s Format Belong to Readers or Editors?</h3><p>There\u2019s a generational disconnect today at the heart of Wikipedia\u2019s current struggles. The encyclopedia\u2019s format remains wedded to the information-dense, text-heavy style of <a href=\"https://en.wikipedia.org/wiki/Encyclop%C3%A6dia_Britannica\" target=\"_blank\">Encyclopedia Britannica</a>\u2014the very model Wikipedia was designed to replace.</p><p>A Britannica replacement made sense in 2001. One-quarter of a century ago, the average internet user was older and accustomed to reading long-form content.</p><p>However, teens and twentysomethings today are of a very different demographic and have markedly different media consumption habits compared to Wikipedia\u2019s forebears. <a href=\"https://www.gwi.com/blog/gen-z-vs-gen-alpha\" target=\"_blank\">Gen Z and Gen Alpha</a> readers are accustomed to TikTok, <a href=\"https://spectrum.ieee.org/how-the-youtube-era-made-cloud-gaming-possible\" target=\"_blank\">YouTube</a>, and mobile-first visual media. Their impatience for Wikipedia\u2019s impenetrable walls of text, as any parent of kids of this age knows, arguably threatens the future of the internet\u2019s collaborative knowledge clearinghouse.</p><p>The Wikimedia Foundation knows this, too. <a href=\"https://wikimediafoundation.org/news/2025/11/10/in-the-ai-era-wikipedia-has-never-been-more-valuable/\" target=\"_blank\">Research has shown</a> that many readers today greatly value quick overviews of any article, before the reader considers whether to dive into the article\u2019s full text. </p><p>So last June, the Foundation launched a modest experiment they called \u201c<a href=\"https://en.wikipedia.org/wiki/Artificial_intelligence_in_Wikimedia_projects#Beginnings_of_generative_AI\" rel=\"noopener noreferrer\" target=\"_blank\">Simple Article Summaries</a>.\u201d The summaries consisted of AI-generated, simplified text at the top of complex articles. Summaries were clearly labeled as machine-generated and unverified, and they were available only to mobile users who opted in.</p><p>Even after all these precautions, however, the volunteer editor community barely gave the experiment time to begin. Editors shut down Simple Article Summaries within <a href=\"https://techcrunch.com/2025/06/11/wikipedia-pauses-ai-generated-summaries-pilot-after-editors-protest/\" rel=\"noopener noreferrer\" target=\"_blank\">a day</a> of its launch.</p><p>The response was fierce. Editors called the experiment a \u201cghastly idea\u201d and warned of \u201cimmediate and irreversible harm\u201d to Wikipedia\u2019s credibility.</p><p>Comments in the <a href=\"https://en.wikipedia.org/wiki/Wikipedia:Village_pump_(technical)/Archive_221\" rel=\"noopener noreferrer\" target=\"_blank\">village pump</a> (a community discussion page) ranged from blunt (\u201c<a href=\"https://www.404media.co/wikipedia-pauses-ai-summaries-after-editor-revolt/\" rel=\"noopener noreferrer\" target=\"_blank\">Yuck\u201d</a>) to alarmed, with contributors raising <a href=\"https://www.404media.co/wikipedia-pauses-ai-generated-summaries-after-editor-backlash/\" rel=\"noopener noreferrer\" target=\"_blank\">legitimate concerns</a> about AI hallucinations and the erosion of editorial oversight.</p><h3>Revisiting Wikipedia\u2019s Past Helps Reveal Its Future</h3><p>Last year\u2019s Simple Summaries storm, and sudden silencing, should be considered in light of historical context. Consider three other flashpoints from Wikipedia\u2019s past:</p><p>In 2013, the Foundation launched VisualEditor\u2014a \u201cwhat you see is what you get\u201d interface meant to make editing easier\u2014as the default for all newcomers. However, the interface often crashed, broke articles, and was so slow that experienced editors fled. After <a href=\"https://en.wikipedia.org/wiki/Wikipedia:VisualEditor/RFC\" rel=\"noopener noreferrer\" target=\"_blank\">protests erupted</a>, a Wikipedia administrator <a href=\"https://www.theregister.com/2013/09/25/wikipedia_peasants_revolt/\" rel=\"noopener noreferrer\" target=\"_blank\">overrode</a> the Foundation\u2019s rollout, returning VisualEditor to an opt-in feature.</p><p>The following year brought <a href=\"https://en.wikipedia.org/wiki/Wikipedia:Media_Viewer\" rel=\"noopener noreferrer\" target=\"_blank\">Media Viewer</a>, which changed how images were displayed. The community voted to disable it. Then, when an administrator implemented that consensus, a Foundation executive reversed the change and threatened to revoke the admin\u2019s privileges. On the German Wikipedia, the Foundation deployed a new \u201csuperprotect\u201d user right to prevent the community from turning off Media Viewer.</p><p>Even proposals that technically won majority support met resistance. In 2011, the Foundation held a referendum on an image filter that would let readers voluntarily hide graphic content. Despite <a href=\"https://meta.wikimedia.org/wiki/Image_filter_referendum/Sue's_report_to_the_board/en\" rel=\"noopener noreferrer\" target=\"_blank\">56 percent support</a>, the feature was shelved after the German Wikipedia community voted 86 percent against it.</p><p>These three controversies from Wikipedia\u2019s past reveal how genuine conversations can achieve\u2014after disagreements and controversy\u2014compromise and evolution of Wikipedia\u2019s features and formats. Reflexive vetoes of new experiments, as the Simple Summaries spat highlighted last summer, is not genuine conversation.</p><p>Supplementing Wikipedia\u2019s Encyclopedia Britannica\u2013style format with a small component that contains AI summaries is not a simple problem with a cut-and-dried answer, though neither were VisualEditor or Media Viewer.</p><p>Why did 2025\u2019s Wikipedia crisis result in immediate clampdown, whereas its internal crises from 2011\u20132014 found more community-based debates involving discussions and plebiscites? Is Wikipedia\u2019s global readership today witnessing the first signs of a dangerous generation gap?</p><h3>Wikipedia Needs to Air Its Sustainability Crisis</h3><p>A still deeper crisis haunts the online encyclopedia: the sustainability of unpaid labor. Wikipedia was built by volunteers who found meaning in collective knowledge creation. That model worked brilliantly when a generation of internet enthusiasts had time, energy, and idealism to spare. But the volunteer base is aging. A <a href=\"https://en.wikipedia.org/wiki/Wikipedia_community\" rel=\"noopener noreferrer\" target=\"_blank\">2010 study</a> found the average Wikipedia contributor was in their mid-twenties; today, many of those same editors are now in their forties or fifties.</p><p>Meanwhile, the tech industry has discovered how to extract billions in value from their work. AI companies train their large language models on Wikipedia\u2019s corpus. The <a href=\"https://wikimediafoundation.org/news/2025/11/10/in-the-ai-era-wikipedia-has-never-been-more-valuable/\" rel=\"noopener noreferrer\" target=\"_blank\">Wikimedia Foundation recently noted</a> it remains one of the highest-quality datasets in the world for AI development. <a href=\"https://www.nature.com/articles/s41586-024-07566-y\" rel=\"noopener noreferrer\" target=\"_blank\">Research confirms</a> that when developers try to omit Wikipedia from training data, their models produce answers that are less accurate, less diverse, and less verifiable.</p><p>The irony is stark. AI systems deliver answers derived from Wikipedia without sending users back to the source. Google\u2019s AI Overviews, <a href=\"https://spectrum.ieee.org/chatgpt-checking-sucks\" target=\"_blank\">ChatGPT</a>, and countless other tools have learned from Wikipedia\u2019s volunteer-created content\u2014then present that knowledge in ways that break the virtuous cycle Wikipedia depends on. Fewer readers visit the encyclopedia directly. Fewer visitors become editors. Fewer users donate. The pipeline that sustained Wikipedia for a quarter century is breaking down.</p><h3>What Does Wikipedia\u2019s Next 25 Years Look Like?</h3><p>The Simple Summaries situation arguably risks making the encyclopedia increasingly irrelevant to younger generations of readers. And they\u2019ll be relying on Wikipedia\u2019s information commons for the longest time frame of any cohort now editing or reading it.</p><p>On the other hand, a larger mandate does, of course, remain at Wikipedia to serve as stewards of the information commons. And wrongly implementing Simple Summaries could fail this ambitious objective. Which would be terrible, too. </p><p>All of which, frankly, are what open discussions and sometimes-messy referenda are all about: not just sudden shutdowns.</p><p>Meanwhile, AI systems should credit Wikipedia when drawing on its content, maintaining the transparency that builds public trust. Companies profiting from Wikipedia\u2019s corpus should pay for access through legitimate channels like Wikimedia Enterprise, rather than scraping servers or relying on data dumps that strain infrastructure without contributing to maintenance.</p><p>Perhaps as the AI marketplace matures, there could be room for new large language models trained exclusively on trustworthy Wikimedia data\u2014transparent, verifiable, and <a href=\"https://arxiv.org/abs/2305.14292\" rel=\"noopener noreferrer\" target=\"_blank\">free from the pollution of synthetic AI-generated content</a>. Perhaps, too, Creative Commons licenses need <a href=\"https://www.jipitec.eu/jipitec/article/view/415\" rel=\"noopener noreferrer\" target=\"_blank\">updating to account for AI-era realities</a>.</p><p>Perhaps Wikipedia itself needs new modalities for creating and sharing knowledge\u2014ones that preserve editorial rigor while meeting audiences where they are.</p><p>Wikipedia has survived edit wars, vandalism campaigns, and <a href=\"https://en.wikipedia.org/wiki/Predictions_of_the_end_of_Wikipedia\" target=\"_blank\">countless predictions of its demise</a>. It has patiently outlived the <a href=\"https://academic.oup.com/gigascience/article/8/12/giz139/5651107\" rel=\"noopener noreferrer\" target=\"_blank\">skeptics who dismissed it as unreliable</a>. It has proven that strangers can collaborate to build something remarkable.</p><p>But Wikipedia cannot survive by refusing to change. Ostrom\u2019s Nobel Prize\u2013winning research reminds us that the communities that govern shared resources often grow conservative over time.</p><p>For anyone who cares about the future of reliable information online, Wikipedia\u2019s 25th anniversary is not just a celebration. It is an urgent warning about what happens when the institutions we depend on cannot adapt to the people they are meant to serve.</p><p><em>Dariusz Jemielniak is vice president of the </em><em><a href=\"https://pan.pl/en/\" target=\"_blank\">Polish Academy of Sciences</a></em><em>, a full professor at </em><em><a href=\"https://www.kozminski.edu.pl/en\" target=\"_blank\">Kozminski University</a></em><em> in Warsaw, and a faculty associate at the </em><em><a href=\"https://cyber.harvard.edu/\" target=\"_blank\">Berkman Klein Center for Internet and Society</a></em><em> at Harvard University. He served for a decade on the </em><em><a href=\"https://meta.wikimedia.org/wiki/Wikimedia_Foundation/Board_of_Trustees\" target=\"_blank\">Wikimedia Foundation Board of Trustees</a></em><em> and is the author of</em> <a href=\"https://www.sup.org/books/sociology/common-knowledge\" target=\"_blank\">Common Knowledge? An Ethnography of Wikipedia</a> <em>(Stanford University Press).</em></p>", "url": "https://spectrum.ieee.org/wikipedia-at-25", "published_at": "Fri, 30 Ja", "source_type": "rss", "credibility_tier": "A", "theme_tags": ["governance"], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/illustration-of-the-wikipedia-logo-in-a-glass-case-on-display-with-a-placard-that-says-wikipedia-2001.jpg?id=63148696&amp;width=1200&amp;height=800&amp;coordinates=156%2C0%2C156%2C0\" /><br /><br /><p><span>Wikipedia celebrates its 25th anniversary th"]}
{"id": "source:rss:1426523236", "title": "How Clean-Energy Firms Adapt Messaging in the Trump Era", "summary": "<img src=\"https://spectrum.ieee.org/media-library/bird-s-eye-view-of-a-geothermal-drilling-plant.jpg?id=63340009&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><span>As the Trump administration doubles down on its energy and AI dominance agenda, U.S. energy companies have found themselves navigating tricky communication strategies. Touting the clean, carbon-free nature of renewable energy no longer carries the clout it did under the Biden administration</span><strong>, </strong>and policy has shifted against certain forms of renewables<span>. At the same time, energy companies </span>are being called upon to meet <a href=\"https://spectrum.ieee.org/nuclear-powered-data-center\" target=\"_self\">rising power demands of data-center developers</a><span>, many of which are prioritizing carbon-free options.</span></p><p>This has forced energy companies to shift the way they communicate: They must garner political favor while also positioning themselves as an answer to the coming onslaught of electricity demand.</p><p>The wind and solar industries are focusing on electricity affordability and the fact that wind farms and photovoltaics are the cheapest and fastest way to add new energy generation. Battery storage developers are aligning themselves with Trump\u2019s domestic manufacturing push, <a href=\"https://www.latitudemedia.com/news/the-unexpected-clean-energy-winner-of-2025-energy-storage/\" target=\"_blank\"><span>scaling up efforts</span></a> to shift supply chains to the United States as they <a href=\"https://www.canarymedia.com/articles/politics/the-great-climate-vibe-shift-of-2025\" target=\"_blank\"><span>battle uncertainty</span></a> over tariffs.</p><p>Nuclear power companies are touting their ability to go small and modular\u2014<a href=\"https://spectrum.ieee.org/nuclear-powered-data-center\" target=\"_blank\">theoretically a faster way to get reactors running</a>. Next-generation geothermal developers are staying the course but playing up the industry\u2019s crossovers with oil and gas. Hydrogen, too, is being highlighted as similar to fossil fuels. And the offshore wind industry is mostly preoccupied with <span><a href=\"https://www.politico.com/news/2026/01/18/trump-offshore-wind-problems-00734850\" target=\"_blank\">using the courts</a></span> to fight the Trump administration\u2019s repeated attempts to ban development.</p><p>It\u2019s not that the renewable technologies themselves have changed, says <a href=\"https://www.linkedin.com/in/samuelefurfari/?originalSubdomain=be\" target=\"_blank\"><span>Samuel Furfari</span></a>, former European Commission senior energy official and current energy geopolitics professor at ESCP Business School in London. \u201cMr. Trump has made a communication revolution, not an energy revolution,\u201d he says about the state of the industry in the United States and abroad.</p><h2>Trump Declares His Energy Darlings <em></em></h2><p>Trump\u2019s affinity for fossil fuels and his disdain for certain renewables, such as wind, have constructed a new federal hierarchy of energy sources. On day one of his second term as U.S. president, Trump issued an <a href=\"https://www.whitehouse.gov/presidential-actions/2025/01/declaring-a-national-energy-emergency/\" target=\"_blank\"><span>executive order</span></a> listing which energy resources his country should promote. The list mentions fossil fuels, geothermal, and nuclear but excludes solar, wind, and hydrogen.</p><p>Then, in July, the One Big Beautiful Bill Act slashed renewable energy incentives for wind and solar while <a href=\"https://spectrum.ieee.org/geothermal-energy-big-beautiful-bill\" target=\"_blank\">extending the tax credits for geothermal</a> through 2033. On 1 December, Trump\u2019s Department of Energy <a href=\"https://www.nrel.gov/news/detail/press/2025/news-release-energy-department-renames-nrel-'national-lab-of-the-rockies'\" target=\"_blank\"><span>renamed</span></a> the National Renewable Energy Laboratory to the National Laboratory of the Rockies\u2014a moniker to demote renewables and reflect the lab\u2019s \u201cexpanding mission\u201d under Trump. And in an eleventh-hour move, the Department of the Interior at the end of 2025 <a href=\"https://www.politico.com/news/2025/12/22/interior-pauses-construction-of-all-offshore-wind-projects-citing-national-security-concerns-00702593\" target=\"_blank\"><span>halted</span></a> all offshore wind projects under construction, citing national security risks.</p><p>At first, the wind and solar industries attempted to fit into the Trump administration\u2019s agenda by leaning into his energy dominance rhetoric, says clean energy consultant  <a href=\"https://greencapitol.net/team\" target=\"_blank\"><span>Lloyd Ritter in Washington D.C.</span></a> But after the government gutted tax incentives for wind and solar, and concerns over high electricity bills became a top election issue, industry players <span>prioritized </span> messaging <span>about </span> affordability for consumers, Ritter says.</p><p>\u201cElectricity costs are now a thing in politics, and I don\u2019t think that\u2019s going to change anytime soon,\u201d Ritter says. The cost concerns stem from estimates that electricity use in the United States is projected to increase 32 percent by 2030,  mostly from data centers, according to the latest <a href=\"https://gridstrategiesllc.com/wp-content/uploads/Grid-Strategies-National-Load-Growth-Report-2025.pdf\" target=\"_blank\"><span>forecast</span></a> from Grid Strategies.</p><p>The solar and storage industries are welcoming these demand projections. That\u2019s because solar is still the \u201cfastest and cheapest form of electronics to get onto the grid,\u201d says <a href=\"https://cleantx.org/raina-hornaday\" target=\"_blank\"><span>Raina Hornaday</span></a>, cofounder of Austin, Texas\u2013based <a href=\"https://caprockrenewables.com/\" target=\"_blank\"><span>Caprock Renewables</span></a>, a solar and storage developer. In her view, meeting the load demands of data centers is going to take care of the political backlash that solar and storage have endured under the Trump administration.</p><p>Hornaday sees a particular opening for batteries. \u201cThe R&amp;D for battery storage is really the winner across the board, and we don\u2019t consider battery storage renewable. It can utilize renewable energy electrons, but it doesn\u2019t have to,\u201d she says. \u201cIt can be power from the grid.\u201d</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Storage pond at a geothermal power plant.\" class=\"rm-shortcode\" id=\"7c045\" src=\"https://spectrum.ieee.org/media-library/storage-pond-at-a-geothermal-power-plant.jpg?id=63340114&amp;width=980\" /> <small class=\"image-media media-caption\">Sage Geosystems harvests heat from underground water reservoirs. The company has recently shifted from talking about geothermal energy as clean to its ability to get electricity to the grid faster to accommodate data-center growth. </small><small class=\"image-media media-photo-credit\">Sage Geosystems</small></p><h2>Geothermal Inherits Fortuitous Position </h2><p>The communications framing for next-generation geothermal power has shifted too, despite it being a political favorite. Companies in this sector say they are continuing to emphasize geothermal as a baseload power source\u2014something that can crank out electricity 24/7, like fossil fuels can. But projected increases in power demand have shifted other elements of the conversation.</p><p>The leading communication strategies now are less about geothermal\u2019s carbon-free benefits and more about getting energy to the grid faster to address data-center growth, says <a href=\"https://www.linkedin.com/in/cindy-d-taff-53b77a57/\" target=\"_blank\"><span>Cindy Taff</span></a>, CEO of Houston-based startup <a href=\"https://www.sagegeosystems.com/\" target=\"_blank\"><span>Sage Geosystems</span></a>. Geothermal companies are <span>also </span>talking about <span>how </span>their use of drilling technology, know-how, and other synergies borrowed from the oil and gas industries can fast-track development.</p><p>\u201cWhen we first started Sage four and a half years ago, we were talking about it being clean and renewable, but if you think about it, there\u2019s now a little bit more allergic connotation with clean and renewable,\u201d says Taff, who spent more than 35 years in well construction and project management at Shell before founding Sage.</p><p>Lessening the use of climate-focused language is something \u201cthe whole industry\u201d is doing, adds  <a href=\"https://www.linkedin.com/in/geoffgarrison/\" target=\"_blank\"><span>Geoffrey Garrison</span></a>, vice president of operations at  <a href=\"https://www.quaise.com/\" target=\"_blank\"><span>Quaise Energy</span></a>, headquartered in Houston. \u201cI think you have to be cognizant of who\u2019s listening and who has got their hands on the lever.\u2026 You tailor your message,\u201d he says.</p><p>Other Trump administration priorities, like <span>moving industry and manufacturing back to U.S. soil, </span>are top of mind for geothermal companies, says <a href=\"https://www.linkedin.com/in/sarah-jewett-10b0732a/\" target=\"_blank\"><span>Sarah Jewett</span></a>, senior vice president of strategy at  <a href=\"https://fervoenergy.com/\" target=\"_blank\"><span>Fervo Energy</span></a>, also in Houston. \u201cWe are thinking a lot more about localization of [the] supply chain, in large part due to this administration\u2019s focus,\u201d Jewett says.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" style=\"float: left;\"> <img alt=\"A geothermal drilling rig in a snowy prairie, with a large mountain range in the background.\" class=\"rm-shortcode\" id=\"d5e4e\" src=\"https://spectrum.ieee.org/media-library/a-geothermal-drilling-rig-in-a-snowy-prairie-with-a-large-mountain-range-in-the-background.jpg?id=63340089&amp;width=980\" /> <small class=\"image-media media-caption\">In its pitches to investors, Fervo Energy includes talking points about how geothermal energy drilling uses technology from the oil and gas industry.  </small><small class=\"image-media media-photo-credit\">Fervo Energy</small></p><p>Overall, Fervo\u2019s messaging has remained \u201cpretty consistent\u201d between U.S. presidential administrations, Jewett says. In its pitch to investors, Fervo includes talking points about how next-generation geothermal uses drilling technology from the oil and gas industry. But clean energy isn\u2019t completely missing from Fervo\u2019s communications. \u201cSome sides of the aisle like parts of it, and other parts of the aisle like other parts of it,\u201d Jewett says.</p><p>Like geothermal, nuclear power has enjoyed support from both political parties in the United States. It too is now focusing on touting its ability to meet rising electricity demand, albeit through the <a href=\"https://spectrum.ieee.org/three-mile-island\" target=\"_self\"><span>restarting of decommissioned reactors</span></a>, the <a href=\"https://spectrum.ieee.org/80-billion-us-nuclear-power\" target=\"_self\"><span>building of massive new plants</span></a>, and experimentation with advanced solutions such as <a href=\"https://spectrum.ieee.org/small-modular-reactor-united-states\" target=\"_self\"><span>small modular reactors</span></a> and <a href=\"https://spectrum.ieee.org/microreactor\" target=\"_self\"><span>microreactors</span></a>.</p><h2> Countries Adopt \u2018Energy Addition\u2019 Tack</h2><p>It\u2019s not just U.S. companies that are shifting the message. In November at ADIPEC, the world\u2019s largest annual energy conference, held in Abu Dhabi, widely adopted buzzwords such as \u201cenergy transition\u201d\u2014a term referring to the shift away from fossil fuels\u2014were being swapped with \u201cenergy addition.\u201d</p><p>That\u2019s not solely a result in shifting political tides. The surge in energy demand may indeed necessitate more of an addition<span>, rather than a complete transition</span>. It\u2019s a reasonable shift, given the \u201chockey stick\u201d demand increase the industry is facing, says Taff at Sage. \u201cEnergy transition was, in my opinion, when [demand] uptick was very steady. But now that you\u2019ve got the hockey stick, the use of \u2018addition\u2019\u2026is much more applicable,\u201d she says.</p><p>Abroad, <span>Trump\u2019s impact reverberates,  </span> Furfari says. \u201cWe were shy to mention fossil fuel. Mr. Trump does not care, and says, \u2018No, we need fossil fuel.\u2019 This is changing the world.\u201d</p>", "url": "https://spectrum.ieee.org/trump-renewable-energy", "published_at": "Wed, 28 Ja", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/bird-s-eye-view-of-a-geothermal-drilling-plant.jpg?id=63340009&amp;width=1200&amp;height=800&amp;coordinates=0%2C83%2C0%2C84\" /><br /><br /><p><span>As the Trump administration doubles down on its energy and AI dominance agenda, U.S. energy companies"]}
{"id": "source:rss:5684812343", "title": "Andrew Ng: Unbiggen AI", "summary": "<img src=\"https://spectrum.ieee.org/media-library/andrew-ng-listens-during-the-power-of-data-sooner-than-you-think-global-technology-conference-in-brooklyn-new-york-on-wednes.jpg?id=29206806&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C0%2C210\" /><br /><br /><p><strong><a href=\"https://en.wikipedia.org/wiki/Andrew_Ng\" rel=\"noopener noreferrer\" target=\"_blank\">Andrew Ng</a> has serious street cred</strong> in artificial intelligence. He pioneered the use of graphics processing units (GPUs) to train deep learning models in the late 2000s with his students at <a href=\"https://stanfordmlgroup.github.io/\" rel=\"noopener noreferrer\" target=\"_blank\">Stanford University</a>, cofounded <a href=\"https://research.google/teams/brain/\" rel=\"noopener noreferrer\" target=\"_blank\">Google Brain</a> in 2011, and then served for three years as chief scientist for <a href=\"https://ir.baidu.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Baidu</a>, where he helped build the Chinese tech giant\u2019s AI group. So when he says he has identified the next big shift in artificial intelligence, people listen. And that\u2019s what he told <em>IEEE Spectrum</em> in an exclusive Q&amp;A.</p><hr /><p> \tNg\u2019s current efforts are focused on his company  \t<a href=\"https://landing.ai/about/\" rel=\"noopener noreferrer\" target=\"_blank\">Landing AI</a>, which built a platform called LandingLens to help manufacturers improve visual inspection with computer vision. He has also become something of an evangelist for what he calls the <a href=\"https://www.youtube.com/watch?v=06-AZXmwHjo\" target=\"_blank\">data-centric AI movement</a>, which he says can yield \u201csmall data\u201d solutions to big issues in AI, including model efficiency, accuracy, and bias. </p><p> \tAndrew Ng on... </p><ul> <li><a href=\"https://spectrum.ieee.org/feeds/feed.rss#big\">What\u2019s next for really big models</a></li> <li><a href=\"https://spectrum.ieee.org/feeds/feed.rss#career\">The career advice he didn\u2019t listen to</a></li> <li><a href=\"https://spectrum.ieee.org/feeds/feed.rss#defining\">Defining the data-centric AI movement</a></li> <li><a href=\"https://spectrum.ieee.org/feeds/feed.rss#synthetic\">Synthetic data</a></li> <li><a href=\"https://spectrum.ieee.org/feeds/feed.rss#work\">Why Landing AI asks its customers to do the work</a></li> </ul><p> <strong>The great advances in deep learning over the past decade or so have been powered by ever-bigger models crunching ever-bigger amounts of data. Some people argue that that\u2019s an <a href=\"https://spectrum.ieee.org/deep-learning-computational-cost\" target=\"_self\">unsustainable trajectory</a>. Do you agree that it can\u2019t go on that way?</strong> </p><p> <strong>Andrew Ng: </strong>This is a big question. We\u2019ve seen foundation models in NLP [natural language processing]. I\u2019m excited about NLP models getting even bigger, and also about the potential of building foundation models in computer vision. I think there\u2019s lots of signal to still be exploited in video: We have not been able to build foundation models yet for video because of compute bandwidth and the cost of processing video, as opposed to tokenized text. So I think that this engine of scaling up deep learning algorithms, which has been running for something like 15 years now, still has steam in it. Having said that, it only applies to certain problems, and there\u2019s a set of other problems that need small data solutions. </p><p> <strong>When you say you want a foundation model for computer vision, what do you mean by that?</strong> </p><p> <strong>Ng:</strong> This is a term coined by <a href=\"https://cs.stanford.edu/~pliang/\" rel=\"noopener noreferrer\" target=\"_blank\">Percy Liang</a> and <a href=\"https://crfm.stanford.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">some of my friends at Stanford</a> to refer to very large models, trained on very large data sets, that can be tuned for specific applications. For example, <a href=\"https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business\" target=\"_self\">GPT-3</a> is an example of a foundation model [for NLP]. Foundation models offer a lot of promise as a new paradigm in developing machine learning applications, but also challenges in terms of making sure that they\u2019re reasonably fair and free from bias, especially if many of us will be building on top of them. </p><p> <strong>What needs to happen for someone to build a foundation model for video?</strong> </p><p> <strong>Ng:</strong> I think there is a scalability problem. The compute power needed to process the large volume of images for video is significant, and I think that\u2019s why foundation models have arisen first in NLP. Many researchers are working on this, and I think we\u2019re seeing early signs of such models being developed in computer vision. But I\u2019m confident that if a semiconductor maker gave us 10 times more processor power, we could easily find 10 times more video to build such models for vision. </p><p> \tHaving said that, a lot of what\u2019s happened over the past decade is that deep learning has happened in consumer-facing companies that have large user bases, sometimes billions of users, and therefore very large data sets. While that paradigm of machine learning has driven a lot of economic value in consumer software, I find that that recipe of scale doesn\u2019t work for other industries. </p><p> <a href=\"https://spectrum.ieee.org/feeds/feed.rss#top\">Back to top</a> </p><p> <strong>It\u2019s funny to hear you say that, because your early work was at a consumer-facing company with millions of users.</strong> </p><p> <strong>Ng: </strong>Over a decade ago, when I proposed starting the <a href=\"https://research.google/teams/brain/\" rel=\"noopener noreferrer\" target=\"_blank\">Google Brain</a> project to use Google\u2019s compute infrastructure to build very large neural networks, it was a controversial step. One very senior person pulled me aside and warned me that starting Google Brain would be bad for my career. I think he felt that the action couldn\u2019t just be in scaling up, and that I should instead focus on architecture innovation. </p><p class=\"pull-quote\"> \t\u201cIn many industries where giant data sets simply don\u2019t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.\u201d<br /> \t\u2014Andrew Ng, CEO & Founder, Landing AI </p><p> \tI remember when my students and I published the first  \t<a href=\"https://nips.cc/\" rel=\"noopener noreferrer\" target=\"_blank\">NeurIPS</a> workshop paper advocating using <a href=\"https://developer.nvidia.com/cuda-zone\" rel=\"noopener noreferrer\" target=\"_blank\">CUDA</a>, a platform for processing on GPUs, for deep learning\u2014a different senior person in AI sat me down and said, \u201cCUDA is really complicated to program. As a programming paradigm, this seems like too much work.\u201d I did manage to convince him; the other person I did not convince. </p><p> <strong>I expect they\u2019re both convinced now.</strong> </p><p> <strong>Ng:</strong> I think so, yes. </p><p> \tOver the past year as I\u2019ve been speaking to people about the data-centric AI movement, I\u2019ve been getting flashbacks to when I was speaking to people about deep learning and scalability 10 or 15 years ago. In the past year, I\u2019ve been getting the same mix of \u201cthere\u2019s nothing new here\u201d and \u201cthis seems like the wrong direction.\u201d </p><p> <a href=\"https://spectrum.ieee.org/feeds/feed.rss#top\">Back to top</a> </p><p> <strong>How do you define data-centric AI, and why do you consider it a movement?</strong> </p><p> <strong>Ng:</strong> Data-centric AI is the discipline of systematically engineering the data needed to successfully build an AI system. For an AI system, you have to implement some algorithm, say a neural network, in code and then train it on your data set. The dominant paradigm over the last decade was to download the data set while you focus on improving the code. Thanks to that paradigm, over the last decade deep learning networks have improved significantly, to the point where for a lot of applications the code\u2014the neural network architecture\u2014is basically a solved problem. So for many practical applications, it\u2019s now more productive to hold the neural network architecture fixed, and instead find ways to improve the data. </p><p> \tWhen I started speaking about this, there were many practitioners who, completely appropriately, raised their hands and said, \u201cYes, we\u2019ve been doing this for 20 years.\u201d This is the time to take the things that some individuals have been doing intuitively and make it a systematic engineering discipline. </p><p> \tThe data-centric AI movement is much bigger than one company or group of researchers. My collaborators and I organized a  \t<a href=\"https://neurips.cc/virtual/2021/workshop/21860\" rel=\"noopener noreferrer\" target=\"_blank\">data-centric AI workshop at NeurIPS</a>, and I was really delighted at the number of authors and presenters that showed up. </p><p> <strong>You often talk about companies or institutions that have only a small amount of data to work with. How can data-centric AI help them?</strong> </p><p> <strong>Ng: </strong>You hear a lot about vision systems built with millions of images\u2014I once built a face recognition system using 350 million images. Architectures built for hundreds of millions of images don\u2019t work with only 50 images. But it turns out, if you have 50 really good examples, you can build something valuable, like a defect-inspection system. In many industries where giant data sets simply don\u2019t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn. </p><p> <strong>When you talk about training a model with just 50 images, does that really mean you\u2019re taking an existing model that was trained on a very large data set and fine-tuning it? Or do you mean a brand new model that\u2019s designed to learn only from that small data set?</strong> </p><p> <strong>Ng: </strong>Let me describe what Landing AI does. When doing visual inspection for manufacturers, we often use our own flavor of <a href=\"https://developers.arcgis.com/python/guide/how-retinanet-works/\" rel=\"noopener noreferrer\" target=\"_blank\">RetinaNet</a>. It is a pretrained model. Having said that, the pretraining is a small piece of the puzzle. What\u2019s a bigger piece of the puzzle is providing tools that enable the manufacturer to pick the right set of images [to use for fine-tuning] and label them in a consistent way. There\u2019s a very practical problem we\u2019ve seen spanning vision, NLP, and speech, where even human annotators don\u2019t agree on the appropriate label. For big data applications, the common response has been: If the data is noisy, let\u2019s just get a lot of data and the algorithm will average over it. But if you can develop tools that flag where the data\u2019s inconsistent and give you a very targeted way to improve the consistency of the data, that turns out to be a more efficient way to get a high-performing system. </p><p class=\"pull-quote\"> \t\u201cCollecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.\u201d<br /> \t\u2014Andrew Ng </p><p> \tFor example, if you have 10,000 images where 30 images are of one class, and those 30 images are labeled inconsistently, one of the things we do is build tools to draw your attention to the subset of data that\u2019s inconsistent. So you can very quickly relabel those images to be more consistent, and this leads to improvement in performance. </p><p> <strong>Could this focus on high-quality data help with bias in data sets? If you\u2019re able to curate the data more before training?</strong> </p><p> <strong>Ng:</strong> Very much so. Many researchers have pointed out that biased data is one factor among many leading to biased systems. There have been many thoughtful efforts to engineer the data. At the NeurIPS workshop, <a href=\"https://www.cs.princeton.edu/~olgarus/\" rel=\"noopener noreferrer\" target=\"_blank\">Olga Russakovsky</a> gave a really nice talk on this. At the main NeurIPS conference, I also really enjoyed <a href=\"https://neurips.cc/virtual/2021/invited-talk/22281\" rel=\"noopener noreferrer\" target=\"_blank\">Mary Gray\u2019s presentation,</a> which touched on how data-centric AI is one piece of the solution, but not the entire solution. New tools like <a href=\"https://www.microsoft.com/en-us/research/project/datasheets-for-datasets/\" rel=\"noopener noreferrer\" target=\"_blank\">Datasheets for Datasets</a> also seem like an important piece of the puzzle. </p><p> \tOne of the powerful tools that data-centric AI gives us is the ability to engineer a subset of the data. Imagine training a machine-learning system and finding that its performance is okay for most of the data set, but its performance is biased for just a subset of the data. If you try to change the whole neural network architecture to improve the performance on just that subset, it\u2019s quite difficult. But if you can engineer a subset of the data you can address the problem in a much more targeted way. </p><p> <strong>When you talk about engineering the data, what do you mean exactly?</strong> </p><p> <strong>Ng: </strong>In AI, data cleaning is important, but the way the data has been cleaned has often been in very manual ways. In computer vision, someone may visualize images through a <a href=\"https://jupyter.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Jupyter notebook</a> and maybe spot the problem, and maybe fix it. But I\u2019m excited about tools that allow you to have a very large data set, tools that draw your attention quickly and efficiently to the subset of data where, say, the labels are noisy. Or to quickly bring your attention to the one class among 100 classes where it would benefit you to collect more data. Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity. </p><p> \tFor example, I once figured out that a speech-recognition system was performing poorly when there was car noise in the background. Knowing that allowed me to collect more data with car noise in the background, rather than trying to collect more data for everything, which would have been expensive and slow. </p><p> <a href=\"https://spectrum.ieee.org/feeds/feed.rss#top\">Back to top</a> </p><p> <strong>What about using synthetic data, is that often a good solution?</strong> </p><p> <strong>Ng: </strong>I think synthetic data is an important tool in the tool chest of data-centric AI. At the NeurIPS workshop, <a href=\"https://tensorlab.cms.caltech.edu/users/anima/\" rel=\"noopener noreferrer\" target=\"_blank\">Anima Anandkumar</a> gave a great talk that touched on synthetic data. I think there are important uses of synthetic data that go beyond just being a preprocessing step for increasing the data set for a learning algorithm. I\u2019d love to see more tools to let developers use synthetic data generation as part of the closed loop of iterative machine learning development. </p><p> <strong>Do you mean that synthetic data would allow you to try the model on more data sets?</strong> </p><p> <strong>Ng: </strong>Not really. Here\u2019s an example. Let\u2019s say you\u2019re trying to detect defects in a smartphone casing. There are many different types of defects on smartphones. It could be a scratch, a dent, pit marks, discoloration of the material, other types of blemishes. If you train the model and then find through error analysis that it\u2019s doing well overall but it\u2019s performing poorly on pit marks, then synthetic data generation allows you to address the problem in a more targeted way. You could generate more data just for the pit-mark category. </p><p class=\"pull-quote\"> \t\u201cIn the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models.\u201d<br /> \t\u2014Andrew Ng </p><p> \tSynthetic data generation is a very powerful tool, but there are many simpler tools that I will often try first. Such as data augmentation, improving labeling consistency, or just asking a factory to collect more data. </p><p> <a href=\"https://spectrum.ieee.org/feeds/feed.rss#top\">Back to top</a> </p><p> <strong>To make these issues more concrete, can you walk me through an example? When a company approaches <a href=\"https://landing.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Landing AI</a> and says it has a problem with visual inspection, how do you onboard them and work toward deployment?</strong> </p><p> <strong>Ng: </strong>When a customer approaches us we usually have a conversation about their inspection problem and look at a few images to verify that the problem is feasible with computer vision. Assuming it is, we ask them to upload the data to the <a href=\"https://landing.ai/platform/\" rel=\"noopener noreferrer\" target=\"_blank\">LandingLens</a> platform. We often advise them on the methodology of data-centric AI and help them label the data. </p><p> \tOne of the foci of Landing AI is to empower manufacturing companies to do the machine learning work themselves. A lot of our work is making sure the software is fast and easy to use. Through the iterative process of machine learning development, we advise customers on things like how to train models on the platform, when and how to improve the labeling of data so the performance of the model improves. Our training and software supports them all the way through deploying the trained model to an edge device in the factory. </p><p> <strong>How do you deal with changing needs? If products change or lighting conditions change in the factory, can the model keep up?</strong> </p><p> <strong>Ng:</strong> It varies by manufacturer. There is data drift in many contexts. But there are some manufacturers that have been running the same manufacturing line for 20 years now with few changes, so they don\u2019t expect changes in the next five years. Those stable environments make things easier. For other manufacturers, we provide tools to flag when there\u2019s a significant data-drift issue. I find it really important to empower manufacturing customers to correct data, retrain, and update the model. Because if something changes and it\u2019s 3 a.m. in the United States, I want them to be able to adapt their learning algorithm right away to maintain operations. </p><p> \tIn the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models. The challenge is, how do you do that without Landing AI having to hire 10,000 machine learning specialists? </p><p> <strong>So you\u2019re saying that to make it scale, you have to empower customers to do a lot of the training and other work.</strong> </p><p> <strong>Ng: </strong>Yes, exactly! This is an industry-wide problem in AI, not just in manufacturing. Look at health care. Every hospital has its own slightly different format for electronic health records. How can every hospital train its own custom AI model? Expecting every hospital\u2019s IT personnel to invent new neural-network architectures is unrealistic. The only way out of this dilemma is to build tools that empower the customers to build their own models by giving them tools to engineer the data and express their domain knowledge. That\u2019s what Landing AI is executing in computer vision, and the field of AI needs other teams to execute this in other domains. </p><p> <strong>Is there anything else you think it\u2019s important for people to understand about the work you\u2019re doing or the data-centric AI movement?</strong> </p><p> <strong>Ng: </strong>In the last decade, the biggest shift in AI was a shift to deep learning. I think it\u2019s quite possible that in this decade the biggest shift will be to data-centric AI. With the maturity of today\u2019s neural network architectures, I think for a lot of the practical applications the bottleneck will be whether we can efficiently get the data we need to develop systems that work well. The data-centric AI movement has tremendous energy and momentum across the whole community. I hope more researchers and developers will jump in and work on it. </p><p> <a href=\"https://spectrum.ieee.org/feeds/feed.rss#top\">Back to top</a> </p><p><em>This article appears in the April 2022 print issue as \u201cAndrew Ng, AI Minimalist</em><em>.\u201d</em></p>", "url": "https://spectrum.ieee.org/andrew-ng-data-centric-ai", "published_at": "Wed, 09 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/andrew-ng-listens-during-the-power-of-data-sooner-than-you-think-global-technology-conference-in-brooklyn-new-york-on-wednes.jpg?id=29206806&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C0%2C210\" /><br /><br /><p><strong><a href=\"https://en.w"]}
{"id": "source:rss:5836994923", "title": "How AI Will Change Chip Design", "summary": "<img src=\"https://spectrum.ieee.org/media-library/layered-rendering-of-colorful-semiconductor-wafers-with-a-bright-white-light-sitting-on-one.jpg?id=29285079&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C0%2C0\" /><br /><br /><p>The end of <a href=\"https://spectrum.ieee.org/on-beyond-moores-law-4-new-laws-of-computing\" target=\"_self\">Moore\u2019s Law</a> is looming. Engineers and designers can do only so much to <a href=\"https://spectrum.ieee.org/ibm-introduces-the-worlds-first-2nm-node-chip\" target=\"_self\">miniaturize transistors</a> and <a href=\"https://spectrum.ieee.org/cerebras-giant-ai-chip-now-has-a-trillions-more-transistors\" target=\"_self\">pack as many of them as possible into chips</a>. So they\u2019re turning to other approaches to chip design, incorporating technologies like AI into the process.</p><p>Samsung, for instance, is <a href=\"https://spectrum.ieee.org/processing-in-dram-accelerates-ai\" target=\"_self\">adding AI to its memory chips</a> to enable processing in memory, thereby saving energy and speeding up machine learning. Speaking of speed, Google\u2019s TPU V4 AI chip has <a href=\"https://spectrum.ieee.org/heres-how-googles-tpu-v4-ai-chip-stacked-up-in-training-tests\" target=\"_self\">doubled its processing power</a> compared with that of  its previous version.</p><p>But AI holds still more promise and potential for the semiconductor industry. To better understand how AI is set to revolutionize chip design, we spoke with <a href=\"https://www.linkedin.com/in/heather-gorr-phd\" rel=\"noopener noreferrer\" target=\"_blank\">Heather Gorr</a>, senior product manager for <a href=\"https://www.mathworks.com/\" rel=\"noopener noreferrer\" target=\"_blank\">MathWorks</a>\u2019 MATLAB platform.</p><p><strong>How is AI currently being used to design the next generation of chips?</strong></p><p><strong>Heather Gorr:</strong> AI is such an important technology because it\u2019s involved in most parts of the cycle, including the design and manufacturing process. There\u2019s a lot of important applications here, even in the general process engineering where we want to optimize things. I think defect detection is a big one at all phases of the process, especially in manufacturing. But even thinking ahead in the design process, [AI now plays a significant role] when you\u2019re designing the light and the sensors and all the different components. There\u2019s a lot of anomaly detection and fault mitigation that you really want to consider.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" style=\"float: left;\"> <img alt=\"Portrait of a woman with blonde-red hair smiling at the camera\" class=\"rm-shortcode rm-resized-image\" id=\"2dc00\" src=\"https://spectrum.ieee.org/media-library/portrait-of-a-woman-with-blonde-red-hair-smiling-at-the-camera.jpg?id=29288554&amp;width=980\" /> <small class=\"image-media media-caption\">Heather Gorr</small><small class=\"image-media media-photo-credit\">MathWorks</small></p><p>Then, thinking about the logistical modeling that you see in any industry, there is always planned downtime that you want to mitigate; but you also end up having unplanned downtime. So, looking back at that historical data of when you\u2019ve had those moments where maybe it took a bit longer than expected to manufacture something, you can take a look at all of that data and use AI to try to identify the proximate cause or to see  something that might jump out even in the processing and design phases. We think of AI oftentimes as a predictive tool, or as a robot doing something, but a lot of times you get a lot of insight from the data through AI.</p><p><strong>What are the benefits of using AI for chip design?</strong></p><p><strong>Gorr:</strong> Historically, we\u2019ve seen a lot of physics-based modeling, which is a very intensive process. We want to do a <a href=\"https://en.wikipedia.org/wiki/Model_order_reduction\" rel=\"noopener noreferrer\" target=\"_blank\">reduced order model</a>, where instead of solving such a computationally expensive and extensive model, we can do something a little cheaper. You could create a surrogate model, so to speak, of that physics-based model, use the data, and then do your <a href=\"https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html\" rel=\"noopener noreferrer\" target=\"_blank\">parameter sweeps</a>, your optimizations, your <a href=\"https://www.ibm.com/cloud/learn/monte-carlo-simulation\" rel=\"noopener noreferrer\" target=\"_blank\">Monte Carlo simulations</a> using the surrogate model. That takes a lot less time computationally than solving the physics-based equations directly. So, we\u2019re seeing that benefit in many ways, including the efficiency and economy that are the results of iterating quickly on the experiments and the simulations that will really help in the design.</p><p><strong>So it\u2019s like having a digital twin in a sense?</strong></p><p><strong>Gorr:</strong> Exactly. That\u2019s pretty much what people are doing, where you have the physical system model and the experimental data. Then, in conjunction, you have this other model that you could tweak and tune and try different parameters and experiments that let sweep through all of those different situations and come up with a better design in the end.</p><p><strong>So, it\u2019s going to be more efficient and, as you said, cheaper?</strong></p><p><strong>Gorr:</strong> Yeah, definitely. Especially in the experimentation and design phases, where you\u2019re trying different things. That\u2019s obviously going to yield dramatic cost savings if you\u2019re actually manufacturing and producing [the chips]. You want to simulate, test, experiment as much as possible without making something using the actual process engineering.</p><p><strong>We\u2019ve talked about the benefits. How about the drawbacks?</strong></p><p><strong>Gorr: </strong>The [AI-based experimental models] tend to not be as accurate as physics-based models. Of course, that\u2019s why you do many simulations and parameter sweeps. But that\u2019s also the benefit of having that digital twin, where you can keep that in mind\u2014it\u2019s not going to be as accurate as that precise model that we\u2019ve developed over the years.</p><p>Both chip design and manufacturing are system intensive; you have to consider every little part. And that can be really challenging. It\u2019s a case where you might have models to predict something and different parts of it, but you still need to bring it all together.</p><p>One of the other things to think about too is that you need the data to build the models. You have to incorporate data from all sorts of different sensors and different sorts of teams, and so that heightens the challenge.</p><p><strong>How can engineers use AI to better prepare and extract insights from hardware or sensor data?</strong></p><p><strong>Gorr: </strong>We always think about using AI to predict something or do some robot task, but you can use AI to come up with patterns and pick out things you might not have noticed before on your own. People will use AI when they have high-frequency data coming from many different sensors, and a lot of times it\u2019s useful to explore the frequency domain and things like data synchronization or resampling. Those can be really challenging if you\u2019re not sure where to start.</p><p>One of the things I would say is, use the tools that are available. There\u2019s a vast community of people working on these things, and you can find lots of examples [of applications and techniques] on <a href=\"https://github.com/\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub</a> or <a href=\"https://www.mathworks.com/matlabcentral/\" rel=\"noopener noreferrer\" target=\"_blank\">MATLAB Central</a>, where people have shared nice examples, even little apps they\u2019ve created. I think many of us are buried in data and just not sure what to do with it, so definitely take advantage of what\u2019s already out there in the community. You can explore and see what makes sense to you, and bring in that balance of domain knowledge and the insight you get from the tools and AI.</p><p><strong>What should engineers and designers consider wh</strong><strong>en using AI for chip design?</strong></p><p><strong>Gorr:</strong> Think through what problems you\u2019re trying to solve or what insights you might hope to find, and try to be clear about that. Consider all of the different components, and document and test each of those different parts. Consider all of the people involved, and explain and hand off in a way that is sensible for the whole team.</p><p><strong>How do you think AI will affect chip designers\u2019 jobs?</strong></p><p><strong>Gorr:</strong> It\u2019s going to free up a lot of human capital for more advanced tasks. We can use AI to reduce waste, to optimize the materials, to optimize the design, but then you still have that human involved whenever it comes to decision-making. I think it\u2019s a great example of people and technology working hand in hand. It\u2019s also an industry where all people involved\u2014even on the manufacturing floor\u2014need to have some level of understanding of what\u2019s happening, so this is a great industry for advancing AI because of how we test things and how we think about them before we put them on the chip.</p><p><strong>How do you envision the future of AI and chip design?</strong></p><p><strong>Gorr</strong><strong>:</strong> It\u2019s very much dependent on that human element\u2014involving people in the process and having that interpretable model. We can do many things with the mathematical minutiae of modeling, but it comes down to how people are using it, how everybody in the process is understanding and applying it. Communication and involvement of people of all skill levels in the process are going to be really important. We\u2019re going to see less of those superprecise predictions and more transparency of information, sharing, and that digital twin\u2014not only using AI but also using our human knowledge and all of the work that many people have done over the years.</p>", "url": "https://spectrum.ieee.org/ai-chip-design-matlab", "published_at": "Tue, 08 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/layered-rendering-of-colorful-semiconductor-wafers-with-a-bright-white-light-sitting-on-one.jpg?id=29285079&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C0%2C0\" /><br /><br /><p>The end of <a href=\"https://spectrum.ieee.org/on-beyond-moores-l"]}
{"id": "source:rss:8010303921", "title": "Atomically Thin Materials Significantly Shrink Qubits", "summary": "<img src=\"https://spectrum.ieee.org/media-library/a-golden-square-package-holds-a-small-processor-sitting-on-top-is-a-metal-square-with-mit-etched-into-it.jpg?id=29281587&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C0%2C0\" /><br /><br /><p>Quantum computing is a devilishly complex technology, with many technical hurdles impacting its development. Of these challenges two critical issues stand out: miniaturization and qubit quality.</p><p>IBM has adopted the superconducting qubit road map of <a href=\"https://spectrum.ieee.org/ibms-envisons-the-road-to-quantum-computing-like-an-apollo-mission\" target=\"_self\">reaching a 1,121-qubit processor by 2023</a>, leading to the expectation that 1,000 qubits with today\u2019s qubit form factor is feasible. However, current approaches will require very large chips (50 millimeters on a side, or larger) at the scale of small wafers, or the use of chiplets on multichip modules. While this approach will work, the aim is to attain a better path toward scalability.</p><p>Now researchers at <a href=\"https://www.nature.com/articles/s41563-021-01187-w\" rel=\"noopener noreferrer\" target=\"_blank\">MIT have been able to both reduce the size of the qubits</a> and done so in a way that reduces the interference that occurs between neighboring qubits. The MIT researchers have increased the number of superconducting qubits that can be added onto a device by a factor of 100.</p><p>\u201cWe are addressing both qubit miniaturization and quality,\u201d said <a href=\"https://equs.mit.edu/william-d-oliver/\" rel=\"noopener noreferrer\" target=\"_blank\">William Oliver</a>, the director for the <a href=\"https://cqe.mit.edu/\" target=\"_blank\">Center for Quantum Engineering</a> at MIT. \u201cUnlike conventional transistor scaling, where only the number really matters, for qubits, large numbers are not sufficient, they must also be high-performance. Sacrificing performance for qubit number is not a useful trade in quantum computing. They must go hand in hand.\u201d</p><p>The key to this big increase in qubit density and reduction of interference comes down to the use of two-dimensional materials, in particular the 2D insulator hexagonal boron nitride (hBN). The MIT researchers demonstrated that a few atomic monolayers of hBN can be stacked to form the insulator in the capacitors of a superconducting qubit.</p><p>Just like other capacitors, the capacitors in these superconducting circuits take the form of a sandwich in which an insulator material is sandwiched between two metal plates. The big difference for these capacitors is that the superconducting circuits can operate only at extremely low temperatures\u2014less than 0.02 degrees above absolute zero (-273.15 \u00b0C).</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" style=\"float: left;\"> <img alt=\"Golden dilution refrigerator hanging vertically\" class=\"rm-shortcode rm-resized-image\" id=\"6c615\" src=\"https://spectrum.ieee.org/media-library/golden-dilution-refrigerator-hanging-vertically.jpg?id=29281593&amp;width=980\" /> <small class=\"image-media media-caption\">Superconducting qubits are measured at temperatures as low as 20 millikelvin in a dilution refrigerator.</small><small class=\"image-media media-photo-credit\">Nathan Fiske/MIT</small></p><p>In that environment, insulating materials that are available for the job, such as PE-CVD silicon oxide or silicon nitride, have quite a few defects that are too lossy for quantum computing applications. To get around these material shortcomings, most superconducting circuits use what are called coplanar capacitors. In these capacitors, the plates are positioned laterally to one another, rather than on top of one another.</p><p>As a result, the intrinsic silicon substrate below the plates and to a smaller degree the vacuum above the plates serve as the capacitor dielectric. Intrinsic silicon is chemically pure and therefore has few defects, and the large size dilutes the electric field at the plate interfaces, all of which leads to a low-loss capacitor. The lateral size of each plate in this open-face design ends up being quite large (typically 100 by 100 micrometers) in order to achieve the required capacitance.</p><p>In an effort to move away from the large lateral configuration, the MIT researchers embarked on a search for an insulator that has very few defects and is compatible with superconducting capacitor plates.</p><p>\u201cWe chose to study hBN because it is the most widely used insulator in 2D material research due to its cleanliness and chemical inertness,\u201d said colead author <a href=\"https://equs.mit.edu/joel-wang/\" rel=\"noopener noreferrer\" target=\"_blank\">Joel Wang</a>, a research scientist in the Engineering Quantum Systems group of the MIT Research Laboratory for Electronics. </p><p>On either side of the hBN, the MIT researchers used the 2D superconducting material, niobium diselenide. One of the trickiest aspects of fabricating the capacitors was working with the niobium diselenide, which oxidizes in seconds when exposed to air, according to Wang. This necessitates that the assembly of the capacitor occur in a glove box filled with argon gas.</p><p>While this would seemingly complicate the scaling up of the production of these capacitors, Wang doesn\u2019t regard this as a limiting factor.</p><p>\u201cWhat determines the quality factor of the capacitor are the two interfaces between the two materials,\u201d said Wang. \u201cOnce the sandwich is made, the two interfaces are \u201csealed\u201d and we don\u2019t see any noticeable degradation over time when exposed to the atmosphere.\u201d</p><p>This lack of degradation is because around 90 percent of the electric field is contained within the sandwich structure, so the oxidation of the outer surface of the niobium diselenide does not play a significant role anymore. This ultimately makes the capacitor footprint much smaller, and it accounts for the reduction in cross talk between the neighboring qubits.</p><p>\u201cThe main challenge for scaling up the fabrication will be the wafer-scale growth of hBN and 2D superconductors like [niobium diselenide], and how one can do wafer-scale stacking of these films,\u201d added Wang.</p><p>Wang believes that this research has shown 2D hBN to be a good insulator candidate for superconducting qubits. He says that the groundwork the MIT team has done will serve as a road map for using other hybrid 2D materials to build superconducting circuits.</p>", "url": "https://spectrum.ieee.org/2d-hbn-qubit", "published_at": "Mon, 07 Fe", "source_type": "rss", "credibility_tier": "A", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://spectrum.ieee.org/media-library/a-golden-square-package-holds-a-small-processor-sitting-on-top-is-a-metal-square-with-mit-etched-into-it.jpg?id=29281587&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C0%2C0\" /><br /><br /><p>Quantum computing is a devilishly complex technolog"]}
{"id": "source:rss:4115272059", "title": "A Wave of Unexplained Bot Traffic Is Sweeping the Web", "summary": "From small publishers to US federal agencies, websites are reporting unusual spikes in automated traffic linked to IP addresses in Lanzhou, China.", "url": "https://www.wired.com/story/made-in-china-niche-websites-are-seeing-a-surge-of-mysterious-traffic-from-china/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["From small publishers to US federal agencies, websites are reporting unusual spikes in automated traffic linked to IP addresses in Lanzhou, China."]}
{"id": "source:rss:8630868166", "title": "OpenAI\u2019s President Gave Millions to Trump. He Says It\u2019s for Humanity", "summary": "In an interview with WIRED, Greg Brockman says his political donations support OpenAI's mission\u2014even if some employees at the company disagree.", "url": "https://www.wired.com/story/openai-president-greg-brockman-political-donations-trump-humanity/", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["In an interview with WIRED, Greg Brockman says his political donations support OpenAI's mission\u2014even if some employees at the company disagree."]}
{"id": "source:rss:1896464329", "title": "I Loved My OpenClaw AI Agent\u2014Until It Turned on Me", "summary": "I used the viral AI helper to order groceries, sort emails, and negotiate deals. Then it decided to scam me.", "url": "https://www.wired.com/story/malevolent-ai-agent-openclaw-clawdbot/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["I used the viral AI helper to order groceries, sort emails, and negotiate deals. Then it decided to scam me."]}
{"id": "source:rss:1840445765", "title": "Jeffrey Epstein Advised an Elon Musk Associate on Taking Tesla Private", "summary": "The financier recommended adding Margaret Thatcher to Tesla\u2019s board, even though she had been dead for five years.", "url": "https://www.wired.com/story/jeffrey-epstein-advised-an-elon-musk-associate-on-taking-tesla-private/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The financier recommended adding Margaret Thatcher to Tesla\u2019s board, even though she had been dead for five years."]}
{"id": "source:rss:9199045634", "title": "AI Industry Rivals Are Teaming Up on a Startup Accelerator", "summary": "OpenAI, Anthropic, Google, and a host of other major tech companies have found common ground in F/ai, a new startup accelerator based out of Paris.", "url": "https://www.wired.com/story/ai-industry-rivals-are-teaming-up-on-a-startup-accelerator/", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI, Anthropic, Google, and a host of other major tech companies have found common ground in F/ai, a new startup accelerator based out of Paris."]}
{"id": "source:rss:2377967181", "title": "Salesforce Workers Circulate Open Letter Urging CEO Marc Benioff to Denounce ICE", "summary": "The letter comes after Benioff joked at a company event on Monday that ICE was monitoring international employees in attendance, sparking immediate backlash.", "url": "https://www.wired.com/story/letter-salesforce-employees-sent-after-marc-benioffs-ice-comments/", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The letter comes after Benioff joked at a company event on Monday that ICE was monitoring international employees in attendance, sparking immediate backlash."]}
{"id": "source:rss:6328903037", "title": "OpenAI Abandons \u2018io\u2019 Branding for Its AI Hardware", "summary": "A court filing in a trademark lawsuit reveals OpenAI won't use the name \u201cio\u201d for its AI hardware device, which isn't expected to ship until 2027.", "url": "https://www.wired.com/story/openai-drops-io-branding-hardware-devices/", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["A court filing in a trademark lawsuit reveals OpenAI won't use the name \u201cio\u201d for its AI hardware device, which isn't expected to ship until 2027."]}
{"id": "source:rss:8379500086", "title": "Meta Goes to Trial in a New Mexico Child Safety Case. Here\u2019s What\u2019s at Stake", "summary": "Attorney general Ra\u00fal Torrez is accusing the tech giant of failing to protect minors on Facebook and Instagram.", "url": "https://www.wired.com/story/meta-child-safety-trial-new-mexico-attorney-general/", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Attorney general Ra\u00fal Torrez is accusing the tech giant of failing to protect minors on Facebook and Instagram."]}
{"id": "source:rss:1464277196", "title": "No Company Has Admitted to Replacing Workers With AI in New York", "summary": "New York state has required companies to disclose if \u201ctechnological innovation or automation\u201d was the cause of job loss for nearly a year. So far, none has.", "url": "https://www.wired.com/story/no-company-has-admitted-to-replacing-workers-with-ai-in-new-york/", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["New York state has required companies to disclose if \u201ctechnological innovation or automation\u201d was the cause of job loss for nearly a year. So far, none has."]}
{"id": "source:rss:5226515675", "title": "AI Is Here to Replace Nuclear Treaties. Scared Yet?", "summary": "The last major nuclear arms treaty between the US and Russia just expired. Some experts believe a combination of satellite surveillance, AI, and human reviewers can take its place. Others, not so much.", "url": "https://www.wired.com/story/satellites-ai-nuclear-treaties/", "published_at": "Mon, 09 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The last major nuclear arms treaty between the US and Russia just expired. Some experts believe a combination of satellite surveillance, AI, and human reviewers can take its place. Others, not so much."]}
{"id": "source:rss:4616439797", "title": "The Only Thing Standing Between Humanity and AI Apocalypse Is \u2026 Claude?", "summary": "As AI systems grow more powerful, Anthropic\u2019s resident philosopher says the startup is betting Claude itself can learn the wisdom needed to avoid disaster.", "url": "https://www.wired.com/story/the-only-thing-standing-between-humanity-and-ai-apocalypse-is-claude/", "published_at": "Fri, 06 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["As AI systems grow more powerful, Anthropic\u2019s resident philosopher says the startup is betting Claude itself can learn the wisdom needed to avoid disaster."]}
{"id": "source:rss:2003073995", "title": "More Than 800 Google Workers Urge Company to Cancel Any Contracts With ICE and CBP", "summary": "The campaign is among the largest anti-ICE protests by workers at a single company since federal agents shot and killed two people in Minneapolis last month.", "url": "https://www.wired.com/story/hundreds-of-google-employees-demand-answers-from-executives-about-ice/", "published_at": "Fri, 06 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The campaign is among the largest anti-ICE protests by workers at a single company since federal agents shot and killed two people in Minneapolis last month."]}
{"id": "source:rss:7145245624", "title": "A Landmark Social Media Addiction Case Puts Big Tech on Trial", "summary": "Juries will soon hear arguments in a case against Meta and Google that could reshape social media protections for kids.", "url": "https://www.wired.com/story/meta-google-youtube-social-media-addiction-trial/", "published_at": "Fri, 06 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Juries will soon hear arguments in a case against Meta and Google that could reshape social media protections for kids."]}
{"id": "source:rss:6040508348", "title": "\u2018Uncanny Valley\u2019: Tech Elites in the Epstein Files, Musk\u2019s Mega Merger, and a Crypto Scam Compound", "summary": "Several big names in tech turned up in the Epstein files. In this episode of Uncanny Valley, our hosts break down what it all means and catch you up on other big stories of the week.", "url": "https://www.wired.com/story/uncanny-valley-podcast-tech-elites-epstein-files-musk-mega-merger-crypto-scam-compound/", "published_at": "Fri, 06 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Several big names in tech turned up in the Epstein files. In this episode of Uncanny Valley, our hosts break down what it all means and catch you up on other big stories of the week."]}
{"id": "source:rss:3201368213", "title": "Loyalty Is Dead in Silicon Valley", "summary": "Founders used to be wedded to their companies. Now, anyone can be lured away for the right price.", "url": "https://www.wired.com/story/model-behavior-loyalty-is-dead-in-silicon-valley/", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Founders used to be wedded to their companies. Now, anyone can be lured away for the right price."]}
{"id": "source:rss:1562027977", "title": "The Rise and Fall of the World's Largest Gay Dating App", "summary": "The new book The Wall Dancers explores the uneasy relationship between Chinese internet users and a government that is always watching.", "url": "https://www.wired.com/story/made-in-china-how-people-in-china-learn-what-they-can-say-online/", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The new book The Wall Dancers explores the uneasy relationship between Chinese internet users and a government that is always watching."]}
{"id": "source:rss:1114083246", "title": "How iPhones Made a Surprising Comeback in China", "summary": "Huawei\u2019s and Xiaomi\u2019s flagship devices are packed with impressive features, but Apple is dominating the Chinese smartphone market again\u2014for now.", "url": "https://www.wired.com/story/how-iphones-made-a-surprising-comeback-in-china/", "published_at": "Thu, 05 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Huawei\u2019s and Xiaomi\u2019s flagship devices are packed with impressive features, but Apple is dominating the Chinese smartphone market again\u2014for now."]}
{"id": "source:rss:8233729503", "title": "A New AI Math Startup Just Cracked 4 Previously Unsolved Problems", "summary": "Axiom says its AI found solutions to several long-standing math problems, a sign of the technology\u2019s steadily advancing reasoning capabilities.", "url": "https://www.wired.com/story/a-new-ai-math-ai-startup-just-cracked-4-previously-unsolved-problems/", "published_at": "Wed, 04 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Axiom says its AI found solutions to several long-standing math problems, a sign of the technology\u2019s steadily advancing reasoning capabilities."]}
{"id": "source:rss:7433640710", "title": "Mistral's New Ultra-Fast Translation Model Gives Big AI Labs a Run for Their Money", "summary": "\u201cToo many GPUs makes you lazy,\u201d says the French startup\u2019s vice president of science operations, as the company carves out a different path than the major US AI companies.", "url": "https://www.wired.com/story/mistral-voxtral-real-time-ai-translation/", "published_at": "Wed, 04 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["\u201cToo many GPUs makes you lazy,\u201d says the French startup\u2019s vice president of science operations, as the company carves out a different path than the major US AI companies."]}
{"id": "source:rss:9028969932", "title": "AI Bots Are Now a Significant Source of Web Traffic", "summary": "New data shows AI bots pushing deeper into the web, prompting publishers to roll out more aggressive defenses.", "url": "https://www.wired.com/story/ai-bots-are-now-a-signifigant-source-of-web-traffic/", "published_at": "Wed, 04 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["New data shows AI bots pushing deeper into the web, prompting publishers to roll out more aggressive defenses."]}
{"id": "source:rss:2912427620", "title": "Good Luck, Have Fun, Don\u2019t Die is a rollicking parable about this moment in tech", "summary": "We are all guilty of pulling out our phones and doomscrolling through stressful headlines or mindnumbing videos when we should be doing anything else. We know it's bad, but we still do it because it's hard to resist when much of our time is spent living and working on our devices. And even though we [&#8230;]", "url": "https://www.theverge.com/entertainment/877244/good-luck-have-fun-dont-die-review", "published_at": "2026-02-12", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["We are all guilty of pulling out our phones and doomscrolling through stressful headlines or mindnumbing videos when we should be doing anything else. We know it's bad, but we still do it because it's hard to resist when much of our time is spent living and working on our devices. And even though we"]}
{"id": "source:rss:3660910685", "title": "The surprising case for AI judges", "summary": "Today, we\u2019re going to talk about the role AI might play in deciding legal disputes. Not just drafting memos and doing research \u2014 actually deciding who\u2019s right and who\u2019s wrong, and who should pay. My guest today is Bridget McCormack, the former chief justice for the Michigan Supreme Court and now president and CEO of [&#8230;]", "url": "https://www.theverge.com/podcast/877299/ai-arbitrator-bridget-mccormack-aaa-arbitration-interview", "published_at": "2026-02-12", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Today, we\u2019re going to talk about the role AI might play in deciding legal disputes. Not just drafting memos and doing research \u2014 actually deciding who\u2019s right and who\u2019s wrong, and who should pay. My guest today is Bridget McCormack, the former chief justice for the Michigan Supreme Court and now pre"]}
{"id": "source:rss:1756809994", "title": "ByteDance\u2019s next-gen AI model can generate clips based on text, images, audio, and video", "summary": "Big Tech's race to leapfrog the latest AI models continues with the launch of ByteDance's next-gen video generator. In a blog post, ByteDance - the China-based company behind TikTok - says Seedance 2.0 supports prompts that combine text, images, video, and audio. The company claims it \"delivers a substantial leap in generation quality,\" offering improvements [&#8230;]", "url": "https://www.theverge.com/ai-artificial-intelligence/877931/bytedance-seedance-2-video-generator-ai-launch", "published_at": "2026-02-12", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Big Tech's race to leapfrog the latest AI models continues with the launch of ByteDance's next-gen video generator. In a blog post, ByteDance - the China-based company behind TikTok - says Seedance 2.0 supports prompts that combine text, images, video, and audio. The company claims it \"delivers a su"]}
{"id": "source:rss:7690406260", "title": "This $7,999 robot will fold (some of) your laundry", "summary": "If you have a spare $7,999 (plus a $250 deposit), hate folding laundry, and happen to live in the Bay Area, one-and-a-half-year-old startup Weave has the robot for you: Isaac 0. It takes Isaac 0 around 30-90 minutes to fold a load of laundry, Weave says. That's all it does - it's stationary and needs [&#8230;]", "url": "https://www.theverge.com/tech/877851/weave-isaac-robot-fold-laundry", "published_at": "2026-02-12", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["If you have a spare $7,999 (plus a $250 deposit), hate folding laundry, and happen to live in the Bay Area, one-and-a-half-year-old startup Weave has the robot for you: Isaac 0. It takes Isaac 0 around 30-90 minutes to fold a load of laundry, Weave says. That's all it does - it's stationary and need"]}
{"id": "source:rss:7268952525", "title": "Two more xAI co-founders are among those leaving after the SpaceX merger", "summary": "Since the xAI-SpaceX merger announced last week, which combined the two companies (as well as social media platform X) for a reported $1.25 trillion valuation - the biggest merger of all time - a handful of xAI employees and two of its co-founders have abruptly exited the company, penning long departure announcements online. Some also [&#8230;]", "url": "https://www.theverge.com/ai-artificial-intelligence/877609/two-more-xai-co-founders-are-among-those-leaving-after-the-spacex-merger", "published_at": "2026-02-11", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Since the xAI-SpaceX merger announced last week, which combined the two companies (as well as social media platform X) for a reported $1.25 trillion valuation - the biggest merger of all time - a handful of xAI employees and two of its co-founders have abruptly exited the company, penning long depar"]}
{"id": "source:rss:2384549586", "title": "Anthropic says it&#8217;ll try to keep its data centers from raising electricity costs", "summary": "Anthropic is the latest AI company promising to limit the impact its data centers have on nearby residents' electricity bills. The company said it would pay higher monthly electricity charges in order to cover 100 percent of the upgrades needed to connect its data centers to power grids. \"This includes the shares of these costs [&#8230;]", "url": "https://www.theverge.com/ai-artificial-intelligence/877526/anthropic-ai-electricity-costs-data-center-pledge", "published_at": "2026-02-11", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Anthropic is the latest AI company promising to limit the impact its data centers have on nearby residents' electricity bills. The company said it would pay higher monthly electricity charges in order to cover 100 percent of the upgrades needed to connect its data centers to power grids. \"This inclu"]}
{"id": "source:rss:2999749825", "title": "Apple keeps hitting bumps with its overhauled Siri", "summary": "Apple had been reportedly pushing to introduce some big changes to Siri with iOS 26.4, but now the company is planning to introduce them in later versions of iOS, including iOS 26.5 and iOS 27, Bloomberg reports. Nearly a year ago, Apple delayed planned features for Siri that would let it understand your personal context [&#8230;]", "url": "https://www.theverge.com/tech/877494/apple-siri-ai-overhaul-ios-personalized", "published_at": "2026-02-11", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Apple had been reportedly pushing to introduce some big changes to Siri with iOS 26.4, but now the company is planning to introduce them in later versions of iOS, including iOS 26.5 and iOS 27, Bloomberg reports. Nearly a year ago, Apple delayed planned features for Siri that would let it understand"]}
{"id": "source:rss:4813757145", "title": "Instagram and X have an impossible deepfake detection deadline", "summary": "The best methods we currently have for detecting and labelling deepfakes online are about to get a stress test. India announced mandates on Tuesday that require social media platforms to remove illegal AI-generated materials much faster, and ensure that all synthetic content is clearly labeled. Tech companies have said for years that they wanted to [&#8230;]", "url": "https://www.theverge.com/ai-artificial-intelligence/877206/youtube-instagram-x-india-deepfake-detection-deadline", "published_at": "2026-02-11", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["The best methods we currently have for detecting and labelling deepfakes online are about to get a stress test. India announced mandates on Tuesday that require social media platforms to remove illegal AI-generated materials much faster, and ensure that all synthetic content is clearly labeled. Tech"]}
{"id": "source:rss:5050280832", "title": "Here are the brands bringing ads to ChatGPT", "summary": "OpenAI officially launched its advertising pilot in ChatGPT, leaving us with a better idea of the kinds of products we might see stuffed beneath our conversations with the AI chatbot. Several companies have announced plans to show ads inside ChatGPT - placements that will reportedly cost them a pretty penny - ranging from major retailers [&#8230;]", "url": "https://www.theverge.com/ai-artificial-intelligence/877148/openai-chatgpt-advertisers-target-adobe-audible", "published_at": "2026-02-11", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["OpenAI officially launched its advertising pilot in ChatGPT, leaving us with a better idea of the kinds of products we might see stuffed beneath our conversations with the AI chatbot. Several companies have announced plans to show ads inside ChatGPT - placements that will reportedly cost them a pret"]}
{"id": "source:rss:3149212398", "title": "How an \u2018icepocalypse\u2019 raises more questions about Meta\u2019s biggest data center project", "summary": "Donna Collins lives about 20 miles from where Meta's biggest data center is being built, in a house her family has lived in for five generations. Construction has thrown the small agricultural community in North Louisiana into the spotlight as a high-profile example of how the infrastructure behind generative AI could impact nearby residents. For [&#8230;]", "url": "https://www.theverge.com/science/876555/meta-data-center-winter-power-outages-storm-ice", "published_at": "2026-02-11", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["Donna Collins lives about 20 miles from where Meta's biggest data center is being built, in a house her family has lived in for five generations. Construction has thrown the small agricultural community in North Louisiana into the spotlight as a high-profile example of how the infrastructure behind "]}
{"id": "source:rss:6493133559", "title": "OpenAI Scales Single Primary Postgresql to Millions of Queries per Second for ChatGPT", "summary": "<img src=\"https://www.infoq.com/styles/static/images/logo/logo_bigger.jpg\" /><p>OpenAI described how it scaled PostgreSQL to support ChatGPT and its API platform, handling millions of queries per second for hundreds of millions of users. By running a single-primary PostgreSQL deployment on Azure with nearly 50 read replicas, optimizing query patterns, and offloading write-heavy workloads to sharded systems, OpenAI maintained low-latency reads while managing write pressure.</p> <i>By Leela Kumili</i>", "url": "https://www.infoq.com/news/2026/02/openai-runs-chatgpt-postgres/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://www.infoq.com/styles/static/images/logo/logo_bigger.jpg\" /><p>OpenAI described how it scaled PostgreSQL to support ChatGPT and its API platform, handling millions of queries per second for hundreds of millions of users. By running a single-primary PostgreSQL deployment on Azure wit"]}
{"id": "source:rss:8779958864", "title": "Creating Impactful Teams through Diversity Using Session 0", "summary": "<img src=\"https://res.infoq.com/news/2026/02/create-impactful-teams-diversity/en/headerimage/generatedHeaderImage-1770636528408.jpg\" /><p>Diverse and empowered teams are impactful teams, Natan \u017dabkar Nordberg mentioned in his talk on creating impactful software teams at QCon London. A session 0 helps set expectations and ensures that everyone is approaching the team in a compatible way.</p> <i>By Ben Linders</i>", "url": "https://www.infoq.com/news/2026/02/create-impactful-teams-diversity/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/news/2026/02/create-impactful-teams-diversity/en/headerimage/generatedHeaderImage-1770636528408.jpg\" /><p>Diverse and empowered teams are impactful teams, Natan \u017dabkar Nordberg mentioned in his talk on creating impactful software teams at QCon London. A session 0 help"]}
{"id": "source:rss:4937819292", "title": "WhatsApp Deploys Rust-Based Media Parser to Block Malware on 3 Billion Devices", "summary": "<img src=\"https://res.infoq.com/news/2026/02/whatsapp-rust-media-malware/en/headerimage/generatedHeaderImage-1770384331851.jpg\" /><p>WhatsApp has rewritten its media handling library in Rust, replacing 160,000 lines of C++ with 90,000 lines of memory-safe code for 3 billion devices. The rollout, part of a system called Kaleidoscope, uses differential fuzzing to ensure bug-for-bug compatibility. The move mirrors a decade-long industry shift toward memory safety, tracing back to Mozilla's first Rust MP4 parser deployment in 2016.</p> <i>By Steef-Jan Wiggers</i>", "url": "https://www.infoq.com/news/2026/02/whatsapp-rust-media-malware/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/news/2026/02/whatsapp-rust-media-malware/en/headerimage/generatedHeaderImage-1770384331851.jpg\" /><p>WhatsApp has rewritten its media handling library in Rust, replacing 160,000 lines of C++ with 90,000 lines of memory-safe code for 3 billion devices. The rollout, par"]}
{"id": "source:rss:8697194473", "title": "Article: You\u2019ve Generated Your MVP Using AI. What Does That Mean for Your Software Architecture?", "summary": "<img src=\"https://res.infoq.com/articles/ai-generated-mvp/en/headerimage/header-ai-generated-mvp-1770282822570.jpg\" /><p>AI\u2011generated code creates implicit architectural decisions, forcing teams to rely on experimentation to validate quality attributes. To get useful results from AI, teams must clearly express trade\u2011offs and reasoning so the model can generate solutions aligned with desired QARs.</p> <i>By Pierre Pureur, Kurt Bittner</i>", "url": "https://www.infoq.com/articles/ai-generated-mvp/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Thu, 12 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/articles/ai-generated-mvp/en/headerimage/header-ai-generated-mvp-1770282822570.jpg\" /><p>AI\u2011generated code creates implicit architectural decisions, forcing teams to rely on experimentation to validate quality attributes. To get useful results from AI, teams must clea"]}
{"id": "source:rss:6170842886", "title": "Presentation: Scaling to 100+ as a Director: Lessons From Growing Engineering Organizations", "summary": "<img src=\"https://res.infoq.com/presentations/scaling-engineering-teams/en/mediumimage/thiago-ghisi-medium-1769589727635.jpg\" /><p>Thiago Ghisi explains the structural shifts required as an engineering org scales from 30 to 100+ engineers. He shares how to transition from managing performance to building opinionated leadership teams and shaping long-term culture. He discusses his \"Three Levels of Impact\" framework - Org, Skip-Level, and Company - to help leaders drive strategy and secure high-level promotions.</p> <i>By Thiago Ghisi</i>", "url": "https://www.infoq.com/presentations/scaling-engineering-teams/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/presentations/scaling-engineering-teams/en/mediumimage/thiago-ghisi-medium-1769589727635.jpg\" /><p>Thiago Ghisi explains the structural shifts required as an engineering org scales from 30 to 100+ engineers. He shares how to transition from managing performance to bui"]}
{"id": "source:rss:8914414274", "title": "Podcast: [Video Podcast] The Craft of Software Architecture in the Age of AI Tools", "summary": "<img src=\"https://res.infoq.com/podcasts/craft-software-architecture/en/smallimage/the-infoq-podcast-logo-thumbnail-1770210409494.jpg\" /><p>AI coding assistants promise speed, but what do they mean for quality, trust, and the architect\u2019s craft? In this inaugural episode of Next Gen Architecture Playbook, Shweta Vohra and Grady Booch explore a principled view of how architecture must evolve when machines begin writing code alongside humans. They unpack the third golden age of software engineering, where productivity gains are real.</p> <i>By Grady Booch</i>", "url": "https://www.infoq.com/podcasts/craft-software-architecture/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/podcasts/craft-software-architecture/en/smallimage/the-infoq-podcast-logo-thumbnail-1770210409494.jpg\" /><p>AI coding assistants promise speed, but what do they mean for quality, trust, and the architect\u2019s craft? In this inaugural episode of Next Gen Architecture Play"]}
{"id": "source:rss:4781306954", "title": "CloudFront Adds Origin mTLS Authentication for End-to-End Zero Trust", "summary": "<img src=\"https://res.infoq.com/news/2026/02/amazon-cloudfront-mtls-origins/en/headerimage/generatedHeaderImage-1770286991456.jpg\" /><p>Amazon CloudFront now supports mutual TLS authentication for origin servers, completing end-to-end zero-trust authentication from viewers to backends. The feature replaces IP allowlists and shared secrets with cryptographic verification, proving particularly valuable for multi-cloud deployments, where origins can verify that traffic originated from CloudFront without VPN tunnels.</p> <i>By Steef-Jan Wiggers</i>", "url": "https://www.infoq.com/news/2026/02/amazon-cloudfront-mtls-origins/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/news/2026/02/amazon-cloudfront-mtls-origins/en/headerimage/generatedHeaderImage-1770286991456.jpg\" /><p>Amazon CloudFront now supports mutual TLS authentication for origin servers, completing end-to-end zero-trust authentication from viewers to backends. The feature r"]}
{"id": "source:rss:1942464225", "title": "Article: From Prompts to Production: A Playbook for Agentic Development", "summary": "<img src=\"https://res.infoq.com/articles/prompts-to-production-playbook-for-agentic-development/en/headerimage/prompts-to-production-playbook-header-1770374539263.jpg\" /><p>In this article, author Abhishek Goswami shares a practitioner's playbook with development practices, that describes building agentic AI applications and scaling them in production. He also presents core architecture patterns for agentic application development.</p> <i>By Abhishek Goswami</i>", "url": "https://www.infoq.com/articles/prompts-to-production-playbook-for-agentic-development/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/articles/prompts-to-production-playbook-for-agentic-development/en/headerimage/prompts-to-production-playbook-header-1770374539263.jpg\" /><p>In this article, author Abhishek Goswami shares a practitioner's playbook with development practices, that describes building a"]}
{"id": "source:rss:2732626147", "title": "Pandas 3.0 Introduces Default String Dtype and Copy-on-Write Semantics", "summary": "<img src=\"https://res.infoq.com/news/2026/02/pandas-library/en/headerimage/generatedHeaderImage-1770797592963.jpg\" /><p>The pandas team has released pandas 3.0.0, a major update that changes core behaviors around string handling, memory semantics, and datetime resolution, while removing a substantial amount of deprecated functionality. The release introduces several changes to core behaviors in the library\u2019s API.</p> <i>By Robert Krzaczy\u0144ski</i>", "url": "https://www.infoq.com/news/2026/02/pandas-library/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/news/2026/02/pandas-library/en/headerimage/generatedHeaderImage-1770797592963.jpg\" /><p>The pandas team has released pandas 3.0.0, a major update that changes core behaviors around string handling, memory semantics, and datetime resolution, while removing a substantia"]}
{"id": "source:rss:3216409918", "title": "Kubernetes Drives AI Expansion as Cultural Shift Becomes Critical", "summary": "<img src=\"https://www.infoq.com/styles/static/images/logo/logo_bigger.jpg\" /><p>A new CNCF report identifies Kubernetes as the primary engine for AI growth, with 82% production adoption. However, technical maturity has outpaced organisational change. Human factors, such as siloed team structures and a lack of cross-functional collaboration, now serve as the leading barriers to successful deployment, making cultural transformation the decisive factor for AI scaling.</p> <i>By Mark Silvester</i>", "url": "https://www.infoq.com/news/2026/02/kubernetes-ai-culture-impact/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Wed, 11 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://www.infoq.com/styles/static/images/logo/logo_bigger.jpg\" /><p>A new CNCF report identifies Kubernetes as the primary engine for AI growth, with 82% production adoption. However, technical maturity has outpaced organisational change. Human factors, such as siloed team structures and"]}
{"id": "source:rss:8889444225", "title": "GitHub Copilot SDK Lets Developers Integrate Copilot CLI's Engine into Apps", "summary": "<img src=\"https://res.infoq.com/news/2026/02/github-copilot-sdk/en/headerimage/github-copilot-sdk-1770752972453.jpeg\" /><p>Now available in technical preview on GitHub, the GitHub Copilot SDK lets developers embed the same engine that powers GitHub Copilot CLI into their own apps, making it easier to build agentic workflows.</p> <i>By Sergio De Simone</i>", "url": "https://www.infoq.com/news/2026/02/github-copilot-sdk/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/news/2026/02/github-copilot-sdk/en/headerimage/github-copilot-sdk-1770752972453.jpeg\" /><p>Now available in technical preview on GitHub, the GitHub Copilot SDK lets developers embed the same engine that powers GitHub Copilot CLI into their own apps, making it easier t"]}
{"id": "source:rss:3252938808", "title": "QCon Previews 20th Anniversary Conferences: Production AI, Resilience, and Staff+ Engineering", "summary": "<img src=\"https://res.infoq.com/news/2026/02/qcon-previews-20th-anniversary/en/headerimage/QCon-20th-anniversary-1770709102792.jpg\" /><p>Celebrating its 20th anniversary, QCon\u2019s 2026 conferences in London and San Francisco will focus on the engineering realities of agentic AI, resilient architectures, and platform ROI. The programs continue the series' two-decade tradition of practitioner-led content, curated by senior engineers from companies like Zoox, UBS, and LinkedIn.</p> <i>By Artenisa Chatziou</i>", "url": "https://www.infoq.com/news/2026/02/qcon-previews-20th-anniversary/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/news/2026/02/qcon-previews-20th-anniversary/en/headerimage/QCon-20th-anniversary-1770709102792.jpg\" /><p>Celebrating its 20th anniversary, QCon\u2019s 2026 conferences in London and San Francisco will focus on the engineering realities of agentic AI, resilient architecture"]}
{"id": "source:rss:5293959446", "title": "BellSoft Survey Finds Container Security Practices Are Undermining Developers\u2019 Own Goals", "summary": "<img src=\"https://res.infoq.com/news/2026/02/bellsoft-container-security/en/headerimage/generatedHeaderImage-1770294152339.jpg\" /><p>Container security incidents are becoming a routine reality for software teams, and the tools meant to protect them may be making the problem worse.</p> <i>By Craig Risi</i>", "url": "https://www.infoq.com/news/2026/02/bellsoft-container-security/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/news/2026/02/bellsoft-container-security/en/headerimage/generatedHeaderImage-1770294152339.jpg\" /><p>Container security incidents are becoming a routine reality for software teams, and the tools meant to protect them may be making the problem worse.</p> <i>By Craig Ri"]}
{"id": "source:rss:8702184461", "title": "Windsurf Introduces Arena Mode to Compare AI Models During Development", "summary": "<img src=\"https://res.infoq.com/news/2026/02/windsurf-arena-mode/en/headerimage/generatedHeaderImage-1770651989189.jpg\" /><p>Windsurf has introduced Arena Mode inside its IDE allowing developers to compare large language models side by side while working on real coding tasks. The feature is designed to let users evaluate models directly within their existing development context, rather than relying on public benchmarks or external evaluation websites.</p> <i>By Daniel Dominguez</i>", "url": "https://www.infoq.com/news/2026/02/windsurf-arena-mode/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/news/2026/02/windsurf-arena-mode/en/headerimage/generatedHeaderImage-1770651989189.jpg\" /><p>Windsurf has introduced Arena Mode inside its IDE allowing developers to compare large language models side by side while working on real coding tasks. The feature is designed"]}
{"id": "source:rss:2902561079", "title": "Article: Jakarta EE 12 Milestone 2: Advent of the Data Age Along with Consistency and Configuration", "summary": "<img src=\"https://res.infoq.com/articles/jakartaee-12-milestone-2/en/headerimage/jakartaee-12-milestone-2-header-1770367607817.jpg\" /><p>Jakarta EE 12 Milestone 2 marks the beginning of the next generation of enterprise Java. It introduces Jakarta Query, a unified query language across Persistence, Data, and NoSQL, while aligning the platform with Java 21. This milestone focuses on integration, modernization, and improving developer productivity for cloud-native enterprise applications.</p> <i>By Otavio Santana</i>", "url": "https://www.infoq.com/articles/jakartaee-12-milestone-2/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=global", "published_at": "Tue, 10 Fe", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<img src=\"https://res.infoq.com/articles/jakartaee-12-milestone-2/en/headerimage/jakartaee-12-milestone-2-header-1770367607817.jpg\" /><p>Jakarta EE 12 Milestone 2 marks the beginning of the next generation of enterprise Java. It introduces Jakarta Query, a unified query language across Persistence, "]}
{"id": "source:rss:1736060025", "title": "A Blueprint for Enterprise-Wide Agentic AI Transformation - SPONSOR CONTENT FROM GOOGLE CLOUD CONSULTING", "summary": "<p>Sponsor Content from Google Cloud Consulting.</p>", "url": "https://hbr.org/sponsored/2026/02/a-blueprint-for-enterprise-wide-agentic-ai-transformation", "published_at": "2026-02-12", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Sponsor Content from Google Cloud Consulting.</p>"]}
{"id": "source:rss:8083020143", "title": "To Thrive in the AI Era, Companies Need Agent Managers", "summary": "<p>Just as product managers emerged during the software revolution, agent managers are becoming essential to translating strategic intent into reliable outcomes.</p>", "url": "https://hbr.org/2026/02/to-thrive-in-the-ai-era-companies-need-agent-managers", "published_at": "2026-02-12", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Just as product managers emerged during the software revolution, agent managers are becoming essential to translating strategic intent into reliable outcomes.</p>"]}
{"id": "source:rss:3549996619", "title": "Disney\u2019s New CEO and the Rise of \u201cExperience Intelligence\u201d", "summary": "<p>Josh D&#8217;Amaro&#8217;s appointment signals a growing belief among top organizations: the strongest force in business is an experience people say they love.</p>", "url": "https://hbr.org/2026/02/disneys-new-ceo-and-the-importance-of-experience-intelligence", "published_at": "2026-02-12", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Josh D&#8217;Amaro&#8217;s appointment signals a growing belief among top organizations: the strongest force in business is an experience people say they love.</p>"]}
{"id": "source:rss:8128316088", "title": "Research Roundup: Salary Disparities, Managers Who Squash Ideas, Exclamation Points, and More", "summary": "<p>Fresh insights from academic research, consultancies, and other expert sources.</p>", "url": "https://hbr.org/2026/02/research-roundup-salary-disparities-managers-who-squash-ideas-exclamation-points-and-more", "published_at": "2026-02-11", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Fresh insights from academic research, consultancies, and other expert sources.</p>"]}
{"id": "source:rss:3920830082", "title": "How to Demonstrate Adaptability When Interviewing for a Senior Role", "summary": "<p>Your strongest advantage in today&#8217;s job market isn&#8217;t your title, experience, or a specific metric of success.</p>", "url": "https://hbr.org/2026/02/how-to-demonstrate-adaptability-when-interviewing-for-a-senior-role", "published_at": "2026-02-11", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Your strongest advantage in today&#8217;s job market isn&#8217;t your title, experience, or a specific metric of success.</p>"]}
{"id": "source:rss:9065407927", "title": "Your Strategy Needs a Visual Metaphor", "summary": "<p>Using visuals that tell a story will engage employees&#8217; imaginations and help win their support.</p>", "url": "https://hbr.org/2026/02/your-strategy-needs-a-visual-metaphor", "published_at": "2026-02-11", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Using visuals that tell a story will engage employees&#8217; imaginations and help win their support.</p>"]}
{"id": "source:rss:4655775150", "title": "How to Avoid a False Start When You\u2019re Leading a Big Change", "summary": "<p>The greatest risk is moving before the organization is ready to move with you.</p>", "url": "https://hbr.org/2026/02/how-to-avoid-a-false-start-when-youre-leading-a-big-change", "published_at": "2026-02-10", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>The greatest risk is moving before the organization is ready to move with you.</p>"]}
{"id": "source:rss:3983536493", "title": "Stop Promoting the Wrong People into Manager Roles", "summary": "<p>How to assess whether someone will actually be a good fit for the role.</p>", "url": "https://hbr.org/2026/02/stop-promoting-the-wrong-people-into-manager-roles", "published_at": "2026-02-10", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>How to assess whether someone will actually be a good fit for the role.</p>"]}
{"id": "source:rss:4412697475", "title": "How Designing with Disability in Mind Sparks Innovation", "summary": "<p>Treating accessibility as an innovation catalyst&#8212;not a market niche&#8212;can unlock surprising social and commercial value.</p>", "url": "https://hbr.org/2026/02/how-designing-with-disability-in-mind-sparks-innovation", "published_at": "2026-02-09", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Treating accessibility as an innovation catalyst&#8212;not a market niche&#8212;can unlock surprising social and commercial value.</p>"]}
{"id": "source:rss:4516290236", "title": "Why New Technologies Don\u2019t Transform Incumbents", "summary": "<p>Older companies tend to change one thing at a time. Challengers win by rethinking the basics of how work gets done.</p>", "url": "https://hbr.org/2026/02/why-new-technologies-dont-transform-incumbents", "published_at": "2026-02-09", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Older companies tend to change one thing at a time. Challengers win by rethinking the basics of how work gets done.</p>"]}
{"id": "source:rss:7036171476", "title": "AI Doesn\u2019t Reduce Work\u2014It Intensifies It", "summary": "<p>An eight-month study found that these tools made productivity surge&#8212;as well as cognitive fatigue, unsustainable hours, and other problems.</p>", "url": "https://hbr.org/2026/02/ai-doesnt-reduce-work-it-intensifies-it", "published_at": "2026-02-09", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>An eight-month study found that these tools made productivity surge&#8212;as well as cognitive fatigue, unsustainable hours, and other problems.</p>"]}
{"id": "source:rss:7857481686", "title": "What\u2019s the ROI on AI?", "summary": "<p>Leaders from Microsoft, Verizon, Allianz, Schneider Electric, and Mahindra share where AI is already delivering results and what it will take to lead through the technology&#8217;s disruption.</p>", "url": "https://hbr.org/2026/02/whats-the-roi-on-ai", "published_at": "2026-02-06", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Leaders from Microsoft, Verizon, Allianz, Schneider Electric, and Mahindra share where AI is already delivering results and what it will take to lead through the technology&#8217;s disruption.</p>"]}
{"id": "source:rss:7782145052", "title": "Do You Know What Your Customers\u2019 Aspirations Are?", "summary": "<p>To serve your customers, you need to understand where they&#8217;re trying to go.</p>", "url": "https://hbr.org/2026/02/do-you-know-what-your-customers-aspirations-are", "published_at": "2026-02-06", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>To serve your customers, you need to understand where they&#8217;re trying to go.</p>"]}
{"id": "source:rss:7685139006", "title": "When the Bold Leader You Hired Starts to Conform", "summary": "<p>Without structural and psychological support, even the strongest leaders drift toward the status quo.</p>", "url": "https://hbr.org/2026/02/when-the-bold-leader-you-hired-starts-to-conform", "published_at": "2026-02-06", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Without structural and psychological support, even the strongest leaders drift toward the status quo.</p>"]}
{"id": "source:rss:6373508313", "title": "The Delicate Politics of Hiring Someone from Another Team", "summary": "<p>How to approach internal hiring without damaging relationships.</p>", "url": "https://hbr.org/2026/02/the-delicate-politics-of-hiring-someone-from-another-team", "published_at": "2026-02-05", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>How to approach internal hiring without damaging relationships.</p>"]}
{"id": "source:rss:4626773948", "title": "How to Foster Psychological Safety When AI Erodes Trust on Your Team", "summary": "<p>Proactively addressing team dynamics can prevent costly errors and cycles of dysfunction.</p>", "url": "https://hbr.org/2026/02/how-to-foster-psychological-safety-when-ai-erodes-trust-on-your-team", "published_at": "2026-02-04", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Proactively addressing team dynamics can prevent costly errors and cycles of dysfunction.</p>"]}
{"id": "source:rss:4957003739", "title": "In an Automated World, Human Hospitality Is a Competitive Advantage", "summary": "<p>Lessons from Ritz-Carlton and Four Seasons.</p> <div> <div class=\"fai-CopilotMessage__actions rmlvq19\"> <p>&#160;</p> <div class=\"___1akvep3 f22iagw f1vx9l62 fdr99fa fly5x3f\"> <div class=\"___m91pmt0 f19gb1f4 f22iagw f1063pyq f122n59 fni485r\"> <div class=\"___kpik3k0 f22iagw f122n59 fbhxue7 f19gb1f4 fni485r\"> <div class=\"___he637h0 f22iagw f122n59 fbhxue7 fsbu5mz fni485r\"> <div class=\"___kpik3k0 f22iagw f122n59 fbhxue7 f19gb1f4 fni485r\"> <div> <div class=\"rrd10u0 fui-AriaLive__assertive\"></div> <div class=\"rrd10u0 fui-AriaLive__polite\"></div> <p>&#160;</p> </div> <p>&#160;</p> <section> <h2 class=\"___59yogb0 f1euv43f frkrog8 f1mpe4l3 fkrn0sh f179hvsh fmxx68s f1538868 f1g0x7ka fhxju0i f1qch9an f1cnd47f f1p9o1ba f1sil6mw f1w1vubc fre7gi1 f1358rze fqdk4by f1rvrf73 fd7fpy0\" id=\"feedback-heading\">Provide your feedback on BizChat</h2> <div> <div class=\"fai-FeedbackButtons ___1o9cutk f22iagw f4d9j23 f122n59 f19gb1f4\"></div> </div> </section> <p>&#160;</p> </div> </div> </div> <div class=\"___152j3kg f22iagw f122n59 f19gb1f4 fni485r\"></div> </div> </div> <p>&#160;</p> </div> </div>", "url": "https://hbr.org/2026/02/in-an-automated-world-human-hospitality-is-a-competitive-advantage", "published_at": "2026-02-04", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Lessons from Ritz-Carlton and Four Seasons.</p> <div> <div class=\"fai-CopilotMessage__actions rmlvq19\"> <p>&#160;</p> <div class=\"___1akvep3 f22iagw f1vx9l62 fdr99fa fly5x3f\"> <div class=\"___m91pmt0 f19gb1f4 f22iagw f1063pyq f122n59 fni485r\"> <div class=\"___kpik3k0 f22iagw f122n59 fbhxue7 f19gb1f"]}
{"id": "source:rss:2841311942", "title": "Asking for Help When Others Look to You for Answers", "summary": "<p>Research that overturns common assumptions about competence and confidence.</p>", "url": "https://hbr.org/podcast/2026/02/asking-for-help-when-others-look-to-you-for-answers", "published_at": "2026-02-04", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Research that overturns common assumptions about competence and confidence.</p>"]}
{"id": "source:rss:1245619055", "title": "Are Legacy Metrics Derailing Your Transformation?", "summary": "<p>You can&#8217;t bring your business into the future when your KPIs are stuck in the past.</p>", "url": "https://hbr.org/2026/02/are-legacy-metrics-derailing-your-transformation", "published_at": "2026-02-04", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>You can&#8217;t bring your business into the future when your KPIs are stuck in the past.</p>"]}
{"id": "source:rss:7129337077", "title": "How Do Workers Develop Good Judgment in the AI Era?", "summary": "<p>AI is simultaneously increasing the need for judgment and destroying the experiences that produce it.</p>", "url": "https://hbr.org/2026/02/how-do-workers-develop-good-judgment-in-the-ai-era", "published_at": "2026-02-03", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>AI is simultaneously increasing the need for judgment and destroying the experiences that produce it.</p>"]}
{"id": "source:rss:8583543157", "title": "To Drive AI Adoption, Build Your Team\u2019s Product Management Skills", "summary": "<p>Without a product-minded approach, employees&#8217; attempts to use AI often remain shallow or short-lived.</p>", "url": "https://hbr.org/2026/02/hb-to-drive-ai-adoption-build-your-teams-product-management-skills", "published_at": "2026-02-03", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>Without a product-minded approach, employees&#8217; attempts to use AI often remain shallow or short-lived.</p>"]}
{"id": "source:rss:6518461562", "title": "If and How to Scale the Acquired Podcast", "summary": "<p>When breaking the rules is what got you here, how do you grow without breaking what works?</p>", "url": "https://hbr.org/podcast/2026/02/if-and-how-to-scale-the-acquired-podcast", "published_at": "2026-02-03", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>When breaking the rules is what got you here, how do you grow without breaking what works?</p>"]}
{"id": "source:rss:7252817818", "title": "The Cognitive Science Behind Sudden Change", "summary": "<p>A conversation about staying resilient in the face of upheaval.</p>", "url": "https://hbr.org/podcast/2026/02/the-cognitive-science-behind-sudden-change", "published_at": "2026-02-03", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>A conversation about staying resilient in the face of upheaval.</p>"]}
{"id": "source:rss:5418882333", "title": "The Management Practices That Make Employee Ownership Pay Off", "summary": "<p>An &#8220;ownership culture&#8221; also requires financial transparency, empathy, and rigorous culture measurement.</p>", "url": "https://hbr.org/2026/02/the-management-practices-that-make-employee-ownership-pay-off", "published_at": "2026-02-02", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>An &#8220;ownership culture&#8221; also requires financial transparency, empathy, and rigorous culture measurement.</p>"]}
{"id": "source:rss:1125890419", "title": "\u201cPeople Need Unifying Messages\u201d", "summary": "<p>How leaders can act with clarity amid rising social and political uncertainty.</p>", "url": "https://hbr.org/2026/02/people-need-unifying-messages", "published_at": "2026-02-02", "source_type": "rss", "credibility_tier": "C", "theme_tags": [], "key_claims": [], "why_it_matters": "", "risk_notes": "", "raw_text_snippets": ["<p>How leaders can act with clarity amid rising social and political uncertainty.</p>"]}
